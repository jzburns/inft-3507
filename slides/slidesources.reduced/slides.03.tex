\part{Processes and Threads}
\section{Processes and Threads}
\subsection{Introduction to Processes and Threads}
\begin{frame}{Introduction to Processes and Threads}
  \begin{itemize}
    \item \textbf{Definition}: A process is an independent program in execution with its own memory space, while a thread is a lightweight unit of execution within a process, sharing the process's memory.
    \item \textbf{Memory}: A process has its own isolated memory space (address space), whereas threads within the same process share the same memory space, including code, data, and resources.
    \item \textbf{Overhead}: Processes are heavier, requiring more system resources and time for creation and context switching, while threads are lighter, with lower overhead for creation and switching.
    \item \textbf{Communication}: Inter-process communication (IPC) is complex and slower (e.g., pipes, sockets), while threads communicate faster via shared memory but require synchronization (e.g., locks).
  \end{itemize}
\end{frame}
\begin{frame}{Context switching}
  \begin{block}{Observations}
    \begin{enumerate}
      \item Threads share the same address space. Thread context switching
            is much faster than process context switching:
            \begin{enumerate}
              \item only registers and program counter need to be saved and restored
            \end{enumerate}
      \item Process context switching is more expensive (in time and space) as
            \begin{enumerate}
              \item TLB needs to be flushed
              \item page table is reloaded
              \item address space changes
            \end{enumerate}
      \item Creating and destroying threads is much cheaper than doing so for processes.
    \end{enumerate}
  \end{block}
\end{frame}
\begin{frame}{Why use threads}
  \begin{block}{Some simple reasons}
    \begin{itemize}
      \item \blue{Avoid needless blocking}: a single-threaded process will \red{block} when doing I/O; in a
            multithreaded process, the operating system can switch the CPU to another thread in that process.
      \item \blue{Exploit parallelism}: the threads in a multithreaded process can be scheduled to run in
            parallel on a multiprocessor or multicore processor.
      \item \blue{Avoid process switching}: structure large applications not as a collection of processes, but
            through multiple threads.
    \end{itemize}
  \end{block}
\end{frame}
\begin{frame}{Avoid process switching}
  \begin{block}{Avoid expensive context switching}
    \begin{centerfig}
      \includefigure{03-01}
    \end{centerfig}
  \end{block}
  \begin{block}{Trade-offs}
    \begin{itemize}
      \item Threads use the same address space: more prone to errors
      \item No support from OS/HW to protect threads using each other's memory
      \item Thread context switching may be faster than process context switching
    \end{itemize}
  \end{block}
\end{frame}
\begin{frame}{The cost of a context switch}
  \begin{block}{Consider a simple clock-interrupt handler}
    \begin{itemize}
      \item \red{direct costs}: actual switch and executing code of the handler
      \item \red{indirect costs}: other costs, notably caused by messing up the cache
    \end{itemize}
  \end{block}
  \begin{block}{What a context switch may cause: indirect costs}
    \begin{columns}
      \begin{column}{0.5\textwidth}
        \begin{center}
          \begin{tabular}{c@{\hspace{24pt}}c@{\hspace{24pt}}c}
            \includefigure{03-02a} &
            \includefigure{03-02b} &
            \includefigure{03-02c}             \\
            {\hspace{0.6cm}}(a)    & (b) & (c)
          \end{tabular}
        \end{center}
      \end{column}
      \begin{column}{0.5\textwidth}
        \begin{itemize}
          \item[(a)] before the context switch
          \item[(b)] after the context switch
          \item[(c)] after accessing block \idsn{D}.
        \end{itemize}
      \end{column}
    \end{columns}
  \end{block}
\end{frame}
% \begin{frame}{A simple example in Python}
%   \begin{centerfig}
%     \includelisting{03-03/mp} 
%   \end{centerfig}
%   \begin{tabular}{l}
%     \small\code{40:23 eve is going to sleep for 14 seconds} \\
%     \small\code{40:23 bob is going to sleep for 4 seconds} \\
%     \small\code{40:27 bob has woken up} \\
%     \small\code{40:37 eve has woken up}
%   \end{tabular}
% \end{frame}
% \begin{frame}{A simple example in Python}
%   \begin{centerfig}
%     \includelisting{03-04/mpthread-slide} 
%   \end{centerfig}
% \end{frame}
% \begin{frame}{A simple example in Python}
%   \begin{tabular}{l}
%     \small\code{eve sees shared x being 71} \\
%     \small\code{53:21 eve 0 is going to sleep for 20 seconds} \\
%     \small\code{bob sees shared x being 84} \\
%     \small\code{53:21 eve 1 is going to sleep for 15 seconds} \\
%     \small\code{53:21 eve 2 is going to sleep for 3 seconds} \\
%     \small\code{53:21 bob 0 is going to sleep for 8 seconds} \\
%     \small\code{53:21 bob 1 is going to sleep for 16 seconds} \\
%     \small\code{53:21 bob 2 is going to sleep for 8 seconds} \\
%     \small\code{53:24 eve 2 has woken up, seeing shared x being 72} \\
%     \small\code{53:29 bob 0 has woken up, seeing shared x being 85} \\
%     \small\code{53:29 bob 2 has woken up, seeing shared x being 86} \\
%     \small\code{53:36 eve 1 has woken up, seeing shared x being 73} \\
%     \small\code{53:37 bob 1 has woken up, seeing shared x being 87} \\
%     \small\code{bob sees shared x being 87} \\
%     \small\code{53:41 eve 0 has woken up, seeing shared x being 74} \\
%     \small\code{eve sees shared x being 74} 
%   \end{tabular}
% \end{frame}
\begin{frame}{Thread Switch vs Process Context Switch}
  \begin{columns}[t]

    % Left column: Thread switch
    \begin{column}{0.48\textwidth}
      \textbf{Thread Switch}

      \begin{itemize}
        \item Switch between threads of the \textit{same process}
        \item Address space remains unchanged
        \item Page tables and memory mappings are reused
        \item Faster than process switches
        \item Typically used for concurrency within applications
      \end{itemize}

      \vspace{0.5em}
      \textbf{Overhead:}
      \begin{itemize}
        \item Save/restore registers
        \item Update stack pointer and program counter
      \end{itemize}
    \end{column}

    % Right column: Process switch
    \begin{column}{0.48\textwidth}
      \textbf{Process Context Switch}

      \begin{itemize}
        \item Switch between threads of \textit{different processes}
        \item Address space changes
        \item Page tables must be switched
        \item TLB often flushed or invalidated
        \item Slower than thread switches
      \end{itemize}

      \vspace{0.5em}
      \textbf{Overhead:}
      \begin{itemize}
        \item Save/restore registers
        \item Switch address space
        \item Update memory management state
      \end{itemize}
    \end{column}

  \end{columns}
\end{frame}

\begin{frame}{Threads and operating systems}
  \begin{alertblock}{Main issue}
    Should an OS kernel provide threads, or should they be implemented as user-level packages?
  \end{alertblock}
  \begin{block}{User-space solution}
    \begin{itemize}
      \item All operations can be completely handled \blue{within a single process} \mathexpr{\Rightarrow}
            implementations can be extremely efficient.
      \item \blue{All} services provided by the kernel are done \blue{on behalf of the process in which a thread
              resides} \mathexpr{\Rightarrow} if the kernel decides to block a thread, the entire process will be
            blocked.
      \item Threads are used when there are many external events: \blue{threads block on a per-event basis}
            \mathexpr{\Rightarrow} if the kernel can't distinguish threads, how can it support signaling events to
            them?
    \end{itemize}
  \end{block}
\end{frame}
\begin{frame}{Linux Kernel Threads}
  \begin{itemize}
    \item \textbf{Task Struct Representation}: In the Linux kernel, threads are implemented as lightweight processes, each represented by a \texttt{task\_struct} (defined in \texttt{include/linux/sched.h}), sharing memory but maintaining separate execution contexts for scheduling.
    \item \textbf{Scheduling with CFS}: The Completely Fair Scheduler (CFS) in \texttt{kernel/sched/fair.c} manages kernel threads, treating them as virtual processors and allocating CPU time fairly using a red-black tree.
    \item \textbf{POSIX Threads Integration}: User-space threads (e.g., via \texttt{pthread\_create}) map to kernel threads, enabling Java’s 1:1 threading model to leverage Linux’s scheduling for efficient concurrency.
  \end{itemize}
\end{frame}
% \begin{frame}{Combining user-level and kernel-level threads}
%   \begin{block}{Basic idea} 
%     Introduce a two-level threading approach: \red{kernel threads} that can execute user-level
%     threads.
%   \end{block}
%   \begin{block}{}
%     \begin{center}
%       \includefigure{03-05}
%     \end{center}
%   \end{block}
% \end{frame}
% \begin{frame}{User and kernel threads combined}
%   \begin{block}{Principle operation}
%     \begin{itemize}%\tightlist
%     \item User thread does system call \mathexpr{\Rightarrow} \red{the kernel thread that is
%       executing that user thread, blocks}. The user thread remains \blue{bound} to the kernel thread.
%     \item The kernel can \red{schedule another kernel thread having a runnable user thread bound to
%       it}. Note: this user thread can switch to \blue{any} other runnable user thread currently in user
%       space.
%     \item A user thread calls a blocking user-level operation \mathexpr{\Rightarrow} do context switch
%       to a runnable user thread, (then bound to the same kernel thread).
%     \item When there are no user threads to schedule, a kernel thread may remain idle, and may even be
%       removed (destroyed) by the kernel.
%     \end{itemize}
%   \end{block}
% \end{frame}
\subsection{Threads in distributed systems}
\begin{frame}{Using threads at the client side}
  \begin{block}{Multithreaded web client}
    Hiding network latencies:
    \begin{itemize}\tightlist
      \item Web browser scans an incoming HTML page, and finds that \blue{more files need to be fetched}.
      \item \blue{Each file is fetched by a separate thread}, each doing a (blocking) HTTP request.
      \item As files come in, the browser displays them.
    \end{itemize}
  \end{block}
  \begin{block}{Multiple request-response calls to other machines (RPC)}
    \begin{itemize}\tightlist
      \item A client does several calls at the same time, each one by a different thread.
      \item It then waits until all results have been returned.
      \item Note: if calls are to different servers, we may have a \blue{linear speed-up}.
    \end{itemize}
  \end{block}
\end{frame}
\begin{frame}{Multithreaded clients: does it help?}
  \begin{block}{Thread-level parallelism: TLP}
    Let \mathexpr{c_i} denote the fraction of time that exactly \mathexpr{i} threads are being executed
    simultaneously.
    \[ TLP = \frac{\sum_{i=1}^N i \cdot c_i}{1- c_0} \]
    with \mathexpr{N} the maximum number of threads that (can) execute at the same time.
  \end{block}
  \onslide
  \begin{block}{Practical measurements}
    A typical Web browser has a TLP value between 1.5 and 2.5 \mathexpr{\Rightarrow} threads are primarily
    used for \blue{logically organizing} browsers.
  \end{block}
\end{frame}
\begin{frame}{Using threads at the server side}
  \begin{block}{Improve performance}
    \begin{itemize}\tightlist
      \item Starting a thread is cheaper than starting a new process.
      \item Having a single-threaded server prohibits simple scale-up to a \blue{multiprocessor system}.
      \item As with clients: \blue{hide network latency} by reacting to next request while previous one is being replied.
    \end{itemize}
  \end{block}
  \begin{block}{Better structure}
    \begin{itemize}\tightlist
      \item Most servers have high I/O demands. Using simple, \blue{well-understood blocking calls} simplifies
            the structure.
      \item Multithreaded programs tend to be \blue{smaller and easier to understand} due to \blue{simplified
              flow of control}.
    \end{itemize}
  \end{block}
\end{frame}
\begin{frame}{Why multithreading is popular: organization}
  \begin{block}{Dispatcher/worker model}
    \begin{center}
      \includefigure{03-06}
    \end{center}
  \end{block}
  \begin{block}{Overview}
    \begin{center}
      \begin{tabular}{|l|l|}\hline
        Multithreading          & Parallelism, blocking system calls    \\ \hline
        Single-threaded process & No parallelism, blocking system calls \\ \hline
      \end{tabular}
    \end{center}
  \end{block}
\end{frame}
\section{Virtualization}
\subsection{Principle of virtualization}
% \begin{frame}{Virtualization}
%   \begin{block}{Privileged instructions}
%     Privileged instructions: allowed to be executed only by the kernel.
%   \end{block}
%   \begin{itemize}\tightlist
%     \item Equivalence: Virtual machines (VMs) provide an environment
%           identical to physical hardware, ensuring software runs unmodified.
%     \item Resource Control: The virtual machine monitor (VMM)
%           maintains full control over system resources, preventing VMs from accessing unauthorized resources.
%     \item Efficiency: Most instructions execute directly on
%           hardware for near-native performance, with sensitive instructions trapped by the VMM.
%     \item Isolation: VMs are fully isolated, ensuring no
%           interference or data leaks between VMs or the VMM, using mechanisms like memory and I/O virtualization.
%   \end{itemize}
% \end{frame}
% % \begin{frame}{Mimicking interfaces}
% %   \begin{block}{Four types of interfaces at three different levels}
% %     \begin{enumerate}\tightlist
% %     \item \red{Instruction set architecture}: the set of machine instructions, with two subsets:
% %       \begin{itemize}\tightlist
% %       \item Privileged instructions: allowed to be executed only by the operating system.
% %       \item General instructions: can be executed by any program.
% %       \end{itemize}
% %     \item \red{System calls} as offered by an operating system.
% %     \item \red{Library calls}, known as an \red{application programming interface} (API)
% %     \end{enumerate}
% %   \end{block}
% % \end{frame}
% \begin{frame}[fragile]{Three Virtualization Approaches}
%   \begin{center}
%     % \begin{tabular}{ccc}
%     %   \includefigure{03-10a} &
%     %   \includefigure{03-10b} &
%     %   \includefigure{03-10c} \\
%     %   \blue{(a) Process VM} & \blue{(b) Native VMM} & \blue{(c) Hosted VMM}
%     % \end{tabular}
%     \begin{verbatim}
% (a) Process VM           (b) Native VMM           (c) Hosted VMM
% ------------------       ------------------       ------------------
%  Application             Application              Application
%  ------------------      ------------------       ------------------
%  Runtime system          Guest OS                 Guest OS
%  (e.g. JVM)              ------------------       ------------------
%  ------------------      Native VMM               Hosted VMM
%  Host Operating          (Type 1 hypervisor)      (Type 2 hypervisor)
%  System                  ------------------       ------------------
%  ------------------      Hardware                 Host Operating System
%  Hardware                                         ------------------
%                                                   Hardware                                                 
% \end{verbatim}
%   \end{center}
%   \begin{block}{Differences}
%     \begin{itemize}\tightlist
%       \item[(a)] Separate set of instructions, an interpreter/emulator, running atop an OS.
%       \item[(b)] Low-level instructions, along with bare-bones minimal operating system
%       \item[(c)] Low-level instructions, but delegating most work to a full-fledged OS.
%     \end{itemize}
%   \end{block}
% \end{frame}

% \begin{frame}{VM Performance}
%   \begin{block}{Refining the organization}
%     \begin{tabular}{@{}ll}
%       \includefigure[0.71]{03-11}
%       \begin{minipage}[b]{0.4\textwidth}
%         \begin{itemize}\tightlist
%           \item \red{Privileged instruction}: if and only if executed in user mode, it causes a \blue{trap}
%                 to the operating system
%           \item \red{Nonpriviliged instruction}: the rest
%         \end{itemize}
%       \end{minipage}
%     \end{tabular}
%   \end{block}
%   \begin{block}{Special instructions}
%     \begin{itemize}
%       \item \red{Control-sensitive instruction}: may affect configuration of a machine (e.g., one affecting
%             relocation register or interrupt table).
%       \item \red{Behavior-sensitive instruction}: effect is partially determined by context (e.g., \code{POPF}
%             sets an interrupt-enabled flag, but only in system mode).
%     \end{itemize}
%   \end{block}
% \end{frame}
% \begin{frame}{Popek and Goldberg: Condition for virtualization}
%   \begin{alertblock}{Necessary condition}
%     \itshape For any conventional computer, a virtual machine monitor may be constructed if the set of
%     sensitive instructions for that computer is a subset of the set of privileged instructions.
%   \end{alertblock}
%   \begin{block}{Problem: condition is not always satisfied}
%     There may be sensitive instructions that are executed in user mode without causing a trap to the
%     operating system.
%   \end{block}
%   \begin{block}{Solutions}
%     \begin{itemize}
%       \item Emulate all instructions
%       \item Wrap nonprivileged sensitive instructions to divert control to VMM
%       \item \blue{Paravirtualization}: modify guest OS, either by preventing nonprivileged sensitive
%             instructions, or making them nonsensitive (i.e., changing the context).
%     \end{itemize}
%   \end{block}
% \end{frame}



\begin{frame}{Scope and Terminology}
  \begin{itemize}
    \item \textbf{System virtualization:} presents a virtual hardware platform capable of running an OS
    \item \textbf{Process virtualization:} presents a virtual execution environment for a single program (e.g., a managed runtime)
    \item \textbf{Emulation:} reproduces an ISA and/or device behavior in software
    \item \textbf{Hypervisor / VMM:} software layer(s) that create and isolate system VMs
  \end{itemize}

  \vspace{0.4em}
  \begin{block}{Goal}
    Provide isolation and controllable sharing of CPU, memory, and I/O while preserving expected software semantics.
  \end{block}
\end{frame}

%------------------------------------------------
\begin{frame}{Execution Virtualization Spectrum}
  \begin{itemize}
    \item \textbf{Emulation} (ISA/device reproduction): maximizes compatibility across architectures, typically higher overhead
    \item \textbf{Process VM} (language/bytecode runtime): portability and safety for applications, not a full OS boundary
    \item \textbf{System VM} (hypervisor-based): strong isolation and full OS virtualization
  \end{itemize}

  \vspace{0.4em}
  \begin{block}{Key distinction}
    Process VMs virtualize a \emph{program execution model}; hypervisors virtualize a \emph{machine interface}.
  \end{block}
\end{frame}

%------------------------------------------------
\begin{frame}{Diagram: Taxonomy of Virtualization Approaches}
  \centering
  \begin{tikzpicture}[
      box/.style={draw, rectangle, rounded corners=2pt, line width=0.7pt,
          minimum width=11.5cm, minimum height=1.0cm, align=left, inner sep=6pt},
      arrow/.style={-Latex, line width=0.8pt},
      node distance=6mm
    ]
    \node[box] (emu) {\textbf{Emulation}\\
      \(\bullet\) Virtualizes an ISA and/or devices in software\\
      \(\bullet\) Primary benefit: cross-architecture compatibility};

    \node[box, below=of emu] (pvm) {\textbf{Process Virtual Machine (e.g., JVM)}\\
      \(\bullet\) Virtualizes an application execution model (bytecode + runtime services)\\
      \(\bullet\) Primary benefit: portability, safety properties, managed services};

    \node[box, below=of pvm] (svm) {\textbf{System Virtual Machine (Hypervisor / VMM)}\\
      \(\bullet\) Virtualizes CPU, memory, and devices to run an unmodified OS\\
      \(\bullet\) Primary benefit: strong isolation and resource control at machine granularity};

    % A light grouping annotation
    \node[draw, dashed, very thick, rounded corners=2pt,
      fit=(pvm), inner sep=7pt] (pvmfit) {};
    \node[anchor=west] at ([xshift=3mm]pvmfit.east) {\small program boundary};

    \node[draw, dashed, very thick, rounded corners=2pt,
      fit=(svm), inner sep=7pt] (svmfit) {};
    \node[anchor=west] at ([xshift=3mm]svmfit.east) {\small OS boundary};

  \end{tikzpicture}

  \vspace{0.6em}
  \small
  \textbf{Figure:} Conceptual taxonomy. Emulation targets compatibility, process VMs target portable execution for programs,
  and system VMs target full OS virtualization and isolation.
\end{frame}

%------------------------------------------------
\begin{frame}{System VMs: Type 1 and Type 2 Hypervisors}
  \begin{itemize}
    \item \textbf{Type 1 (bare-metal):} hypervisor runs directly on hardware, commonly with a privileged management domain
    \item \textbf{Type 2 (hosted):} hypervisor/VMM runs atop a general-purpose host OS and leverages host drivers/services
  \end{itemize}

  \vspace{0.4em}
  \begin{block}{Engineering focus}
    The practical security boundary is determined by the \textbf{trusted computing base (TCB)}: what must be trusted for isolation.
  \end{block}
\end{frame}

%------------------------------------------------
\begin{frame}{Diagram: Type 1 vs Type 2 Stack Organization}
  \centering
  \begin{tikzpicture}[
      layer/.style={draw, rectangle, rounded corners=2pt, line width=0.7pt,
          minimum width=5.6cm, minimum height=0.85cm, align=center},
      arrow/.style={-Latex, line width=0.8pt},
      tcb/.style={draw, dashed, very thick, rounded corners=2pt, inner sep=6pt},
      node distance=4mm
    ]

    % --- Left: Type 1 ---
    \node at (-3.4,4.2) {\textbf{Type 1 (Bare-metal)}};

    \node[layer] (t1a) at (-3.4,3.4) {Guest Apps};
    \node[layer] (t1g) at (-3.4,2.45) {Guest OS};
    \node[layer] (t1v) at (-3.4,1.50) {VMM / Device Model};
    \node[layer] (t1h) at (-3.4,0.55) {Hypervisor Core};
    \node[layer] (t1p) at (-3.4,-0.40) {Hardware};

    \draw[arrow] (t1a) -- (t1g);
    \draw[arrow] (t1g) -- (t1v);
    \draw[arrow] (t1v) -- (t1h);
    \draw[arrow] (t1h) -- (t1p);

    \node[tcb, fit=(t1v)(t1h)] (t1tcb) {};
    \node[anchor=west] at ([xshift=2mm]t1tcb.east) {\small TCB};

    % --- Right: Type 2 ---
    \node at (3.4,4.2) {\textbf{Type 2 (Hosted)}};

    \node[layer] (t2a) at (3.4,3.4) {Guest Apps};
    \node[layer] (t2g) at (3.4,2.45) {Guest OS};
    \node[layer] (t2v) at (3.4,1.50) {VMM / Hypervisor Module};
    \node[layer] (t2o) at (3.4,0.55) {Host OS (drivers, services)};
    \node[layer] (t2p) at (3.4,-0.40) {Hardware};

    \draw[arrow] (t2a) -- (t2g);
    \draw[arrow] (t2g) -- (t2v);
    \draw[arrow] (t2v) -- (t2o);
    \draw[arrow] (t2o) -- (t2p);

    \node[tcb, fit=(t2v)(t2o)] (t2tcb) {};
    \node[anchor=west] at ([xshift=2mm]t2tcb.east) {\small TCB};

  \end{tikzpicture}

  \vspace{0.6em}
  \small
  \textbf{Figure:} Representative stack organizations. In Type~2 systems, the host OS becomes part of the trusted base for isolation.
\end{frame}

%------------------------------------------------
\begin{frame}{Emulation vs Hypervisor-Based Virtualization}
  \begin{itemize}
    \item \textbf{Emulation:} can execute software for a different ISA; overhead arises from instruction translation and device modeling
    \item \textbf{System VM with hardware assist:} guest code runs largely natively; overhead concentrates in traps/exits and I/O paths
    \item \textbf{Process VM (e.g., JVM):} does not virtualize devices or privileged CPU state; relies on the host OS for isolation
  \end{itemize}

  \vspace{0.4em}
  \begin{block}{Implication}
    ISA portability and OS-level isolation are different objectives; they are frequently conflated but have different mechanisms and costs.
  \end{block}
\end{frame}

%------------------------------------------------
\begin{frame}{Resource Control: CPU and Memory}
  \begin{block}{CPU control concepts}
    \begin{itemize}
      \item \textbf{Capacity:} number of vCPUs and their mapping to physical CPUs
      \item \textbf{Shares/weights:} proportional allocation under contention
      \item \textbf{Limits/caps:} enforce maximum CPU usage (often expressed as a percentage of a core set)
      \item \textbf{Reservations:} minimum guaranteed CPU capacity (where supported)
    \end{itemize}
  \end{block}

  \begin{block}{Memory control concepts}
    \begin{itemize}
      \item \textbf{Static limit:} maximum assigned memory for a VM
      \item \textbf{Ballooning:} cooperative reclamation from guests to enable overcommit
      \item \textbf{Swapping/reclamation:} provider-side memory pressure mechanisms (risk of latency inflation)
    \end{itemize}
  \end{block}
\end{frame}

%------------------------------------------------
\begin{frame}{Diagram: Resource Allocation and Enforcement Points}
  \begin{tikzpicture}[
      box/.style={draw, rectangle, rounded corners=2pt, line width=0.7pt,
          minimum width=9.0cm, minimum height=0.9cm, align=left, inner sep=6pt},
      smallbox/.style={draw, rectangle, rounded corners=2pt, line width=0.7pt,
          minimum width=5.8cm, minimum height=0.85cm, align=left, inner sep=6pt},
      arrow/.style={-Latex, line width=0.8pt},
      node distance=6mm
    ]

    \node[box] (vm) {\textbf{Virtual Machine}\\
      \(\bullet\) configured: vCPUs, CPU cap/share; memory limit/reservation\\
      \(\bullet\) observed: CPU utilization, run-queue delay; memory pressure indicators};

    \node[smallbox, below=of vm, xshift=-3.1cm] (cpu) {\textbf{CPU Scheduler (Hypervisor)}\\
      \(\bullet\) enforces shares and caps\\
      \(\bullet\) maps vCPUs \(\rightarrow\) pCPUs};

    \node[smallbox, below=of vm, xshift=3.1cm] (mem) {\textbf{Memory Manager (Hypervisor)}\\
      \(\bullet\) enforces memory limits\\
      \(\bullet\) ballooning / reclamation};

    \node[box, below=of cpu, yshift=-2mm] (hw) {\textbf{Hardware Resources}\\
      \(\bullet\) physical cores, caches; DRAM; IOMMU/device DMA constraints};

    \draw[arrow] (vm.south) -- (cpu.north);
    \draw[arrow] (vm.south) -- (mem.north);
    \draw[arrow] (cpu.south) -- (hw.north);
    \draw[arrow] (mem.south) -- (hw.north);

  \end{tikzpicture}

  \vspace{0.6em}
  \small
  \textbf{Figure:} Enforcement points for CPU and memory control. Allocation policies are implemented by the hypervisor scheduler
  and memory manager, which multiplex physical resources across VMs.
\end{frame}

%------------------------------------------------
\begin{frame}{Concrete Control Examples (CPU \% and Memory \%)}
  \begin{block}{CPU}
    \begin{itemize}
      \item \textbf{CPU cap (percentage):} limit a VM to (e.g.) \(60\%\) of one core or \(240\%\) of a 4-core entitlement
      \item \textbf{Shares/weights:} if two VMs have weights \(2{:}1\), they receive that proportion under contention
      \item \textbf{Pinning/affinity:} restrict vCPUs to selected cores to control interference and improve predictability
    \end{itemize}
  \end{block}

  \begin{block}{Memory}
    \begin{itemize}
      \item \textbf{Memory limit:} hard upper bound on guest-usable memory
      \item \textbf{Reservation:} minimum memory intended to remain available (platform-dependent)
      \item \textbf{Overcommit with ballooning:} reclaim unused guest pages before swapping at the host
    \end{itemize}
  \end{block}
\end{frame}

%------------------------------------------------
\begin{frame}{Summary}
  \begin{itemize}
    \item Emulation, process VMs, and hypervisors address different requirements and expose different boundaries
    \item Type~1 and Type~2 hypervisors differ mainly in where the trusted base resides and how drivers are obtained
    \item Modern platforms treat CPU and memory as first-class, policy-controlled resources: shares, caps, reservations, and limits
  \end{itemize}
\end{frame}

% ------------------------------------------------------------
\begin{frame}{Virtualization and Containers}
  Virtualization is about running workloads as if they had their own machine.

  \medskip
  In Linux container-style virtualization, two kernel features provide most of the illusion:
  \begin{itemize}
    \item \textbf{Namespaces} \(\rightarrow\) \emph{isolation}: ``what you can see''
    \item \textbf{Control groups (cgroups)} \(\rightarrow\) \emph{control}: ``what you can use''
  \end{itemize}

  \medskip
  A \textbf{container} is typically: \textit{namespaces + cgroups} (plus filesystem + tooling).

  If multiple applications share one OS kernel, we want:
  \begin{itemize}
    \item Strong \textbf{separation of views} (processes, network, mounts, hostnames, users)
    \item Predictable \textbf{resource sharing} (CPU, memory, I/O) without one app starving others
  \end{itemize}

  \medskip
  Linux containers achieve this without a hypervisor by virtualizing \emph{interfaces to the kernel}.
\end{frame}

% ------------------------------------------------------------
\begin{frame}{Namespaces: isolation of kernel resources}
  A \textbf{namespace} gives a process a private view of a specific kernel resource.

  \medskip
  Common namespaces:
  \begin{itemize}
    \item \textbf{PID} (process IDs): processes see a different PID tree
    \item \textbf{Mount} (MNT): separate mount table / filesystem view
    \item \textbf{Network} (NET): interfaces, routes, ports isolated
    \item \textbf{UTS}: hostname/domainname isolation
    \item \textbf{IPC}: SysV IPC, POSIX message queues, etc.
    \item \textbf{User} (USER): user/group ID mapping (enables unprivileged containers)
    \item \textbf{Cgroup} namespace: hides cgroup paths
  \end{itemize}
\end{frame}

% ------------------------------------------------------------
\begin{frame}{Control groups (cgroups): accounting and limits}
  \textbf{cgroups} group processes and apply resource \emph{accounting, limits, and prioritization}.

  \medskip
  Typical controls:
  \begin{itemize}
    \item \textbf{CPU}: shares/quotas; prevent CPU hogging
    \item \textbf{Memory}: limits; OOM behavior per group
    \item \textbf{I/O}: throttle block I/O
    \item \textbf{PIDs}: limit number of processes
  \end{itemize}

  \medskip
  Key idea: \textbf{namespaces isolate}; \textbf{cgroups constrain}.
\end{frame}

% ------------------------------------------------------------
\begin{frame}{How they fit together (container model)}
  A container runtime typically:
  \begin{enumerate}
    \item Creates new \textbf{namespaces} for the process (isolation)
    \item Places the process into \textbf{cgroups} (resource governance)
    \item Sets up a root filesystem and mounts (often with overlayfs)
    \item Configures networking (veth pairs, bridges, NAT, etc.)
  \end{enumerate}

  \medskip
  The result: a process that \emph{looks} like it runs on its own system and can be \emph{limited}.
\end{frame}

% ============================================================
% TikZ DIAGRAM SLIDE #1 (own slide + caption)
% ============================================================
\begin{frame}{Diagram: cgroups as a resource governance tree}
  \centering
  \begin{figure}
    \centering
    \begin{tikzpicture}[
        font=\small,
        node distance=10mm,
        box/.style={draw, rounded corners, align=center, inner sep=6pt},
        arrow/.style={-Latex, thick}
      ]
      \node[box] (root) {cgroup root\\\texttt{/sys/fs/cgroup}};
      \node[box, below left=of root, xshift=-6mm] (svcA) {serviceA\\CPU=50\%\\Mem=512MB};
      \node[box, below right=of root, xshift=6mm] (svcB) {serviceB\\CPU=50\%\\Mem=512MB};

      \node[box, below=of svcA] (a1) {proc A1};
      \node[box, below=of a1] (a2) {proc A2};

      \node[box, below=of svcB] (b1) {proc B1};

      \draw[arrow] (root) -- (svcA);
      \draw[arrow] (root) -- (svcB);
      \draw[arrow] (svcA) -- (a1);
      \draw[arrow] (a1) -- (a2);
      \draw[arrow] (svcB) -- (b1);

      \node[draw, dashed, rounded corners, fit=(svcA)(a2), inner sep=6pt, label={[font=\small]above:limits apply to the group}] {};
      \node[draw, dashed, rounded corners, fit=(svcB)(b1), inner sep=6pt] {};
    \end{tikzpicture}
    \caption{Cgroups organize processes into a hierarchy and apply resource limits/accounting per group.}
  \end{figure}
\end{frame}

% ============================================================
% TikZ DIAGRAM SLIDE #2 (own slide + caption)
% ============================================================
\begin{frame}{Diagram: namespaces provide separate ``views''}
  \centering
  \begin{figure}
    \centering
    \begin{tikzpicture}[
        font=\small,
        node distance=8mm,
        box/.style={draw, rounded corners, align=center, inner sep=6pt},
        layer/.style={draw, rounded corners, minimum width=3.5cm, minimum height=0.9cm, align=center},
        arrow/.style={-Latex, thick}
      ]
      \node[box] (host) {Host kernel\\(shared)};

      \node[layer, below=of host] (ns1) {Namespace set for Container 1: \\ PID, NET, MNT, UTS, IPC, USER};
      \node[layer, below=of ns1] (p1) {Processes inside Container 1\\see private PID tree, mounts, hostname, network};

      \node[layer, right=2.2cm of ns1] (ns2) {Namespace set for Container 2: \\PID, NET, MNT, UTS, IPC, USER};
      \node[layer, below=of ns2] (p2) {Processes inside Container 2\\see a different private view};

      \draw[arrow] (host) -- (ns1);
      \draw[arrow] (ns1) -- (p1);

      \draw[arrow] (host) -- (ns2);
      \draw[arrow] (ns2) -- (p2);

      \node[draw, dashed, rounded corners, fit=(ns1)(p1), inner sep=6pt, label={[font=\small]above:Container 1}] {};
      \node[draw, dashed, rounded corners, fit=(ns2)(p2), inner sep=6pt, label={[font=\small]above:Container 2}] {};
    \end{tikzpicture}
    \caption{Namespaces isolate what processes can see; multiple containers can share one kernel while keeping distinct views.}
  \end{figure}
\end{frame}

% ------------------------------------------------------------
\begin{frame}{A simple isolation example with \texttt{unshare}}
  \texttt{unshare} creates new namespaces for a process (and its children).

  \medskip
  We'll demonstrate isolation by creating:
  \begin{itemize}
    \item a new \textbf{UTS namespace} (private hostname)
    \item a new \textbf{PID namespace} (PID 1 inside)
    \item a new \textbf{mount namespace} (private mount table)
    \item optionally a \textbf{user namespace} (run as ``root'' inside without host root)
  \end{itemize}
\end{frame}

% ------------------------------------------------------------
\begin{frame}[fragile]{Example: \texttt{unshare} for a private hostname + PID tree}
  \begin{lstlisting}[style=sh]
# Create new user, mount, UTS, and PID namespaces.
# --map-root-user maps your user to root inside the user namespace.
unshare --user --map-root-user --mount --uts --pid --fork /bin/bash
\end{lstlisting}

  Inside the new shell:
  \begin{lstlisting}[style=sh]
# UTS namespace: hostname is private
hostname container-demo

# PID namespace: this shell's child processes start a new PID tree
echo "my pid:" $$

# Compare process listing (you should see a tiny PID universe)
ps -ef
\end{lstlisting}
\end{frame}

% ------------------------------------------------------------
\begin{frame}[fragile]{Example: mount namespace isolation (private mounts)}
  In the same \texttt{unshare} shell:

  \begin{lstlisting}[style=sh]
# Make mount operations "private" to this namespace
mount --make-rprivate /

# Create a temporary mount only visible here
mkdir -p /tmp/ns-mount
mount -t tmpfs tmpfs /tmp/ns-mount

# Observe it exists here:
mount | grep ns-mount
\end{lstlisting}

  On the host (outside the namespace), that tmpfs mount will not appear in \texttt{mount} output.
\end{frame}

% ------------------------------------------------------------
\begin{frame}{What isolation did we get?}
  From the example:
  \begin{itemize}
    \item \textbf{UTS namespace}: hostname change does not affect the host
    \item \textbf{PID namespace}: processes see a new PID hierarchy (often with PID 1 inside)
    \item \textbf{Mount namespace}: mounts are private to the namespace
    \item \textbf{User namespace}: you can have root-like IDs inside without being host root
  \end{itemize}

  \medskip
  This is the core of container isolation, and it ties directly back to virtualization:\\
  \textbf{virtualize the process's view of the system without virtualizing the hardware.}
\end{frame}

% ------------------------------------------------------------
\subsection{Containers}
\begin{frame}{Containers}
  \begin{centerfig}
    \includefigure{03-12}
  \end{centerfig}

  \begin{itemize}\tightlist
    \item \blue{Namespaces}: a collection of processes in a container is given their own view of identifiers
    \item \blue{Union file system:} combine several file systems into a layered fashion with only the highest
          layer allowing for \code{write} operations (and the one being part of a container).
    \item \blue{Control groups}: resource restrictions can be imposed upon a collection of processes.
  \end{itemize}
\end{frame}

\begin{frame}{Summary}
  \begin{itemize}
    \item Virtualization can be done at different layers: hardware (VMs) vs. OS interfaces (containers).
    \item \textbf{Namespaces} isolate what processes can see (views of kernel resources).
    \item \textbf{cgroups} govern what processes can use (resource limits/accounting).
    \item \texttt{unshare} is a minimal, direct way to see namespace isolation in action.
  \end{itemize}
\end{frame}

% \begin{frame}{Example: PlanetLab}
%   \begin{block}{Essence} 
%     Different organizations contribute machines, which they subsequently \blue{share} for various experiments.
%   \end{block}
%   \begin{alertblock}{Problem} 
%     We need to ensure that different distributed applications do not get into each other's way
%     \mathexpr{\Rightarrow} \blue{virtualization}
%   \end{alertblock}
% \end{frame}
% \begin{frame}{PlanetLab basic organization}
%   \begin{centerfig}
%     \includefigure{03-13}
%   \end{centerfig}
% \begin{block}{Vserver}
%   Independent and protected environment with its own libraries, server versions, and so on. Distributed
%   applications are assigned a \blue{collection of vservers} \red{distributed across multiple machines}
% \end{block}
% \end{frame}
% \begin{frame}{PlanetLab Vservers and slices}
%   \begin{block}{Essence}
%     \begin{itemize}\tightlist
%     \item Each Vserver operates in its own environment (cf.\ \code{chroot}). 
%     \item Linux enhancements include proper adjustment of process IDs (e.g., \code{init} having ID 0). 
%     \item Two processes in different Vservers may have same user ID, but does not imply the same user.
%     \end{itemize}
%   \end{block}
%   \begin{block}{Separation leads to slices}
%     \begin{center}
%       \includefigure[1]{03-14}
%     \end{center}
%   \end{block}
% \end{frame}
\subsection{Comparing virtual machines and containers}
\subsection{Application of virtual machines to distributed systems}
\begin{frame}{VMs and cloud computing}
  \begin{block}{Three types of cloud services}
    \begin{itemize}\tightlist
      \item \blue{Infrastructure-as-a-Service} covering the basic infrastructure
      \item \blue{Platform-as-a-Service} covering system-level services
      \item \blue{Software-as-a-Service} containing actual applications
    \end{itemize}
  \end{block}
  \begin{alertblock}{IaaS}
    Instead of renting out a physical machine, a cloud provider will rent out a VM (or VMM) that may be
    sharing a physical machine with other customers \mathexpr{\Rightarrow} almost complete isolation between
    customers (although performance isolation may not be reached).
  \end{alertblock}
\end{frame}
% \section{Clients}
% \subsection{Networked user interfaces}
% \begin{frame}{Client-server interaction}
%   \begin{block}{Distinguish application-level and middleware-level solutions}
%     \begin{center}
%       \begin{tabular}{@{}cc}
%         \includefigure{03-15a} &
%         \includefigure{03-15b} \\
%       \end{tabular}
%     \end{center}
%   \end{block}
% \end{frame}
% \begin{frame}{Example: The X Window system}
%   \begin{block}{Basic organization}
%     \begin{center}
%       \includefigure{03-16}
%     \end{center}
%   \end{block}
%   \onslide
%   \begin{alertblock}{X client and server}
%     The application acts as a \red{client} to the X-kernel, the latter running as a \red{server} on the
%     client's machine.
%   \end{alertblock}
% \end{frame}
% \begin{frame}{Improving X}
%   \begin{block}{Practical observations}
%     \begin{itemize}\tightlist
%     \item There is often no clear separation between application logic and user-interface commands
%     \item Applications tend to operate in a tightly synchronous manner with an X kernel
%     \end{itemize}
%   \end{block}
%   \begin{block}{Alternative approaches}
%     \begin{itemize}
%     \item Let applications control the display \blue{completely}, up to the pixel level (e.g., \red{VNC})
%     \item Provide only a few high-level display operations (dependent on local video drivers), allowing more
%       efficient display operations.
%     \end{itemize}
%   \end{block}
% \end{frame}
% \subsection{Virtual desktop environment}
% \begin{frame}{Virtual desktop environment}
%   \begin{block}{Logical development}
%     With an increasing number of cloud-based applications, the question is how to use those applications from
%     a user's premise?
%     \begin{itemize}\firmlist
%     \item \red{Issue}: develop the ultimate networked user interface
%     \item \red{Answer}: use a Web browser to establish a seamless experience
%     \end{itemize}
%   \end{block}
%   \begin{centerfig}
%     \includefigure[0.18]{chrome-book} \\
%     The Google Chromebook
%   \end{centerfig}
% \end{frame}
% \begin{frame}{The anatomy of a Web browser}
%   \begin{centerfig}
%     \includefigure[0.83]{03-17}
%   \end{centerfig}
% \end{frame}
% \subsection{Client-side software for distribution transparency}
% \begin{frame}{Client-side software}
%   \begin{block}{Generally tailored for distribution transparency}
%     \begin{itemize}\tightlist
%     \item \blue{Access transparency}: client-side stubs for RPCs
%     \item \blue{Location/migration transparency}: let client-side software keep track of actual location
%     \item \blue{Replication transparency}: multiple invocations handled by client stub:
%       \begin{center}
%         \includefigure{03-18}
%       \end{center}
%     \item \blue{Failure transparency}: can often be placed only at client (we're trying to mask server and
%       communication failures).
%     \end{itemize}
%   \end{block}
% \end{frame}
% \section{Servers}
% \subsection{General design issues}
% \begin{frame}{Servers: General organization}
%   \begin{block}{Basic model} 
%     A process implementing a specific service on behalf of a collection of clients. It waits for an incoming
%     request from a client and subsequently ensures that the request is taken care of, after which it waits for
%     the next incoming request.
%   \end{block}
%   \onslide
%   \begin{block}{Two basic types}
%     \begin{itemize}
%     \item \red{Iterative server}: Server handles the request before attending a next request.
%     \item \red{Concurrent server}: Uses a \blue{dispatcher}, which picks up an incoming request that is then
%       passed on to a separate thread/process.
%     \end{itemize}
%   \end{block}
%   \begin{alertblock}{Observation}
%     Concurrent servers are the norm: they can easily handle multiple requests, notably in the presence of
%     blocking operations (to disks or other servers).
%   \end{alertblock}
% \end{frame}
% \begin{frame}{Contacting a server}
%   \begin{block}{Observation: most services are tied to a specific port}
%     \begin{center}
%       \renewcommand{\arraystretch}{1.1}
%       \begin{tabular}{|lrl|}\hline
%         ftp-data    &     20 &    File Transfer [Default Data]				\\ 
%         ftp         &     21 &    File Transfer [Control]					\\ 
%         telnet      &     23 &    Telnet									\\ 
%         smtp        &     25 &    Simple Mail Transfer						\\ 
%         www         &     80 &    Web (HTTP)                                \\ \hline
%       \end{tabular}
%     \end{center}
%   \end{block}
%   \begin{block}{Dynamically assigning an end point: two approaches}
%     \begin{center}
%       \begin{tabular}{@{}c@{}c}
%         \includefigure[0.65]{03-19a} &
%         \includefigure[0.65]{03-19b} \\
%       \end{tabular}
%     \end{center}
%   \end{block}
% \end{frame}
% \begin{frame}{Out-of-band communication}
%   \begin{block}{Issue} 
%     Is it possible to \blue{interrupt} a server once it has accepted (or is in the process of accepting) a
%     service request?
%   \end{block}
%   \onslide
%   \begin{block}{Solution~1: Use a separate port for urgent data}
%     \begin{itemize}\tightlist
%     \item Server has a separate thread/process for urgent messages
%     \item Urgent message comes in \mathexpr{\Rightarrow} \blue{associated request is put on hold}
%     \item Note: we require \blue{OS supports priority-based scheduling}
%     \end{itemize}
%   \end{block}
%   \onslide
%   \begin{block}{Solution~2: Use facilities of the transport layer}
%     \begin{itemize}\tightlist
%     \item Example: TCP allows for urgent messages in same connection
%     \item Urgent messages can be caught using OS signaling techniques
%     \end{itemize}
%   \end{block}
% \end{frame}
% \begin{frame}{Servers and state}
%   \begin{block}{Stateless servers}
%     Never keep \blue{accurate} information about the status of a client after having handled a request:
%     \begin{itemize}\tightlist
%     \item Don't record whether a file has been opened (simply close it again after access)
%     \item Don't promise to invalidate a client's cache
%     \item Don't keep track of your clients
%     \end{itemize}
%   \end{block}
%   \onslide
%   \begin{block}{Consequences}
%     \begin{itemize}\tightlist
%     \item Clients and servers are \blue{completely independent}
%     \item \blue{State inconsistencies} due to client or server crashes \blue{are reduced}
%     \item Possible \blue{loss of performance} because, e.g., a server cannot anticipate client behavior (think of
%       prefetching file blocks)
%     \end{itemize}
%   \end{block}
%   \onslide
%   \begin{alertblock}{Question}
%     Does connection-oriented communication fit into a stateless design?
%   \end{alertblock}
% \end{frame}
% \begin{frame}{Servers and state}
%   \begin{block}{Stateful servers}
%     Keeps track of the status of its clients:
%     \begin{itemize}\tightlist
%     \item Record that a file has been opened, so that prefetching can be done
%     \item Knows which data a client has cached, and allows clients to keep local copies of shared data
%     \end{itemize}
%   \end{block}
%   \onslide
%   \begin{alertblock}{Observation} 
%     The \blue{performance of stateful servers can be extremely high}, provided clients are allowed to keep
%     local copies. As it turns out, \blue{reliability is often not a major problem}.
%   \end{alertblock}
% \end{frame}
% \subsection{Object servers}
% \begin{frame}{Object servers}
%   \begin{columns}[T]
%     \begin{column}{0.35\textwidth}
%       \includefigure[0.71]{03-20}
%     \end{column}
%     \begin{column}{0.6\textwidth}
%       \begin{itemize}
%       \item \blue{Activation policy}: which actions to take when an invocation request comes in:
%         \begin{itemize}\firmlist
%         \item Where are code and data of the object?
%         \item Which threading model to use?
%         \item Keep modified state of object, if any?
%         \end{itemize}
%       \item \blue{Object adapter}: implements a specific activation policy
%       \end{itemize}
%     \end{column}
%   \end{columns}
% \end{frame}
% \begin{frame}{Example: Ice runtime system -- a server}
%   \begin{centerfig}
%     \includelisting{03-21/server2}    
%   \end{centerfig}
% \end{frame}
% \begin{frame}{Example: Ice runtime system -- a client }
%   \begin{centerfig}
%     \includelisting{03-21/client2}    
%   \end{centerfig}
%   \begin{quote}
%     \code{Object1 says: Hello World from printer1!} \\
%     \code{Object2 says: Hello World from printer2!}
%   \end{quote}
% \end{frame}
% \subsection{Example: The Apache Web server}
% \begin{frame}{Example: the Apache Web server}
%   \begin{centerfig}
%     \includefigure{03-22}
%   \end{centerfig}
% \end{frame}
% \subsection{Server clusters}
% \begin{frame}{Three different tiers}
%   \begin{block}{Common organization}
%     \begin{center}
%       \includefigure{03-23}
%     \end{center}
%   \end{block}
%   \begin{alertblock}{Crucial element} 
%     The first tier is generally responsible for passing requests to an appropriate server: \blue{request
%       dispatching}
%   \end{alertblock}
% \end{frame}
% \begin{frame}{Request Handling}
%   \begin{block}{Observation} 
%     Having the first tier handle all communication from/to the cluster may lead to a \blue{bottleneck}.
%   \end{block}
%   \begin{exampleblock}{A solution: TCP handoff} 
%     \begin{center}
%       \includefigure{03-24}
%     \end{center}
%   \end{exampleblock}
% \end{frame}
% \begin{frame}{When servers are spread across the Internet}
%   \begin{block}{Observation}
%     Spreading servers across the Internet may introduce administrative problems. These can be largely
%     circumvented by using data centers from a single cloud provider.
%   \end{block}
%   \begin{block}{Request dispatching: if locality is important}
%     Common approach: use DNS:
%     \begin{enumerate}\tightlist
%     \item Client looks up specific service through DNS - client's IP address is part of request
%     \item DNS server keeps track of replica servers for the requested service, and returns address of most
%       local server.
%     \end{enumerate}
%   \end{block}
%   \begin{alertblock}{Client transparency}
%     To keep client unaware of distribution, let DNS resolver act on behalf of client. Problem is that the
%     resolver may actually be \blue{far from local} to the actual client.
%   \end{alertblock}
% \end{frame}
% \begin{frame}{A simplified version of the Akamai CDN}
%   \begin{centerfig}
%     \includefigure{03-25}
%   \end{centerfig}
%   \onslide
%   \begin{alertblock}{Important note}
%     The cache is often sophisticated enough to hold more than just passive data. Much of the application code
%     of the origin server can be moved to the cache as well.
%   \end{alertblock}
% \end{frame}
% \section{Code migration}
% \subsection{Reasons for migrating code}
% \begin{frame}{Reasons to migrate code}
%   \begin{block}{Load distribution}
%     \begin{itemize}\firmlist
%     \item Ensuring that servers in a data center are \blue{sufficiently} loaded (e.g., to prevent waste of
%       energy)
%     \item Minimizing communication by ensuring that computations are close to where the data is (think of
%       mobile computing).
%     \end{itemize}
%   \end{block}

%   \begin{block}{Flexibility: moving code to a client when needed}
%     \begin{centerfig}
%       \includefigure{03-27}
%     \end{centerfig}
%     Avoids pre-installing software and increases dynamic configuration.
%   \end{block}
% \end{frame}
% \begin{frame}{Reasons to migrate code}
%   \begin{block}{Privacy and security}
%     In many cases, one cannot move data to another location, for whatever reason (often legal
%     ones). \blue{Solution}: move the code to the data.
%   \end{block}
%   \begin{block}{Example: federated machine learning}
%     \begin{centerfig}
%       \includefigure{03-26}      
%     \end{centerfig}
%   \end{block}
% \end{frame}
% \subsection{Models for code migration}
% \begin{frame}{Paradigms for code mobility}
%   \begin{centerfig}
%     \includefigure[0.77]{03-28}
%   \end{centerfig}
% \end{frame}
% \begin{frame}{Strong and weak mobility}
%   \begin{block}{Object components}
%     \begin{itemize}
%     \item \blue{Code segment}: contains the actual code
%     \item \blue{Data segment}: contains the state
%     \item \blue{Execution state}: contains context of thread executing the object's code
%     \end{itemize}
%   \end{block}
%   \begin{block}{Weak mobility: Move only code and data segment (and reboot execution)}
%     \begin{itemize}
%     \item Relatively simple, especially if code is portable
%     \item Distinguish \blue{code shipping} (push) from \blue{code fetching} (pull)
%     \end{itemize}
%   \end{block}
%   \begin{block}{Strong mobility: Move component, including execution state}
%     \begin{itemize}
%     \item \blue{Migration}: move entire object from one machine to the other
%     \item \blue{Cloning}: start a clone, and set it in the same execution state.
%     \end{itemize}
%   \end{block}
% \end{frame}
% \subsection{Migration in heterogeneous systems}
% \begin{frame}{Migration in heterogeneous systems}
%   \begin{block}{Main problem}
%     \begin{itemize}
%     \item The target machine may not be \blue{suitable to execute the migrated code}
%     \item The definition of process/thread/processor context is \blue{highly dependent on local hardware,
%       operating system and runtime system}
%     \end{itemize}
%   \end{block}
%   \begin{alertblock}{Only solution: abstract machine implemented on different platforms}
%     \begin{itemize}
%     \item Interpreted languages, effectively having their own VM
%     \item Virtual machine monitors
%     \end{itemize}
%   \end{alertblock}
%   \begin{alertblock}{Observation}
%     As containers are directly dependent on the underlying operating system, their migration in heterogeneous
%     environments is far from trivial, to simply impractical, just as process migration is.
%   \end{alertblock}

% \end{frame}
% \begin{frame}{Migrating a virtual machine}
%   \begin{block}{Migrating images: three alternatives}
%     \begin{enumerate}
%     \item Pushing memory pages to the new machine and resending the ones that are later modified during the
%       migration process.
%     \item Stopping the current virtual machine; migrate memory, and start the new virtual machine.
%     \item Letting the new virtual machine pull in new pages as needed: processes start on the new
%       virtual machine immediately and copy memory pages on demand.
%     \end{enumerate}
%   \end{block}
% \end{frame}
%   \begin{frame}{Performance of migrating virtual machines}
%     \begin{block}{Problem}
%       A complete migration may actually take tens of seconds. We also need to realize that during the
%       migration, a service will be completely unavailable for multiple seconds. 
%     \end{block}
%     \begin{block}{Measurements regarding response times during VM migration}
%       \begin{center}
%         \includefigure{03-29} 
%       \end{center}
%     \end{block}
%   \end{frame}
\section{Summary}
\begin{frame}{Summary and Conclusions}
  We have discussed processes and threads
  in Distributed Systems, namely:
  \begin{itemize}
    \item Processes and Threads
    \item Context Switching
    \item Multithreading
    \item Virtualization
    \item Containerization
  \end{itemize}
\end{frame}

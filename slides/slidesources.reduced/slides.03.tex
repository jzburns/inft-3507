\part{Processes}
\section{Threads}
\subsection{Introduction to Processes and Threads}
\begin{slide}{Introduction to Processes and Threads}
    \begin{itemize}
    \item \textbf{Definition}: A process is an independent program in execution with its own memory space, while a thread is a lightweight unit of execution within a process, sharing the process's memory.
    \item \textbf{Memory}: A process has its own isolated memory space (address space), whereas threads within the same process share the same memory space, including code, data, and resources.
    \item \textbf{Overhead}: Processes are heavier, requiring more system resources and time for creation and context switching, while threads are lighter, with lower overhead for creation and switching.
    \item \textbf{Communication}: Inter-process communication (IPC) is complex and slower (e.g., pipes, sockets), while threads communicate faster via shared memory but require synchronization (e.g., locks).      
  \end{itemize}
\end{slide}
\begin{slide}{Context switching}
  \begin{block}{Observations}
    \begin{enumerate}
    \item Threads share the same address space. Thread context switching 
    is much faster than process context switching:
    \begin{enumerate}
      \item only registers and program counter need to be saved and restored
    \end{enumerate}
    \item Process context switching is more expensive (in time and space) as     
    \begin{enumerate}
      \item TLB needs to be flushed 
      \item page table is reloaded 
      \item address space changes
    \end{enumerate}
    \item Creating and destroying threads is much cheaper than doing so for processes.
    \end{enumerate}
  \end{block}
\end{slide}
\begin{slide}{Why use threads}
  \begin{block}{Some simple reasons}
    \begin{itemize}
    \item \blue{Avoid needless blocking}: a single-threaded process will \red{block} when doing I/O; in a
      multithreaded process, the operating system can switch the CPU to another thread in that process.
    \item \blue{Exploit parallelism}: the threads in a multithreaded process can be scheduled to run in
      parallel on a multiprocessor or multicore processor.
    \item \blue{Avoid process switching}: structure large applications not as a collection of processes, but
      through multiple threads.
    \end{itemize}
  \end{block}
\end{slide}
\begin{slide}{Avoid process switching}
  \begin{block}{Avoid expensive context switching}
    \begin{centerfig}
      \includefigure{03-01}
    \end{centerfig}
  \end{block}
  \begin{block}{Trade-offs}
    \begin{itemize}
    \item Threads use the same address space: more prone to errors
    \item No support from OS/HW to protect threads using each other's memory
    \item Thread context switching may be faster than process context switching
    \end{itemize}
  \end{block}
\end{slide}
  \begin{slide}{The cost of a context switch}
    \begin{block}{Consider a simple clock-interrupt handler}
      \begin{itemize}
        \item \red{direct costs}: actual switch and executing code of the handler
        \item \red{indirect costs}: other costs, notably caused by messing up the cache
      \end{itemize}
    \end{block}
    \begin{block}{What a context switch may cause: indirect costs}
      \begin{columns}
        \begin{column}{0.5\textwidth}
          \begin{center}
            \begin{tabular}{c@{\hspace{24pt}}c@{\hspace{24pt}}c}
              \includefigure{03-02a} &
              \includefigure{03-02b} &
              \includefigure{03-02c} \\
              {\hspace{0.6cm}}(a) & (b) & (c)
            \end{tabular}
          \end{center}
        \end{column}
        \begin{column}{0.5\textwidth}
          \begin{itemize}
          \item[(a)] before the context switch
          \item[(b)] after the context switch
          \item[(c)] after accessing block \idsn{D}.
          \end{itemize}
        \end{column}
      \end{columns}
    \end{block}
  \end{slide}
% \begin{slide}{A simple example in Python}
%   \begin{centerfig}
%     \includelisting{03-03/mp} 
%   \end{centerfig}
%   \begin{tabular}{l}
%     \small\code{40:23 eve is going to sleep for 14 seconds} \\
%     \small\code{40:23 bob is going to sleep for 4 seconds} \\
%     \small\code{40:27 bob has woken up} \\
%     \small\code{40:37 eve has woken up}
%   \end{tabular}
% \end{slide}
% \begin{slide}{A simple example in Python}
%   \begin{centerfig}
%     \includelisting{03-04/mpthread-slide} 
%   \end{centerfig}
% \end{slide}
% \begin{slide}{A simple example in Python}
%   \begin{tabular}{l}
%     \small\code{eve sees shared x being 71} \\
%     \small\code{53:21 eve 0 is going to sleep for 20 seconds} \\
%     \small\code{bob sees shared x being 84} \\
%     \small\code{53:21 eve 1 is going to sleep for 15 seconds} \\
%     \small\code{53:21 eve 2 is going to sleep for 3 seconds} \\
%     \small\code{53:21 bob 0 is going to sleep for 8 seconds} \\
%     \small\code{53:21 bob 1 is going to sleep for 16 seconds} \\
%     \small\code{53:21 bob 2 is going to sleep for 8 seconds} \\
%     \small\code{53:24 eve 2 has woken up, seeing shared x being 72} \\
%     \small\code{53:29 bob 0 has woken up, seeing shared x being 85} \\
%     \small\code{53:29 bob 2 has woken up, seeing shared x being 86} \\
%     \small\code{53:36 eve 1 has woken up, seeing shared x being 73} \\
%     \small\code{53:37 bob 1 has woken up, seeing shared x being 87} \\
%     \small\code{bob sees shared x being 87} \\
%     \small\code{53:41 eve 0 has woken up, seeing shared x being 74} \\
%     \small\code{eve sees shared x being 74} 
%   \end{tabular}
% \end{slide}
\begin{slide}{Threads and operating systems}
  \begin{alertblock}{Main issue} 
    Should an OS kernel provide threads, or should they be implemented as user-level packages?
  \end{alertblock}
  \begin{block}{User-space solution}
    \begin{itemize}
    \item All operations can be completely handled \blue{within a single process} \mathexpr{\Rightarrow}
      implementations can be extremely efficient.
    \item \blue{All} services provided by the kernel are done \blue{on behalf of the process in which a thread
      resides} \mathexpr{\Rightarrow} if the kernel decides to block a thread, the entire process will be
      blocked.
    \item Threads are used when there are many external events: \blue{threads block on a per-event basis}
      \mathexpr{\Rightarrow} if the kernel can't distinguish threads, how can it support signaling events to
      them?
    \end{itemize}
  \end{block}
\end{slide}
\begin{slide}{Linux Kernel Threads}
\begin{itemize}
  \item \textbf{Task Struct Representation}: In the Linux kernel, threads are implemented as lightweight processes, each represented by a \texttt{task\_struct} (defined in \texttt{include/linux/sched.h}), sharing memory but maintaining separate execution contexts for scheduling.
  \item \textbf{Scheduling with CFS}: The Completely Fair Scheduler (CFS) in \texttt{kernel/sched/fair.c} manages kernel threads, treating them as virtual processors and allocating CPU time fairly using a red-black tree.
  \item \textbf{POSIX Threads Integration}: User-space threads (e.g., via \texttt{pthread\_create}) map to kernel threads, enabling Java’s 1:1 threading model to leverage Linux’s scheduling for efficient concurrency.
\end{itemize}
\end{slide}
  % \begin{slide}{Combining user-level and kernel-level threads}
  %   \begin{block}{Basic idea} 
  %     Introduce a two-level threading approach: \red{kernel threads} that can execute user-level
  %     threads.
  %   \end{block}
  %   \begin{block}{}
  %     \begin{center}
  %       \includefigure{03-05}
  %     \end{center}
  %   \end{block}
  % \end{slide}
  % \begin{slide}{User and kernel threads combined}
  %   \begin{block}{Principle operation}
  %     \begin{itemize}%\tightlist
  %     \item User thread does system call \mathexpr{\Rightarrow} \red{the kernel thread that is
  %       executing that user thread, blocks}. The user thread remains \blue{bound} to the kernel thread.
  %     \item The kernel can \red{schedule another kernel thread having a runnable user thread bound to
  %       it}. Note: this user thread can switch to \blue{any} other runnable user thread currently in user
  %       space.
  %     \item A user thread calls a blocking user-level operation \mathexpr{\Rightarrow} do context switch
  %       to a runnable user thread, (then bound to the same kernel thread).
  %     \item When there are no user threads to schedule, a kernel thread may remain idle, and may even be
  %       removed (destroyed) by the kernel.
  %     \end{itemize}
  %   \end{block}
  % \end{slide}
\subsection{Threads in distributed systems}
\begin{slide}{Using threads at the client side}
  \begin{block}{Multithreaded web client}
    Hiding network latencies:
    \begin{itemize}\tightlist
    \item Web browser scans an incoming HTML page, and finds that \blue{more files need to be fetched}.
    \item \blue{Each file is fetched by a separate thread}, each doing a (blocking) HTTP request.
    \item As files come in, the browser displays them.
    \end{itemize}
  \end{block}
  \begin{block}{Multiple request-response calls to other machines (RPC)}
    \begin{itemize}\tightlist
    \item A client does several calls at the same time, each one by a different thread.
    \item It then waits until all results have been returned.
    \item Note: if calls are to different servers, we may have a \blue{linear speed-up}.
    \end{itemize}
  \end{block}
\end{slide}
  \begin{slide}{Multithreaded clients: does it help?}
    \begin{block}{Thread-level parallelism: TLP}
      Let \mathexpr{c_i} denote the fraction of time that exactly \mathexpr{i} threads are being executed
      simultaneously.
      \[ TLP = \frac{\sum_{i=1}^N i \cdot c_i}{1- c_0} \]
      with \mathexpr{N} the maximum number of threads that (can) execute at the same time. 
    \end{block}
    \onslide
    \begin{block}{Practical measurements}
      A typical Web browser has a TLP value between 1.5 and 2.5 \mathexpr{\Rightarrow} threads are primarily
      used for \blue{logically organizing} browsers.
    \end{block}
  \end{slide}
\begin{slide}{Using threads at the server side}
  \begin{block}{Improve performance}
    \begin{itemize}\tightlist
    \item Starting a thread is cheaper than starting a new process.
    \item Having a single-threaded server prohibits simple scale-up to a \blue{multiprocessor system}.
    \item As with clients: \blue{hide network latency} by reacting to next request while previous one is being replied.
    \end{itemize}
  \end{block}
  \begin{block}{Better structure}
    \begin{itemize}\tightlist
    \item Most servers have high I/O demands. Using simple, \blue{well-understood blocking calls} simplifies
      the structure.
    \item Multithreaded programs tend to be \blue{smaller and easier to understand} due to \blue{simplified
      flow of control}.
    \end{itemize}
  \end{block}
\end{slide}
\begin{slide}{Why multithreading is popular: organization}
  \begin{block}{Dispatcher/worker model}
    \begin{center}
      \includefigure{03-06}
    \end{center}
  \end{block}
  \begin{block}{Overview}
    \begin{center}
      \begin{tabular}{|l|l|}\hline
        Multithreading          & Parallelism, blocking system calls \\ \hline
        Single-threaded process & No parallelism, blocking system calls \\ \hline
      \end{tabular}
    \end{center}
  \end{block}
\end{slide}
\section{Virtualization}
\subsection{Principle of virtualization}
\begin{slide}{Virtualization}
    \begin{itemize}\tightlist
      \item Equivalence: Virtual machines (VMs) provide an environment 
      identical to physical hardware, ensuring software runs unmodified.
      \item Resource Control: The virtual machine monitor (VMM) 
      maintains full control over system resources, preventing VMs from accessing unauthorized resources.
      \item Efficiency: Most instructions execute directly on 
      hardware for near-native performance, with sensitive instructions trapped by the VMM.
      \item Isolation: VMs are fully isolated, ensuring no 
      interference or data leaks between VMs or the VMM, using mechanisms like memory and I/O virtualization. 
    \end{itemize}
    \begin{block}{Privileged instructions}
      Privileged instructions: allowed to be executed only by the kernel.
    \end{block}
\end{slide}
% \begin{slide}{Mimicking interfaces}
%   \begin{block}{Four types of interfaces at three different levels}
%     \begin{enumerate}\tightlist
%     \item \red{Instruction set architecture}: the set of machine instructions, with two subsets:
%       \begin{itemize}\tightlist
%       \item Privileged instructions: allowed to be executed only by the operating system.
%       \item General instructions: can be executed by any program.
%       \end{itemize}
%     \item \red{System calls} as offered by an operating system.
%     \item \red{Library calls}, known as an \red{application programming interface} (API)
%     \end{enumerate}
%   \end{block}
% \end{slide}
\begin{slide}{Ways of virtualization}
  \begin{center}
    \begin{tabular}{ccc}
      \includefigure{03-10a} &
      \includefigure{03-10b} &
      \includefigure{03-10c} \\
      \blue{(a) Process VM} & \blue{(b) Native VMM} & \blue{(c) Hosted VMM}
    \end{tabular}
  \end{center}
  \begin{block}{Differences}
    \begin{itemize}\tightlist
    \item[(a)] Separate set of instructions, an interpreter/emulator, running atop an OS.
    \item[(b)] Low-level instructions, along with bare-bones minimal operating system
    \item[(c)] Low-level instructions, but delegating most work to a full-fledged OS.
    \end{itemize}
  \end{block}
\end{slide}
  \begin{slide}{Zooming into VMs: performance}
    \begin{block}{Refining the organization}
      \begin{tabular}{@{}ll}
        \includefigure[0.71]{03-11}
        \begin{minipage}[b]{0.4\textwidth}
          \begin{itemize}\tightlist
          \item \red{Privileged instruction}: if and only if executed in user mode, it causes a \blue{trap}
            to the operating system
          \item \red{Nonpriviliged instruction}: the rest
          \end{itemize}
        \end{minipage}
      \end{tabular}
    \end{block}
    \begin{block}{Special instructions}
      \begin{itemize}
      \item \red{Control-sensitive instruction}: may affect configuration of a machine (e.g., one affecting
        relocation register or interrupt table).
      \item \red{Behavior-sensitive instruction}: effect is partially determined by context (e.g., \code{POPF}
        sets an interrupt-enabled flag, but only in system mode).
      \end{itemize}
    \end{block}
  \end{slide}
  \begin{slide}{Condition for virtualization}
    \begin{alertblock}{Necessary condition}
      \itshape For any conventional computer, a virtual machine monitor may be constructed if the set of
      sensitive instructions for that computer is a subset of the set of privileged instructions.
    \end{alertblock}
    \begin{block}{Problem: condition is not always satisfied}
      There may be sensitive instructions that are executed in user mode without causing a trap to the
      operating system.
    \end{block}
    \begin{block}{Solutions}
      \begin{itemize}
      \item Emulate all instructions
      \item Wrap nonprivileged sensitive instructions to divert control to VMM
      \item \red{Paravirtualization}: modify guest OS, either by preventing nonprivileged sensitive
        instructions, or making them nonsensitive (i.e., changing the context).
      \end{itemize}
    \end{block}
  \end{slide}
\subsection{Containers}
\begin{slide}{Containers}
  \begin{centerfig}
    \includefigure{03-12}
  \end{centerfig}

  \begin{itemize}\tightlist
  \item \blue{Namespaces}: a collection of processes in a container is given their own view of identifiers
  \item \blue{Union file system:} combine several file systems into a layered fashion with only the highest
    layer allowing for \code{write} operations (and the one being part of a container).
  \item \blue{Control groups}: resource restrictions can be imposed upon a collection of processes.
  \end{itemize}
\end{slide}
  % \begin{slide}{Example: PlanetLab}
  %   \begin{block}{Essence} 
  %     Different organizations contribute machines, which they subsequently \blue{share} for various experiments.
  %   \end{block}
  %   \begin{alertblock}{Problem} 
  %     We need to ensure that different distributed applications do not get into each other's way
  %     \mathexpr{\Rightarrow} \blue{virtualization}
  %   \end{alertblock}
  % \end{slide}
  % \begin{slide}{PlanetLab basic organization}
  %   \begin{centerfig}
  %     \includefigure{03-13}
  %   \end{centerfig}
  % \begin{block}{Vserver}
  %   Independent and protected environment with its own libraries, server versions, and so on. Distributed
  %   applications are assigned a \blue{collection of vservers} \red{distributed across multiple machines}
  % \end{block}
  % \end{slide}
  % \begin{slide}{PlanetLab Vservers and slices}
  %   \begin{block}{Essence}
  %     \begin{itemize}\tightlist
  %     \item Each Vserver operates in its own environment (cf.\ \code{chroot}). 
  %     \item Linux enhancements include proper adjustment of process IDs (e.g., \code{init} having ID 0). 
  %     \item Two processes in different Vservers may have same user ID, but does not imply the same user.
  %     \end{itemize}
  %   \end{block}
  %   \begin{block}{Separation leads to slices}
  %     \begin{center}
  %       \includefigure[1]{03-14}
  %     \end{center}
  %   \end{block}
  % \end{slide}
\subsection{Comparing virtual machines and containers}
\subsection{Application of virtual machines to distributed systems}
\begin{slide}{VMs and cloud computing}
  \begin{block}{Three types of cloud services}
    \begin{itemize}\tightlist
    \item \red{Infrastructure-as-a-Service} covering the basic infrastructure
    \item \red{Platform-as-a-Service} covering system-level services
    \item \red{Software-as-a-Service} containing actual applications
    \end{itemize}
  \end{block}
  \begin{alertblock}{IaaS}
    Instead of renting out a physical machine, a cloud provider will rent out a VM (or VMM) that may be
    sharing a physical machine with other customers \mathexpr{\Rightarrow} almost complete isolation between
    customers (although performance isolation may not be reached).
  \end{alertblock}
\end{slide}
% \section{Clients}
% \subsection{Networked user interfaces}
% \begin{slide}{Client-server interaction}
%   \begin{block}{Distinguish application-level and middleware-level solutions}
%     \begin{center}
%       \begin{tabular}{@{}cc}
%         \includefigure{03-15a} &
%         \includefigure{03-15b} \\
%       \end{tabular}
%     \end{center}
%   \end{block}
% \end{slide}
% \begin{slide}{Example: The X Window system}
%   \begin{block}{Basic organization}
%     \begin{center}
%       \includefigure{03-16}
%     \end{center}
%   \end{block}
%   \onslide
%   \begin{alertblock}{X client and server}
%     The application acts as a \red{client} to the X-kernel, the latter running as a \red{server} on the
%     client's machine.
%   \end{alertblock}
% \end{slide}
% \begin{slide}{Improving X}
%   \begin{block}{Practical observations}
%     \begin{itemize}\tightlist
%     \item There is often no clear separation between application logic and user-interface commands
%     \item Applications tend to operate in a tightly synchronous manner with an X kernel
%     \end{itemize}
%   \end{block}
%   \begin{block}{Alternative approaches}
%     \begin{itemize}
%     \item Let applications control the display \blue{completely}, up to the pixel level (e.g., \red{VNC})
%     \item Provide only a few high-level display operations (dependent on local video drivers), allowing more
%       efficient display operations.
%     \end{itemize}
%   \end{block}
% \end{slide}
% \subsection{Virtual desktop environment}
% \begin{slide}{Virtual desktop environment}
%   \begin{block}{Logical development}
%     With an increasing number of cloud-based applications, the question is how to use those applications from
%     a user's premise?
%     \begin{itemize}\firmlist
%     \item \red{Issue}: develop the ultimate networked user interface
%     \item \red{Answer}: use a Web browser to establish a seamless experience
%     \end{itemize}
%   \end{block}
%   \begin{centerfig}
%     \includefigure[0.18]{chrome-book} \\
%     The Google Chromebook
%   \end{centerfig}
% \end{slide}
% \begin{slide}{The anatomy of a Web browser}
%   \begin{centerfig}
%     \includefigure[0.83]{03-17}
%   \end{centerfig}
% \end{slide}
% \subsection{Client-side software for distribution transparency}
% \begin{slide}{Client-side software}
%   \begin{block}{Generally tailored for distribution transparency}
%     \begin{itemize}\tightlist
%     \item \blue{Access transparency}: client-side stubs for RPCs
%     \item \blue{Location/migration transparency}: let client-side software keep track of actual location
%     \item \blue{Replication transparency}: multiple invocations handled by client stub:
%       \begin{center}
%         \includefigure{03-18}
%       \end{center}
%     \item \blue{Failure transparency}: can often be placed only at client (we're trying to mask server and
%       communication failures).
%     \end{itemize}
%   \end{block}
% \end{slide}
% \section{Servers}
% \subsection{General design issues}
% \begin{slide}{Servers: General organization}
%   \begin{block}{Basic model} 
%     A process implementing a specific service on behalf of a collection of clients. It waits for an incoming
%     request from a client and subsequently ensures that the request is taken care of, after which it waits for
%     the next incoming request.
%   \end{block}
%   \onslide
%   \begin{block}{Two basic types}
%     \begin{itemize}
%     \item \red{Iterative server}: Server handles the request before attending a next request.
%     \item \red{Concurrent server}: Uses a \blue{dispatcher}, which picks up an incoming request that is then
%       passed on to a separate thread/process.
%     \end{itemize}
%   \end{block}
%   \begin{alertblock}{Observation}
%     Concurrent servers are the norm: they can easily handle multiple requests, notably in the presence of
%     blocking operations (to disks or other servers).
%   \end{alertblock}
% \end{slide}
% \begin{slide}{Contacting a server}
%   \begin{block}{Observation: most services are tied to a specific port}
%     \begin{center}
%       \renewcommand{\arraystretch}{1.1}
%       \begin{tabular}{|lrl|}\hline
%         ftp-data    &     20 &    File Transfer [Default Data]				\\ 
%         ftp         &     21 &    File Transfer [Control]					\\ 
%         telnet      &     23 &    Telnet									\\ 
%         smtp        &     25 &    Simple Mail Transfer						\\ 
%         www         &     80 &    Web (HTTP)                                \\ \hline
%       \end{tabular}
%     \end{center}
%   \end{block}
%   \begin{block}{Dynamically assigning an end point: two approaches}
%     \begin{center}
%       \begin{tabular}{@{}c@{}c}
%         \includefigure[0.65]{03-19a} &
%         \includefigure[0.65]{03-19b} \\
%       \end{tabular}
%     \end{center}
%   \end{block}
% \end{slide}
% \begin{slide}{Out-of-band communication}
%   \begin{block}{Issue} 
%     Is it possible to \blue{interrupt} a server once it has accepted (or is in the process of accepting) a
%     service request?
%   \end{block}
%   \onslide
%   \begin{block}{Solution~1: Use a separate port for urgent data}
%     \begin{itemize}\tightlist
%     \item Server has a separate thread/process for urgent messages
%     \item Urgent message comes in \mathexpr{\Rightarrow} \blue{associated request is put on hold}
%     \item Note: we require \blue{OS supports priority-based scheduling}
%     \end{itemize}
%   \end{block}
%   \onslide
%   \begin{block}{Solution~2: Use facilities of the transport layer}
%     \begin{itemize}\tightlist
%     \item Example: TCP allows for urgent messages in same connection
%     \item Urgent messages can be caught using OS signaling techniques
%     \end{itemize}
%   \end{block}
% \end{slide}
% \begin{slide}{Servers and state}
%   \begin{block}{Stateless servers}
%     Never keep \blue{accurate} information about the status of a client after having handled a request:
%     \begin{itemize}\tightlist
%     \item Don't record whether a file has been opened (simply close it again after access)
%     \item Don't promise to invalidate a client's cache
%     \item Don't keep track of your clients
%     \end{itemize}
%   \end{block}
%   \onslide
%   \begin{block}{Consequences}
%     \begin{itemize}\tightlist
%     \item Clients and servers are \blue{completely independent}
%     \item \blue{State inconsistencies} due to client or server crashes \blue{are reduced}
%     \item Possible \blue{loss of performance} because, e.g., a server cannot anticipate client behavior (think of
%       prefetching file blocks)
%     \end{itemize}
%   \end{block}
%   \onslide
%   \begin{alertblock}{Question}
%     Does connection-oriented communication fit into a stateless design?
%   \end{alertblock}
% \end{slide}
% \begin{slide}{Servers and state}
%   \begin{block}{Stateful servers}
%     Keeps track of the status of its clients:
%     \begin{itemize}\tightlist
%     \item Record that a file has been opened, so that prefetching can be done
%     \item Knows which data a client has cached, and allows clients to keep local copies of shared data
%     \end{itemize}
%   \end{block}
%   \onslide
%   \begin{alertblock}{Observation} 
%     The \blue{performance of stateful servers can be extremely high}, provided clients are allowed to keep
%     local copies. As it turns out, \blue{reliability is often not a major problem}.
%   \end{alertblock}
% \end{slide}
% \subsection{Object servers}
% \begin{slide}{Object servers}
%   \begin{columns}[T]
%     \begin{column}{0.35\textwidth}
%       \includefigure[0.71]{03-20}
%     \end{column}
%     \begin{column}{0.6\textwidth}
%       \begin{itemize}
%       \item \blue{Activation policy}: which actions to take when an invocation request comes in:
%         \begin{itemize}\firmlist
%         \item Where are code and data of the object?
%         \item Which threading model to use?
%         \item Keep modified state of object, if any?
%         \end{itemize}
%       \item \blue{Object adapter}: implements a specific activation policy
%       \end{itemize}
%     \end{column}
%   \end{columns}
% \end{slide}
% \begin{slide}{Example: Ice runtime system -- a server}
%   \begin{centerfig}
%     \includelisting{03-21/server2}    
%   \end{centerfig}
% \end{slide}
% \begin{slide}{Example: Ice runtime system -- a client }
%   \begin{centerfig}
%     \includelisting{03-21/client2}    
%   \end{centerfig}
%   \begin{quote}
%     \code{Object1 says: Hello World from printer1!} \\
%     \code{Object2 says: Hello World from printer2!}
%   \end{quote}
% \end{slide}
% \subsection{Example: The Apache Web server}
% \begin{slide}{Example: the Apache Web server}
%   \begin{centerfig}
%     \includefigure{03-22}
%   \end{centerfig}
% \end{slide}
% \subsection{Server clusters}
% \begin{slide}{Three different tiers}
%   \begin{block}{Common organization}
%     \begin{center}
%       \includefigure{03-23}
%     \end{center}
%   \end{block}
%   \begin{alertblock}{Crucial element} 
%     The first tier is generally responsible for passing requests to an appropriate server: \blue{request
%       dispatching}
%   \end{alertblock}
% \end{slide}
% \begin{slide}{Request Handling}
%   \begin{block}{Observation} 
%     Having the first tier handle all communication from/to the cluster may lead to a \blue{bottleneck}.
%   \end{block}
%   \begin{exampleblock}{A solution: TCP handoff} 
%     \begin{center}
%       \includefigure{03-24}
%     \end{center}
%   \end{exampleblock}
% \end{slide}
% \begin{slide}{When servers are spread across the Internet}
%   \begin{block}{Observation}
%     Spreading servers across the Internet may introduce administrative problems. These can be largely
%     circumvented by using data centers from a single cloud provider.
%   \end{block}
%   \begin{block}{Request dispatching: if locality is important}
%     Common approach: use DNS:
%     \begin{enumerate}\tightlist
%     \item Client looks up specific service through DNS - client's IP address is part of request
%     \item DNS server keeps track of replica servers for the requested service, and returns address of most
%       local server.
%     \end{enumerate}
%   \end{block}
%   \begin{alertblock}{Client transparency}
%     To keep client unaware of distribution, let DNS resolver act on behalf of client. Problem is that the
%     resolver may actually be \blue{far from local} to the actual client.
%   \end{alertblock}
% \end{slide}
% \begin{slide}{A simplified version of the Akamai CDN}
%   \begin{centerfig}
%     \includefigure{03-25}
%   \end{centerfig}
%   \onslide
%   \begin{alertblock}{Important note}
%     The cache is often sophisticated enough to hold more than just passive data. Much of the application code
%     of the origin server can be moved to the cache as well.
%   \end{alertblock}
% \end{slide}
% \section{Code migration}
% \subsection{Reasons for migrating code}
% \begin{slide}{Reasons to migrate code}
%   \begin{block}{Load distribution}
%     \begin{itemize}\firmlist
%     \item Ensuring that servers in a data center are \blue{sufficiently} loaded (e.g., to prevent waste of
%       energy)
%     \item Minimizing communication by ensuring that computations are close to where the data is (think of
%       mobile computing).
%     \end{itemize}
%   \end{block}

%   \begin{block}{Flexibility: moving code to a client when needed}
%     \begin{centerfig}
%       \includefigure{03-27}
%     \end{centerfig}
%     Avoids pre-installing software and increases dynamic configuration.
%   \end{block}
% \end{slide}
% \begin{slide}{Reasons to migrate code}
%   \begin{block}{Privacy and security}
%     In many cases, one cannot move data to another location, for whatever reason (often legal
%     ones). \blue{Solution}: move the code to the data.
%   \end{block}
%   \begin{block}{Example: federated machine learning}
%     \begin{centerfig}
%       \includefigure{03-26}      
%     \end{centerfig}
%   \end{block}
% \end{slide}
% \subsection{Models for code migration}
% \begin{slide}{Paradigms for code mobility}
%   \begin{centerfig}
%     \includefigure[0.77]{03-28}
%   \end{centerfig}
% \end{slide}
% \begin{slide}{Strong and weak mobility}
%   \begin{block}{Object components}
%     \begin{itemize}
%     \item \blue{Code segment}: contains the actual code
%     \item \blue{Data segment}: contains the state
%     \item \blue{Execution state}: contains context of thread executing the object's code
%     \end{itemize}
%   \end{block}
%   \begin{block}{Weak mobility: Move only code and data segment (and reboot execution)}
%     \begin{itemize}
%     \item Relatively simple, especially if code is portable
%     \item Distinguish \blue{code shipping} (push) from \blue{code fetching} (pull)
%     \end{itemize}
%   \end{block}
%   \begin{block}{Strong mobility: Move component, including execution state}
%     \begin{itemize}
%     \item \blue{Migration}: move entire object from one machine to the other
%     \item \blue{Cloning}: start a clone, and set it in the same execution state.
%     \end{itemize}
%   \end{block}
% \end{slide}
% \subsection{Migration in heterogeneous systems}
% \begin{slide}{Migration in heterogeneous systems}
%   \begin{block}{Main problem}
%     \begin{itemize}
%     \item The target machine may not be \blue{suitable to execute the migrated code}
%     \item The definition of process/thread/processor context is \blue{highly dependent on local hardware,
%       operating system and runtime system}
%     \end{itemize}
%   \end{block}
%   \begin{alertblock}{Only solution: abstract machine implemented on different platforms}
%     \begin{itemize}
%     \item Interpreted languages, effectively having their own VM
%     \item Virtual machine monitors
%     \end{itemize}
%   \end{alertblock}
%   \begin{alertblock}{Observation}
%     As containers are directly dependent on the underlying operating system, their migration in heterogeneous
%     environments is far from trivial, to simply impractical, just as process migration is.
%   \end{alertblock}

% \end{slide}
% \begin{slide}{Migrating a virtual machine}
%   \begin{block}{Migrating images: three alternatives}
%     \begin{enumerate}
%     \item Pushing memory pages to the new machine and resending the ones that are later modified during the
%       migration process.
%     \item Stopping the current virtual machine; migrate memory, and start the new virtual machine.
%     \item Letting the new virtual machine pull in new pages as needed: processes start on the new
%       virtual machine immediately and copy memory pages on demand.
%     \end{enumerate}
%   \end{block}
% \end{slide}
%   \begin{slide}{Performance of migrating virtual machines}
%     \begin{block}{Problem}
%       A complete migration may actually take tens of seconds. We also need to realize that during the
%       migration, a service will be completely unavailable for multiple seconds. 
%     \end{block}
%     \begin{block}{Measurements regarding response times during VM migration}
%       \begin{center}
%         \includefigure{03-29} 
%       \end{center}
%     \end{block}
%   \end{slide}
\section{Summary}
\begin{slide}{Summary and Conclusions}
We have discussed processes and threads
in Distributed Systems, namely:
\begin{itemize}
  \item Processes and Threads
  \item Context Switching
  \item Multithreading
  \item Virtualization
  \item Containerization
\end{itemize}  
\end{slide}

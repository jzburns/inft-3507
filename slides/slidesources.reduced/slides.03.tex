\part{Processes, Threads and Virtualization}
\section{Processes, Threads and Virtualization}
\subsection{Introduction to Processes and Threads}
\begin{frame}{Introduction to Processes and Threads}
  \begin{itemize}
    \item \textbf{Definition}: A process is an independent program in execution with its own memory space, while a thread is a lightweight unit of execution within a process, sharing the process's memory.
    \item \textbf{Memory}: A process has its own isolated memory space (address space), whereas threads within the same process share the same memory space, including code, data, and resources.
    \item \textbf{Overhead}: Processes are heavier, requiring more system resources and time for creation and context switching, while threads are lighter, with lower overhead for creation and switching.
    \item \textbf{Communication}: Inter-process communication (IPC) is complex and slower (e.g., pipes, sockets), while threads communicate faster via shared memory but require synchronization (e.g., locks).
  \end{itemize}
\end{frame}
\begin{frame}{Context switching}
  \begin{block}{Observations}
    \begin{enumerate}
      \item Threads share the same address space. Thread context switching
            is much faster than process context switching:
            \begin{enumerate}
              \item only registers and program counter need to be saved and restored
            \end{enumerate}
      \item Process context switching is more expensive (in time and space) as
            \begin{enumerate}
              \item TLB needs to be flushed
              \item page table is reloaded
              \item address space changes
            \end{enumerate}
      \item Creating and destroying threads is much cheaper than doing so for processes.
    \end{enumerate}
  \end{block}
\end{frame}
\begin{frame}{Why use threads}
  \begin{block}{Some simple reasons}
    \begin{itemize}
      \item \textbf{Avoid needless blocking}: a single-threaded process will \red{block} when doing I/O; in a
            multithreaded process, the operating system can switch the CPU to another thread in that process.
      \item \textbf{Exploit parallelism}: the threads in a multithreaded process can be scheduled to run in
            parallel on a multiprocessor or multicore processor.
      \item \textbf{Avoid process switching}: structure large applications not as a collection of processes, but
            through multiple threads.
    \end{itemize}
  \end{block}
\end{frame}
\begin{frame}{Avoid process switching}
  \begin{block}{Avoid expensive context switching}
    \begin{centerfig}
      \includefigure{03-01}
    \end{centerfig}
  \end{block}
  \begin{block}{Trade-offs}
    \begin{itemize}
      \item Threads use the same address space: more prone to errors
      \item No support from OS/HW to protect threads using each other's memory
      \item Thread context switching may be faster than process context switching
    \end{itemize}
  \end{block}
\end{frame}
\begin{frame}{The cost of a context switch}
  Suppose we have a page cache on the CPU with 4 slots. Each
  slot can accommodate one 4k page, associated with
  the instructions for a process (below, A,B,C,D)
  \begin{block}{What a context switch may cause: indirect costs}
    \begin{columns}
      \begin{column}{0.5\textwidth}
        \begin{center}
          \begin{tabular}{c@{\hspace{24pt}}c@{\hspace{24pt}}c}
            \includefigure{03-02a} &
            \includefigure{03-02b} &
            \includefigure[0.184]{03-02c-corrected} \\
            {\hspace{0.6cm}}(a)    & (b) & (c)
          \end{tabular}
        \end{center}
      \end{column}
      \begin{column}{0.5\textwidth}
        \begin{itemize}
          \item[(a)] before the context switch
          \item[(b)] after the context switch
          \item[(c)] after accessing block \idsn{D}.
        \end{itemize}
      \end{column}
    \end{columns}
  \end{block}
\end{frame}

\begin{frame}{Cache Perturbation Hypothesis}
  Ref: "The Context-Switch Overhead Inflicted by
  Hardware Interrupts (and the Enigma of
  Do-Nothing Loops)” by Dan Tsafrir (IBM T.J. Watson
  Research Center), presented at the ACM
  Workshop on Experimental Computer Science (ExpCS ’07)."

  \begin{block}{Experiment}
    \begin{itemize}
      \item A trivial 1 ms loop is repeatedly executed.
      \item Time measurements show perturbations due to interrupts.
      \item Some implementations showed overheads an order of magnitude larger than expected.
    \end{itemize}
  \end{block}

  Hardware counters were insufficient to isolate cause.
  Some effects might involve:

  \begin{itemize}\tightlist
    \item Instruction cache
    \item Data cache
    \item TLB
    \item Branch predictors
  \end{itemize}
  % This is exactly the problem we see in the previous slide
\end{frame}

% \begin{frame}{A simple example in Python}
%   \begin{centerfig}
%     \includelisting{03-03/mp} 
%   \end{centerfig}
%   \begin{tabular}{l}
%     \small\code{40:23 eve is going to sleep for 14 seconds} \\
%     \small\code{40:23 bob is going to sleep for 4 seconds} \\
%     \small\code{40:27 bob has woken up} \\
%     \small\code{40:37 eve has woken up}
%   \end{tabular}
% \end{frame}
% \begin{frame}{A simple example in Python}
%   \begin{centerfig}
%     \includelisting{03-04/mpthread-slide} 
%   \end{centerfig}
% \end{frame}
% \begin{frame}{A simple example in Python}
%   \begin{tabular}{l}
%     \small\code{eve sees shared x being 71} \\
%     \small\code{53:21 eve 0 is going to sleep for 20 seconds} \\
%     \small\code{bob sees shared x being 84} \\
%     \small\code{53:21 eve 1 is going to sleep for 15 seconds} \\
%     \small\code{53:21 eve 2 is going to sleep for 3 seconds} \\
%     \small\code{53:21 bob 0 is going to sleep for 8 seconds} \\
%     \small\code{53:21 bob 1 is going to sleep for 16 seconds} \\
%     \small\code{53:21 bob 2 is going to sleep for 8 seconds} \\
%     \small\code{53:24 eve 2 has woken up, seeing shared x being 72} \\
%     \small\code{53:29 bob 0 has woken up, seeing shared x being 85} \\
%     \small\code{53:29 bob 2 has woken up, seeing shared x being 86} \\
%     \small\code{53:36 eve 1 has woken up, seeing shared x being 73} \\
%     \small\code{53:37 bob 1 has woken up, seeing shared x being 87} \\
%     \small\code{bob sees shared x being 87} \\
%     \small\code{53:41 eve 0 has woken up, seeing shared x being 74} \\
%     \small\code{eve sees shared x being 74} 
%   \end{tabular}
% \end{frame}
\begin{frame}{Thread Switch vs Process Context Switch}
  \begin{columns}[t]

    % Left column: Thread switch
    \begin{column}{0.48\textwidth}
      \textbf{Thread Switch}

      \begin{itemize}
        \item Switch between threads of the \textit{same process}
        \item Address space remains unchanged
        \item Page tables and memory mappings are reused
        \item Faster than process switches
        \item Typically used for concurrency within applications
      \end{itemize}

      \vspace{0.5em}
      \textbf{Overhead:}
      \begin{itemize}
        \item Save/restore registers
        \item Update stack pointer and program counter
      \end{itemize}
    \end{column}

    % Right column: Process switch
    \begin{column}{0.48\textwidth}
      \textbf{Process Context Switch}

      \begin{itemize}
        \item Switch between threads of \textit{different processes}
        \item Address space changes
        \item Page tables must be switched
        \item TLB often flushed or invalidated
        \item Slower than thread switches
      \end{itemize}

      \vspace{0.5em}
      \textbf{Overhead:}
      \begin{itemize}
        \item Save/restore registers
        \item Switch address space
        \item Update memory management state
      \end{itemize}
    \end{column}

  \end{columns}
\end{frame}

\begin{frame}{Threads and operating systems}
  \begin{alertblock}{Main issue}
    Should an OS kernel provide threads, or should they be implemented as user-level packages?
  \end{alertblock}
  \begin{block}{User-space solution}
    \begin{itemize}
      \item All operations can be completely handled \textbf{within a single process} \mathexpr{\Rightarrow}
            implementations can be extremely efficient.
      \item \textbf{All} services provided by the kernel are done \textbf{on behalf of the process in which a thread
              resides} \mathexpr{\Rightarrow} if the kernel decides to block a thread, the entire process will be
            blocked.
      \item Threads are used when there are many external events: \textbf{threads block on a per-event basis}
            \mathexpr{\Rightarrow} if the kernel can't distinguish threads, how can it support signaling events to
            them?
    \end{itemize}
  \end{block}
\end{frame}
\begin{frame}{Linux Kernel Threads}
  \begin{itemize}
    \item \textbf{Task Struct Representation}: In the Linux kernel, threads are implemented as lightweight processes, each represented by a \texttt{task\_struct} (defined in \texttt{include/linux/sched.h}), sharing memory but maintaining separate execution contexts for scheduling.
    \item \textbf{Scheduling with CFS}: The Completely Fair Scheduler (CFS) in \texttt{kernel/sched/fair.c} manages kernel threads, treating them as virtual processors and allocating CPU time fairly using a red-black tree.
    \item \textbf{POSIX Threads Integration}: User-space threads (e.g., via \texttt{pthread\_create}) map to kernel threads, enabling Java’s 1:1 threading model to leverage Linux’s scheduling for efficient concurrency.
  \end{itemize}
\end{frame}
% \begin{frame}{Combining user-level and kernel-level threads}
%   \begin{block}{Basic idea} 
%     Introduce a two-level threading approach: \red{kernel threads} that can execute user-level
%     threads.
%   \end{block}
%   \begin{block}{}
%     \begin{center}
%       \includefigure{03-05}
%     \end{center}
%   \end{block}
% \end{frame}
% \begin{frame}{User and kernel threads combined}
%   \begin{block}{Principle operation}
%     \begin{itemize}%\tightlist
%     \item User thread does system call \mathexpr{\Rightarrow} \red{the kernel thread that is
%       executing that user thread, blocks}. The user thread remains \textbf{bound} to the kernel thread.
%     \item The kernel can \red{schedule another kernel thread having a runnable user thread bound to
%       it}. Note: this user thread can switch to \textbf{any} other runnable user thread currently in user
%       space.
%     \item A user thread calls a blocking user-level operation \mathexpr{\Rightarrow} do context switch
%       to a runnable user thread, (then bound to the same kernel thread).
%     \item When there are no user threads to schedule, a kernel thread may remain idle, and may even be
%       removed (destroyed) by the kernel.
%     \end{itemize}
%   \end{block}
% \end{frame}
\subsection{Threads in distributed systems}
\begin{frame}{Using threads at the client side}
  \begin{block}{Multithreaded web client}
    Hiding network latencies:
    \begin{itemize}\tightlist
      \item Web browser scans an incoming HTML page, and finds that \textbf{more files need to be fetched}.
      \item \textbf{Each file is fetched by a separate thread}, each doing a (blocking) HTTP request.
      \item As files come in, the browser displays them.
    \end{itemize}
  \end{block}
  \begin{block}{Multiple request-response calls to other machines (RPC)}
    \begin{itemize}\tightlist
      \item A client does several calls at the same time, each one by a different thread.
      \item It then waits until all results have been returned.
      \item Note: if calls are to different servers, we may have a \textbf{linear speed-up}.
    \end{itemize}
  \end{block}
\end{frame}
\begin{frame}{Multithreaded clients: does it help?}
  \begin{block}{Thread-level parallelism: TLP}
    Let \mathexpr{c_i} denote the fraction of time that exactly \mathexpr{i} threads are being executed
    simultaneously.
    \[ TLP = \frac{\sum_{i=1}^N i \cdot c_i}{1- c_0} \]
    with \mathexpr{N} the maximum number of threads that (can) execute at the same time.
  \end{block}
  \onslide
  \begin{block}{Practical measurements}
    A typical Web browser has a TLP value between 1.5 and 2.5 \mathexpr{\Rightarrow} threads are primarily
    used for \textbf{logically organizing} browsers.
  \end{block}
\end{frame}
\begin{frame}{Using threads at the server side}
  \begin{block}{Improve performance}
    \begin{itemize}\tightlist
      \item Starting a thread is cheaper than starting a new process.
      \item Having a single-threaded server prohibits simple scale-up to a \textbf{multiprocessor system}.
      \item As with clients: \textbf{hide network latency} by reacting to next request while previous one is being replied.
    \end{itemize}
  \end{block}
  \begin{block}{Better structure}
    \begin{itemize}\tightlist
      \item Most servers have high I/O demands. Using simple, \textbf{well-understood blocking calls} simplifies
            the structure.
      \item Multithreaded programs tend to be \textbf{smaller and easier to understand} due to \textbf{simplified
              flow of control}.
    \end{itemize}
  \end{block}
\end{frame}
\begin{frame}{Why multithreading is popular: organization}
  \begin{block}{Dispatcher/worker model}
    \begin{center}
      \includefigure{03-06}
    \end{center}
  \end{block}
  \begin{block}{Overview}
    \begin{center}
      \begin{tabular}{|l|l|}\hline
        Multithreading          & Parallelism, blocking system calls    \\ \hline
        Single-threaded process & No parallelism, blocking system calls \\ \hline
      \end{tabular}
    \end{center}
  \end{block}
\end{frame}
\section{Virtualization}
\subsection{Principle of virtualization}
% \begin{frame}{Virtualization}
%   \begin{block}{Privileged instructions}
%     Privileged instructions: allowed to be executed only by the kernel.
%   \end{block}
%   \begin{itemize}\tightlist
%     \item Equivalence: Virtual machines (VMs) provide an environment
%           identical to physical hardware, ensuring software runs unmodified.
%     \item Resource Control: The virtual machine monitor (VMM)
%           maintains full control over system resources, preventing VMs from accessing unauthorized resources.
%     \item Efficiency: Most instructions execute directly on
%           hardware for near-native performance, with sensitive instructions trapped by the VMM.
%     \item Isolation: VMs are fully isolated, ensuring no
%           interference or data leaks between VMs or the VMM, using mechanisms like memory and I/O virtualization.
%   \end{itemize}
% \end{frame}
% % \begin{frame}{Mimicking interfaces}
% %   \begin{block}{Four types of interfaces at three different levels}
% %     \begin{enumerate}\tightlist
% %     \item \red{Instruction set architecture}: the set of machine instructions, with two subsets:
% %       \begin{itemize}\tightlist
% %       \item Privileged instructions: allowed to be executed only by the operating system.
% %       \item General instructions: can be executed by any program.
% %       \end{itemize}
% %     \item \red{System calls} as offered by an operating system.
% %     \item \red{Library calls}, known as an \red{application programming interface} (API)
% %     \end{enumerate}
% %   \end{block}
% % \end{frame}
% \begin{frame}[fragile]{Three Virtualization Approaches}
%   \begin{center}
%     % \begin{tabular}{ccc}
%     %   \includefigure{03-10a} &
%     %   \includefigure{03-10b} &
%     %   \includefigure{03-10c} \\
%     %   \textbf{(a) Process VM} & \textbf{(b) Native VMM} & \textbf{(c) Hosted VMM}
%     % \end{tabular}
%     \begin{verbatim}
% (a) Process VM           (b) Native VMM           (c) Hosted VMM
% ------------------       ------------------       ------------------
%  Application             Application              Application
%  ------------------      ------------------       ------------------
%  Runtime system          Guest OS                 Guest OS
%  (e.g. JVM)              ------------------       ------------------
%  ------------------      Native VMM               Hosted VMM
%  Host Operating          (Type 1 hypervisor)      (Type 2 hypervisor)
%  System                  ------------------       ------------------
%  ------------------      Hardware                 Host Operating System
%  Hardware                                         ------------------
%                                                   Hardware                                                 
% \end{verbatim}
%   \end{center}
%   \begin{block}{Differences}
%     \begin{itemize}\tightlist
%       \item[(a)] Separate set of instructions, an interpreter/emulator, running atop an OS.
%       \item[(b)] Low-level instructions, along with bare-bones minimal operating system
%       \item[(c)] Low-level instructions, but delegating most work to a full-fledged OS.
%     \end{itemize}
%   \end{block}
% \end{frame}

% \begin{frame}{VM Performance}
%   \begin{block}{Refining the organization}
%     \begin{tabular}{@{}ll}
%       \includefigure[0.71]{03-11}
%       \begin{minipage}[b]{0.4\textwidth}
%         \begin{itemize}\tightlist
%           \item \red{Privileged instruction}: if and only if executed in user mode, it causes a \textbf{trap}
%                 to the operating system
%           \item \red{Nonpriviliged instruction}: the rest
%         \end{itemize}
%       \end{minipage}
%     \end{tabular}
%   \end{block}
%   \begin{block}{Special instructions}
%     \begin{itemize}
%       \item \red{Control-sensitive instruction}: may affect configuration of a machine (e.g., one affecting
%             relocation register or interrupt table).
%       \item \red{Behavior-sensitive instruction}: effect is partially determined by context (e.g., \code{POPF}
%             sets an interrupt-enabled flag, but only in system mode).
%     \end{itemize}
%   \end{block}
% \end{frame}
% \begin{frame}{Popek and Goldberg: Condition for virtualization}
%   \begin{alertblock}{Necessary condition}
%     \itshape For any conventional computer, a virtual machine monitor may be constructed if the set of
%     sensitive instructions for that computer is a subset of the set of privileged instructions.
%   \end{alertblock}
%   \begin{block}{Problem: condition is not always satisfied}
%     There may be sensitive instructions that are executed in user mode without causing a trap to the
%     operating system.
%   \end{block}
%   \begin{block}{Solutions}
%     \begin{itemize}
%       \item Emulate all instructions
%       \item Wrap nonprivileged sensitive instructions to divert control to VMM
%       \item \textbf{Paravirtualization}: modify guest OS, either by preventing nonprivileged sensitive
%             instructions, or making them nonsensitive (i.e., changing the context).
%     \end{itemize}
%   \end{block}
% \end{frame}



\begin{frame}{Scope and Terminology}
  \begin{itemize}
    \item \textbf{System virtualization:} presents a virtual hardware platform capable of running an OS
    \item \textbf{Process virtualization:} presents a virtual execution environment for a single program (e.g., a managed runtime)
    \item \textbf{Emulation:} reproduces an ISA and/or device behavior in software
    \item \textbf{Hypervisor / VMM:} software layer(s) that create and isolate system VMs
  \end{itemize}

  \vspace{0.4em}
  \begin{block}{Goal}
    Provide isolation and controllable sharing of CPU, memory, and I/O while preserving expected software semantics.
  \end{block}
\end{frame}

%------------------------------------------------
\begin{frame}{Execution Virtualization Spectrum}
  \begin{itemize}
    \item \textbf{Emulation} (ISA/device reproduction): maximizes compatibility across architectures, typically higher overhead
    \item \textbf{Process VM} (language/bytecode runtime): portability and safety for applications, not a full OS boundary
    \item \textbf{System VM} (hypervisor-based): strong isolation and full OS virtualization
  \end{itemize}

  \vspace{0.4em}
  \begin{block}{Key distinction}
    Process VMs virtualize a \emph{program execution model}; hypervisors virtualize a \emph{machine interface}.
  \end{block}
\end{frame}

%------------------------------------------------
\begin{frame}{Diagram: Taxonomy of Virtualization Approaches}
  \begin{tikzpicture}[
      box/.style={draw, rectangle, rounded corners=2pt, line width=0.7pt,
          minimum width=9cm, minimum height=1.0cm, align=left, inner sep=6pt},
      arrow/.style={-Latex, line width=0.8pt},
      node distance=6mm
    ]
    \node[box] (emu) {\textbf{Emulation}\\
      \(\bullet\) Virtualizes an ISA and/or devices in software\\
      \(\bullet\) Primary benefit: cross-architecture compatibility};

    \node[box, below=of emu] (pvm) {\textbf{Process Virtual Machine (e.g., JVM)}\\
      \(\bullet\) Virtualizes an application execution model (bytecode + runtime services)\\
      \(\bullet\) Primary benefit: portability, safety properties, managed services};

    \node[box, below=of pvm] (svm) {\textbf{System Virtual Machine (Hypervisor / VMM)}\\
      \(\bullet\) Virtualizes CPU, memory, and devices to run an unmodified OS\\
      \(\bullet\) Primary benefit: strong isolation and resource control at machine granularity};

    % A light grouping annotation
    \node[draw, dashed, very thick, rounded corners=2pt,
      fit=(pvm), inner sep=7pt] (pvmfit) {};
    \node[anchor=west] at ([xshift=2mm]pvmfit.east) {\footnotesize program boundary};

    \node[draw, dashed, very thick, rounded corners=2pt,
      fit=(svm), inner sep=7pt] (svmfit) {};
    \node[anchor=west] at ([xshift=2mm]svmfit.east) {\footnotesize OS boundary};

  \end{tikzpicture}

  \vspace{0.6em}
  \small
  \textbf{Figure:} Conceptual taxonomy. Emulation targets compatibility, process VMs target portable execution for programs,
  and system VMs target full OS virtualization and isolation.
\end{frame}

%------------------------------------------------
\begin{frame}{System VMs: Type 1 and Type 2 Hypervisors}
  \begin{itemize}
    \item \textbf{Type 1 (bare-metal):} hypervisor runs directly on hardware, commonly with a privileged management domain
    \item \textbf{Type 2 (hosted):} hypervisor/VMM runs atop a general-purpose host OS and leverages host drivers/services
  \end{itemize}

  \vspace{0.4em}
  \begin{block}{Engineering focus}
    The practical security boundary is determined by the \textbf{trusted computing base (TCB)}: what must be trusted for isolation.
  \end{block}
\end{frame}

%------------------------------------------------
\begin{frame}{Diagram: Type 1 vs Type 2 Stack Organization}
  \centering
  \begin{tikzpicture}[
      layer/.style={draw, rectangle, rounded corners=2pt, line width=0.7pt,
          minimum width=5.6cm, minimum height=0.85cm, align=center},
      arrow/.style={-Latex, line width=0.8pt},
      tcb/.style={draw, dashed, very thick, rounded corners=2pt, inner sep=6pt},
      node distance=4mm
    ]

    % --- Left: Type 1 ---
    \node at (-3.4,4.2) {\textbf{Type 1 (Bare-metal)}};

    \node[layer] (t1a) at (-3.4,3.4) {Guest Apps};
    \node[layer] (t1g) at (-3.4,2.45) {Guest OS};
    \node[layer] (t1v) at (-3.4,1.50) {VMM / Device Model};
    \node[layer] (t1h) at (-3.4,0.55) {Hypervisor Core};
    \node[layer] (t1p) at (-3.4,-0.40) {Hardware};

    \draw[arrow] (t1a) -- (t1g);
    \draw[arrow] (t1g) -- (t1v);
    \draw[arrow] (t1v) -- (t1h);
    \draw[arrow] (t1h) -- (t1p);

    \node[tcb, fit=(t1v)(t1h)] (t1tcb) {};
    \node[anchor=west] at ([xshift=-1mm]t1tcb.east) {\small TCB};

    % --- Right: Type 2 ---
    \node at (3.4,4.2) {\textbf{Type 2 (Hosted)}};

    \node[layer] (t2a) at (3.4,3.4) {Guest Apps};
    \node[layer] (t2g) at (3.4,2.45) {Guest OS};
    \node[layer] (t2v) at (3.4,1.50) {VMM / Hypervisor Module};
    \node[layer] (t2o) at (3.4,0.55) {Host OS (drivers, services)};
    \node[layer] (t2p) at (3.4,-0.40) {Hardware};

    \draw[arrow] (t2a) -- (t2g);
    \draw[arrow] (t2g) -- (t2v);
    \draw[arrow] (t2v) -- (t2o);
    \draw[arrow] (t2o) -- (t2p);

    \node[tcb, fit=(t2v)(t2o)] (t2tcb) {};
    \node[anchor=west] at ([xshift=2mm]t2tcb.east) {\small TCB};

  \end{tikzpicture}

  \vspace{0.6em}
  \small
  \textbf{Figure:} Representative stack organizations. In Type~2 systems, the host OS becomes part of the trusted base for isolation.
\end{frame}

%------------------------------------------------
\begin{frame}{Emulation vs Hypervisor-Based Virtualization}
  \begin{itemize}
    \item \textbf{Emulation:} can execute software for a different ISA; overhead arises from instruction translation and device modeling
    \item \textbf{System VM with hardware assist:} guest code runs largely natively; overhead concentrates in traps/exits and I/O paths
    \item \textbf{Process VM (e.g., JVM):} does not virtualize devices or privileged CPU state; relies on the host OS for isolation
  \end{itemize}

  \vspace{0.4em}
  \begin{block}{Implication}
    ISA portability and OS-level isolation are different objectives; they are frequently conflated but have different mechanisms and costs.
  \end{block}
\end{frame}

%------------------------------------------------
\begin{frame}{Resource Control: CPU and Memory}
  \begin{block}{CPU control concepts}
    \begin{itemize}
      \item \textbf{Capacity:} number of vCPUs and their mapping to physical CPUs
      \item \textbf{Shares/weights:} proportional allocation under contention
      \item \textbf{Limits/caps:} enforce maximum CPU usage (often expressed as a percentage of a core set)
      \item \textbf{Reservations:} minimum guaranteed CPU capacity (where supported)
    \end{itemize}
  \end{block}

  \begin{block}{Memory control concepts}
    \begin{itemize}
      \item \textbf{Static limit:} maximum assigned memory for a VM
      \item \textbf{Ballooning:} cooperative reclamation from guests to enable overcommit
      \item \textbf{Swapping/reclamation:} provider-side memory pressure mechanisms (risk of latency inflation)
    \end{itemize}
  \end{block}
\end{frame}

%------------------------------------------------
\begin{frame}{Diagram: Resource Allocation and Enforcement Points}
  \begin{tikzpicture}[
      box/.style={draw, rectangle, rounded corners=2pt, line width=0.7pt,
          minimum width=9.0cm, minimum height=0.9cm, align=left, inner sep=6pt},
      smallbox/.style={draw, rectangle, rounded corners=2pt, line width=0.7pt,
          minimum width=5.8cm, minimum height=0.85cm, align=left, inner sep=6pt},
      arrow/.style={-Latex, line width=0.8pt},
      node distance=6mm
    ]

    \node[box] (vm) {\textbf{Virtual Machine}\\
      \(\bullet\) configured: vCPUs, CPU cap/share; memory limit/reservation\\
      \(\bullet\) observed: CPU utilization, run-queue delay; memory pressure indicators};

    \node[smallbox, below=of vm, xshift=-3.1cm] (cpu) {\textbf{CPU Scheduler (Hypervisor)}\\
      \(\bullet\) enforces shares and caps\\
      \(\bullet\) maps vCPUs \(\rightarrow\) pCPUs};

    \node[smallbox, below=of vm, xshift=3.1cm] (mem) {\textbf{Memory Manager (Hypervisor)}\\
      \(\bullet\) enforces memory limits\\
      \(\bullet\) ballooning / reclamation};

    \node[box, below=of cpu, yshift=-2mm] (hw) {\textbf{Hardware Resources}\\
      \(\bullet\) physical cores, caches; DRAM; IOMMU/device DMA constraints};

    \draw[arrow] (vm.south) -- (cpu.north);
    \draw[arrow] (vm.south) -- (mem.north);
    \draw[arrow] (cpu.south) -- (hw.north);
    \draw[arrow] (mem.south) -- (hw.north);

  \end{tikzpicture}

  \vspace{0.6em}
  \small
  \textbf{Figure:} Enforcement points for CPU and memory control. Allocation policies are implemented by the hypervisor scheduler
  and memory manager, which multiplex physical resources across VMs.
\end{frame}

%------------------------------------------------
\begin{frame}{Concrete Control Examples (CPU \% and Memory \%)}
  \begin{block}{CPU}
    \begin{itemize}
      \item \textbf{CPU cap (percentage):} limit a VM to (e.g.) \(60\%\) of one core or \(240\%\) of a 4-core entitlement
      \item \textbf{Shares/weights:} if two VMs have weights \(2{:}1\), they receive that proportion under contention
      \item \textbf{Pinning/affinity:} restrict vCPUs to selected cores to control interference and improve predictability
    \end{itemize}
  \end{block}

  \begin{block}{Memory}
    \begin{itemize}
      \item \textbf{Memory limit:} hard upper bound on guest-usable memory
      \item \textbf{Reservation:} minimum memory intended to remain available (platform-dependent)
      \item \textbf{Overcommit with ballooning:} reclaim unused guest pages before swapping at the host
    \end{itemize}
  \end{block}
\end{frame}

%------------------------------------------------
\begin{frame}{Summary}
  \begin{itemize}
    \item Emulation, process VMs, and hypervisors address different requirements and expose different boundaries
    \item Type~1 and Type~2 hypervisors differ mainly in where the trusted base resides and how drivers are obtained
    \item Modern platforms treat CPU and memory as first-class, policy-controlled resources: shares, caps, reservations, and limits
  \end{itemize}
\end{frame}

% ------------------------------------------------------------
\begin{frame}{Virtualization and Containers}
  Virtualization is about running workloads as if they had their own machine.

  \medskip
  In Linux container-style virtualization, two kernel features provide most of the illusion:
  \begin{itemize}
    \item \textbf{Namespaces} \(\rightarrow\) \emph{isolation}: ``what you can see''
    \item \textbf{Control groups (cgroups)} \(\rightarrow\) \emph{control}: ``what you can use''
  \end{itemize}

  \medskip
  A \textbf{container} is typically: \textit{namespaces + cgroups} (plus filesystem + tooling).

  If multiple applications share one OS kernel, we want:
  \begin{itemize}
    \item Strong \textbf{separation of views} (processes, network, mounts, hostnames, users)
    \item Predictable \textbf{resource sharing} (CPU, memory, I/O) without one app starving others
  \end{itemize}

  \medskip
  Linux containers achieve this without a hypervisor by virtualizing \emph{interfaces to the kernel}.
\end{frame}

% ------------------------------------------------------------
\begin{frame}{Namespaces: isolation of kernel resources}
  A \textbf{namespace} gives a process a private view of a specific kernel resource.

  \medskip
  Common namespaces:
  \begin{itemize}
    \item \textbf{PID} (process IDs): processes see a different PID tree
    \item \textbf{Mount} (MNT): separate mount table / filesystem view
    \item \textbf{Network} (NET): interfaces, routes, ports isolated
    \item \textbf{UTS}: hostname/domainname isolation
    \item \textbf{IPC}: SysV IPC, POSIX message queues, etc.
    \item \textbf{User} (USER): user/group ID mapping (enables unprivileged containers)
    \item \textbf{Cgroup} namespace: hides cgroup paths
  \end{itemize}
\end{frame}

% ------------------------------------------------------------
\begin{frame}{Control groups (cgroups): accounting and limits}
  \textbf{cgroups} group processes and apply resource \emph{accounting, limits, and prioritization}.

  \medskip
  Typical controls:
  \begin{itemize}
    \item \textbf{CPU}: shares/quotas; prevent CPU hogging
    \item \textbf{Memory}: limits; OOM behavior per group
    \item \textbf{I/O}: throttle block I/O
    \item \textbf{PIDs}: limit number of processes
  \end{itemize}

  \medskip
  Key idea: \textbf{namespaces isolate}; \textbf{cgroups constrain}.
\end{frame}

% ------------------------------------------------------------
\begin{frame}{How they fit together (container model)}
  A container runtime typically:
  \begin{enumerate}
    \item Creates new \textbf{namespaces} for the process (isolation)
    \item Places the process into \textbf{cgroups} (resource governance)
    \item Sets up a root filesystem and mounts (often with overlayfs)
    \item Configures networking (veth pairs, bridges, NAT, etc.)
  \end{enumerate}

  \medskip
  The result: a process that \emph{looks} like it runs on its own system and can be \emph{limited}.
\end{frame}

% ============================================================
% TikZ DIAGRAM SLIDE #1 (own slide + caption)
% ============================================================
\begin{frame}{Diagram: cgroups as a resource governance tree}
  \centering
  \begin{figure}
    \centering
    \begin{tikzpicture}[
        font=\small,
        node distance=10mm,
        box/.style={draw, rounded corners, align=center, inner sep=6pt},
        arrow/.style={-Latex, thick}
      ]
      \node[box] (root) {cgroup root\\\texttt{/sys/fs/cgroup}};
      \node[box, below left=of root, xshift=-6mm] (svcA) {serviceA\\CPU=50\%\\Mem=512MB};
      \node[box, below right=of root, xshift=6mm] (svcB) {serviceB\\CPU=50\%\\Mem=512MB};

      \node[box, below=of svcA] (a1) {proc A1};
      \node[box, below=of a1] (a2) {proc A2};

      \node[box, below=of svcB] (b1) {proc B1};

      \draw[arrow] (root) -- (svcA);
      \draw[arrow] (root) -- (svcB);
      \draw[arrow] (svcA) -- (a1);
      \draw[arrow] (a1) -- (a2);
      \draw[arrow] (svcB) -- (b1);

      \node[draw, dashed, rounded corners, fit=(svcA)(a2), inner sep=6pt, label={[font=\small]above:limits apply to the group}] {};
      \node[draw, dashed, rounded corners, fit=(svcB)(b1), inner sep=6pt] {};
    \end{tikzpicture}
    \caption{Cgroups organize processes into a hierarchy and apply resource limits/accounting per group.}
  \end{figure}
\end{frame}

% ============================================================
% TikZ DIAGRAM SLIDE #2 (own slide + caption)
% ============================================================
\begin{frame}{Diagram: namespaces provide separate ``views''}
  \centering
  \begin{figure}
    \centering
    \begin{tikzpicture}[
        font=\small,
        node distance=8mm,
        box/.style={draw, rounded corners, align=center, inner sep=6pt},
        layer/.style={draw, rounded corners, minimum width=3.5cm, minimum height=0.9cm, align=center},
        arrow/.style={-Latex, thick}
      ]
      \node[box] (host) {Host kernel\\(shared)};

      \node[layer, below=of host] (ns1) {Namespace set for Container 1: \\ PID, NET, MNT, UTS, IPC, USER};
      \node[layer, below=of ns1] (p1) {Processes inside Container 1\\see private PID tree, mounts, hostname, network};

      \node[layer, right=2.2cm of ns1] (ns2) {Namespace set for Container 2: \\PID, NET, MNT, UTS, IPC, USER};
      \node[layer, below=of ns2] (p2) {Processes inside Container 2\\see a different private view};

      \draw[arrow] (host) -- (ns1);
      \draw[arrow] (ns1) -- (p1);

      \draw[arrow] (host) -- (ns2);
      \draw[arrow] (ns2) -- (p2);

      \node[draw, dashed, rounded corners, fit=(ns1)(p1), inner sep=6pt, label={[font=\small]above:Container 1}] {};
      \node[draw, dashed, rounded corners, fit=(ns2)(p2), inner sep=6pt, label={[font=\small]above:Container 2}] {};
    \end{tikzpicture}
    \caption{Namespaces isolate what processes can see; multiple containers can share one kernel while keeping distinct views.}
  \end{figure}
\end{frame}

% ------------------------------------------------------------
\begin{frame}{A simple isolation example with \texttt{unshare}}
  \texttt{unshare} creates new namespaces for a process (and its children).

  \medskip
  We'll demonstrate isolation by creating:
  \begin{itemize}
    \item a new \textbf{UTS namespace} (private hostname)
    \item a new \textbf{PID namespace} (PID 1 inside)
    \item a new \textbf{mount namespace} (private mount table)
    \item optionally a \textbf{user namespace} (run as ``root'' inside without host root)
  \end{itemize}
\end{frame}

% ------------------------------------------------------------
\begin{frame}[fragile]{Example: \texttt{unshare} for a private hostname + PID tree}
  \begin{lstlisting}[style=sh]
# Create new user, mount, UTS, and PID namespaces.
# --map-root-user maps your user to root inside the user namespace.
unshare --user --map-root-user --mount --uts --pid --fork /bin/bash
\end{lstlisting}

  Inside the new shell:
  \begin{lstlisting}[style=sh]
# UTS namespace: hostname is private
hostname container-demo

# PID namespace: this shell's child processes start a new PID tree
echo "my pid:" $$

# Compare process listing (you should see a tiny PID universe)
ps -ef
\end{lstlisting}
\end{frame}

% ------------------------------------------------------------
\begin{frame}[fragile]{Example: mount namespace isolation (private mounts)}
  In the same \texttt{unshare} shell:

  \begin{lstlisting}[style=sh]
# Make mount operations "private" to this namespace
mount --make-rprivate /

# Create a temporary mount only visible here
mkdir -p /tmp/ns-mnt
mount -t tmpfs tmpfs /tmp/ns-mnt

# Observe it exists here:
mount | grep ns-mnt
\end{lstlisting}

  On the host (outside the namespace), that tmpfs mount will not appear in \texttt{mount} output.
\end{frame}

% ------------------------------------------------------------
\begin{frame}{What isolation did we get?}
  From the example:
  \begin{itemize}
    \item \textbf{UTS namespace}: hostname change does not affect the host
    \item \textbf{PID namespace}: processes see a new PID hierarchy (often with PID 1 inside)
    \item \textbf{Mount namespace}: mounts are private to the namespace
    \item \textbf{User namespace}: you can have root-like IDs inside without being host root
  \end{itemize}

  \medskip
  This is the core of container isolation, and it ties directly back to virtualization:\\
  \textbf{virtualize the process's view of the system without virtualizing the hardware.}
\end{frame}

% ------------------------------------------------------------
\subsection{Containers}
\begin{frame}{Containers}
  \begin{centerfig}
    \includefigure{03-12}
  \end{centerfig}

  \begin{itemize}\tightlist
    \item \textbf{Namespaces}: a collection of processes in a container is given their own view of identifiers
    \item \textbf{Union file system:} combine several file systems into a layered fashion with only the highest
          layer allowing for \code{write} operations (and the one being part of a container).
    \item \textbf{Control groups}: resource restrictions can be imposed upon a collection of processes.
  \end{itemize}
\end{frame}

\begin{frame}{Summary}
  \begin{itemize}
    \item Virtualization can be done at different layers: hardware (VMs) vs. OS interfaces (containers).
    \item \textbf{Namespaces} isolate what processes can see (views of kernel resources).
    \item \textbf{cgroups} govern what processes can use (resource limits/accounting).
    \item \texttt{unshare} is a minimal, direct way to see namespace isolation in action.
  \end{itemize}
\end{frame}

\begin{frame}{Virtualization in Cloud Computing}
  Virtualization is the foundational technology that enables modern cloud platforms.

  \medskip
  In cloud computing, virtualization:
  \begin{itemize}
    \item Allows multiple \textbf{virtual machines (VMs)} to run on a single physical server
    \item Provides strong \textbf{isolation} between tenants for security and fault containment
    \item Enables \textbf{elastic resource allocation} (CPU, memory, storage) on demand
    \item Makes infrastructure \textbf{hardware-agnostic}, simplifying scaling and migration
  \end{itemize}

  \medskip
  Cloud providers rely on virtualization to offer Infrastructure-as-a-Service (IaaS), where users deploy full operating systems without managing physical hardware.
\end{frame}

\begin{frame}{Containerization in Cloud Computing}
  Containerization builds on virtualization to improve efficiency and agility.

  \medskip
  In cloud environments, containers:
  \begin{itemize}
    \item Package applications with their dependencies for \textbf{portable deployment}
    \item Share the host kernel, enabling \textbf{higher density} than VMs
    \item Start quickly, supporting \textbf{rapid scaling} and auto-healing services
    \item Integrate naturally with orchestration systems (e.g., Kubernetes)
  \end{itemize}

  \medskip
  As a result, containerization is central to Platform-as-a-Service (PaaS) and microservice-based architectures, enabling fast iteration and efficient use of cloud resources.
\end{frame}

\section{Summary}
\begin{frame}{Summary and Conclusions}
  We have discussed processes and threads
  in Distributed Systems, namely:
  \begin{itemize}
    \item Processes and Threads
    \item Context Switching
    \item Multithreading
    \item Virtualization
    \item Containerization
  \end{itemize}
\end{frame}

\part{Coordination}
% \section{Clock synchronization}
% \subsection{Physical clocks}
% \begin{frame}{Physical clocks}
%   \begin{alertblock}{Problem}
%     Sometimes we simply need the exact time, not just an ordering.
%   \end{alertblock}
%   \begin{block}{Solution: Universal Coordinated Time (UTC)}
%     \begin{itemize}\tightlist
%     \item Based on the number of transitions per second of the cesium 133 atom (pretty accurate).
%     \item At present, the real time is taken as the average of some 50 cesium clocks around the world.
%     \item Introduces a leap second from time to time to compensate that days are getting longer.
%     \end{itemize}
%   \end{block}
%   \begin{block}{Note}
%     UTC is \blue{broadcast} through short-wave radio and satellite. Satellites can give an accuracy of about
%     \mathexpr{\pm 0.5} ms.
%   \end{block}
% \end{frame}
% \subsection{Clock synchronization algorithms}
% \begin{frame}{Clock synchronization}
%   \begin{block}{Precision}
%     The goal is to keep the deviation \blue{between two clocks on any two machines} within a specified bound,
%     known as the \red{precision} \mathexpr{\pi}:
%     \[ \forall t, \forall \id{p},\id{q}: |C_p(t) - C_q(t)| \leq \pi \]
%     with \mathexpr{C_p(t)} the \blue{computed} clock time of machine \id{p} at \blue{UTC time} \mathexpr{t}. 
%   \end{block}
%   \begin{block}{Accuracy}
%     In the case of \red{accuracy}, we aim to keep the clock bound to a value \mathexpr{\alpha}:
%     \[ \forall t, \forall \id{p}: |C_p(t) - t| \leq \alpha \]
%   \end{block}
%   \begin{alertblock}{Synchronization}
%     \begin{itemize}\tightlist
%     \item \red{Internal synchronization}: keep clocks \blue{precise}
%     \item \red{External synchronization}: keep clocks \blue{accurate}
%     \end{itemize}
%   \end{alertblock}
% \end{frame}
% \begin{frame}{Clock drift}
%   \begin{block}{Clock specifications}
%     \begin{itemize}\tightlist
%     \item A clock comes specified with its \red{maximum clock drift rate} \mathexpr{\rho}.
%     \item \mathexpr{F(t)} denotes oscillator frequency of the hardware clock at time \mathexpr{t}
%     \item \mathexpr{F} is the clock's ideal (constant) frequency \mathexpr{\Rightarrow} living up to
%       specifications: 
%       \[ \forall t: (1 - \rho) \leq \frac{F(t)}{F} \leq (1 + \rho) \]
%     \end{itemize}
%   \end{block}
%   \begin{columns}[T]
%     \begin{column}{0.5\textwidth}
%       \begin{block}{Observation}
%         By using hardware interrupts we couple a software clock to the hardware clock, and thus also its clock
%         drift rate:
%         \[ C_p(t) = \frac{1}{F} \int_0^t F(t) dt \Rightarrow \frac{dC_p(t)}{dt} = \frac{F(t)}{F} \]
%         \[ \Rightarrow \blue{\forall t: 1 - \rho \leq \frac{dC_p(t)}{dt} \leq 1 + \rho}\]
%       \end{block}
%     \end{column}
%     \begin{column}{0.45\textwidth}    
%       \begin{block}{Fast, perfect, slow clocks}
%         \begin{centerfig}
%           \includefigure[0.71]{05-04}
%         \end{centerfig}
%       \end{block}
%     \end{column}
%   \end{columns}
% \end{frame}
% \begin{frame}{Detecting and adjusting incorrect times}
%   \begin{block}{Getting the current time from a timeserver}
%     \begin{centerfig}
%       \includefigure{05-05}
%     \end{centerfig}
%   \end{block}
%   \begin{block}{Computing the relative offset \mathexpr{\theta} and delay \mathexpr{\delta}}
%     \red{Assumption}: \mathexpr{\delta T_{req} = T_2 - T_1 \approx T_4 - T_3 = \delta T_{res}}
%     \[
%     \theta = T_3 + \bigl(( T_2 - T_1 ) + ( T_4 - T_3 )\bigr)/{2} - T_4 = \bigl(( T_2 - T_1 ) + ( T_3 - T_4 )\bigr)/{2}
%     \]
%     \[
%     \delta = \bigl((T_4-T_1) - (T_3 -T_2)\bigr)/{2}
%     \]
%   \end{block}
%   
%   \begin{exampleblock}{Network Time Protocol}
%     Collect \mathexpr{(\theta,\delta)} pairs. Choose \mathexpr{\theta} for which associated delay
%     \mathexpr{\delta} was minimal.
%   \end{exampleblock}
% \end{frame}
% \begin{frame}{Reference broadcast synchronization}
%   \begin{block}{Essence}
%     \begin{itemize}\tightlist
%     \item A node broadcasts a reference message \id{m} \mathexpr{\Rightarrow} each receiving node \id{p}
%       records the time \mathexpr{T_{p,m}} that it received \id{m}. 
%     \item \blue{Note}: \mathexpr{T_{p,m}} is read from \id{p}'s local clock. 
%     \end{itemize}
%   \end{block}
%   \begin{columns}[T]
%     \begin{column}{0.5\textwidth}
%       \begin{block}{Problem: averaging will not capture drift \mathexpr{\Rightarrow} use linear regression}
%         \[
%         \begin{array}{ll}
%         \mbox{NO:}  & \func{Offset}[p,q](t) = \frac{\sum_{k=1}^{M} ( T_{p,k} - T_{q,k} )}{M} \\
%         \mbox{YES:} & \func{Offset}[p,q](t) = \alpha t + \beta
%         \end{array}
%         \]
%       \end{block}
%     \end{column}
%     \begin{column}{0.45\textwidth}
%       \begin{block}{RBS minimizes critical path}
%         \begin{center}
%           \includefigure{05-06}
%         \end{center}
%       \end{block}
%     \end{column}
%   \end{columns}
% \end{frame}
% \section{Logical clocks}
% \subsection{Lamport's logical clocks}
% \begin{frame}{The Happened-before relationship}
%   \begin{alertblock}{Issue}
%     What usually matters is not that all processes agree on exactly what time it is, but that they agree on
%     the \red{order in which events occur}. \blue{Requires a notion of ordering}.
%   \end{alertblock}
%   
%   \begin{block}{The \red{happened-before} relation}
%     \begin{itemize}\tightlist
%     \item If \mathexpr{a} and \mathexpr{b} are two events in the same process, and \mathexpr{a} comes before
%       \mathexpr{b}, then \mathexpr{a \rightarrow b}.
%     \item If \mathexpr{a} is the sending of a message, and \mathexpr{b} is the receipt of that message, then
%       \mathexpr{a \rightarrow b}
%     \item If \mathexpr{a \rightarrow b} and \mathexpr{b \rightarrow c}, then \mathexpr{a \rightarrow c}
%     \end{itemize}
%   \end{block}
%   \begin{alertblock}{Note}
%     This introduces a \blue{partial ordering of events} in a system with concurrently operating processes.
%   \end{alertblock}
% \end{frame}
% \begin{frame}{Logical clocks}
%   \begin{alertblock}{Problem}
%     How do we maintain a global view of the system's behavior that is consistent with the happened-before
%     relation?
%   \end{alertblock}
%   
%   \begin{block}{Attach a time\-stamp \mathexpr{C(e)} to each event \mathexpr{e}, satisfying the following properties:}
%     \begin{enumerate}\tightlist
%     \item[\blue{P1}] If \mathexpr{a} and \mathexpr{b} are two events in the same process, and \mathexpr{a
%       \rightarrow b}, then we demand that \mathexpr{C(a) < C(b)}.
%     \item[\blue{P2}] If \mathexpr{a} corresponds to sending a message \id{m}, and \mathexpr{b} to the
%       receipt of that message, then also \mathexpr{C(a) < C(b)}.
%     \end{enumerate}
%   \end{block}
%   
%   \begin{alertblock}{Problem}
%     How to attach a time\-stamp to an event when there's no global clock \mathexpr{\Rightarrow} maintain a
%     \blue{consistent} set of logical clocks, one per process.
%   \end{alertblock}
% \end{frame}
% \begin{frame}{Logical clocks: solution}
%   \begin{block}{Each process \id{P_i} maintains a \blue{local} counter \id{C_i} and adjusts this counter}
%     \begin{enumerate}\tightlist
%     \item For each new event that takes place within \id{P_i}, \id{C_i} is incremented by 1.
%     \item Each time a message \id{m} is \blue{sent} by process \id{P_i}, the message receives a time\-stamp
%       \mathexpr{ts(\id{m}) = \id{C_i}}.
%     \item Whenever a message \mathexpr{m} is \blue{received} by a process \id{P_j}, \id{P_j} adjusts its local
%       counter \id{C_j} to \red{\mathexpr{\max\{\id{C_j}, ts(\id{m})\}}}; then executes step 1 before passing
%       \id{m} to the application.
%     \end{enumerate}
%   \end{block}
%   \begin{block}{Notes}
%     \begin{itemize}\tightlist
%     \item Property \blue{P1} is satisfied by (1); Property \blue{P2} by (2) and (3).
%     \item It can still occur that two events happen at the same time. Avoid this by \blue{breaking ties through
%       process IDs}.
%     \end{itemize}
%   \end{block}
% \end{frame}
% \begin{frame}{Logical clocks: example}
%   \begin{block}{Consider three processes with \red{event counters} operating at different rates}
%     \begin{center}
%       \begin{tabular}{c@{\hspace*{48pt}}c}
%         \includefigure{05-07a} &
%         \includefigure{05-07b} 
%       \end{tabular}
%     \end{center}
%   \end{block}
% \end{frame}
% \begin{frame}{Logical clocks: where implemented}
%   \begin{block}{Adjustments implemented in middleware}
%     \begin{center}
%       \includefigure{05-08}
%     \end{center}
%   \end{block}
% \end{frame}
% \begin{frame}{Example: Totally ordered multicast}
%   \begin{block}{Concurrent updates on a replicated database are seen in the same order everywhere}
%     \begin{itemize}\tightlist
%     \item \id{P_1} adds \dollar 100 to an account (initial value: \dollar 1000)
%     \item \id{P_2} increments account by 1\%
%     \item There are two replicas
%     \end{itemize}
%     \begin{center}
%       \includefigure{05-09}
%     \end{center}
%   \end{block}
%   \begin{block}{Result} 
%     In absence of proper synchronization: \newline replica \#1 \mathexpr{\leftarrow} \dollar 1111, while
%     replica \#2 \mathexpr{\leftarrow} \dollar 1110.
%   \end{block}
% \end{frame}
% \begin{frame}{Example: Totally ordered multicast}
%   \begin{block}{Solution}
%     \begin{itemize}\tightlist
%     \item Process \id{P_i} sends \blue{timestamped message} \id{m_i} to all others. The message itself is put in a
%       local queue \id{queue_i}.
%     \item Any incoming message at \id{P_j} is queued in \id{queue_j}, \blue{according to its timestamp}, and
%       \blue{acknowledged} to every other process.
%     \end{itemize}
%   \end{block}
%   
%   \begin{alertblock}{\id{P_j} passes a message \id{m_i} to its application if:}
%     \begin{itemize}\tightlist
%     \item[(1)] \id{m_i} is at the head of \id{queue_j}
%     \item[(2)] for each process \id{P_k}, there is a message \id{m_k} in \id{queue_j} with a larger
%       timestamp.
%     \end{itemize}
%   \end{alertblock}
%   
%   \begin{block}{Note}
%     We are assuming that communication is \red{reliable} and \red{FIFO ordered}.
%   \end{block}
% \end{frame}
%   \begin{frame}{Lamport's clocks for mutual exclusion}
%     \begin{tabular}{@{\hspace*{1em}}l}
%       \includelisting{05-10/process-book-a}
%     \end{tabular}
%   \end{frame}
%   \begin{frame}{Lamport's clocks for mutual exclusion}
%     \begin{tabular}{@{\hspace*{1em}}l}
%       \includelisting{05-10/process-book-b}
%     \end{tabular}
%   \end{frame}
%   \begin{frame}{Lamport's clocks for mutual exclusion}
%     \begin{block}{Analogy with totally ordered multicast}
%       \begin{itemize}\firmlist
%       \item With totally ordered multicast, all processes build identical queues, delivering messages in the same order
%       \item Mutual exclusion is about agreeing in which order processes are allowed to enter a critical region
%       \end{itemize}
%     \end{block}
%   \end{frame}
% \subsection{Vector clocks}
% \begin{frame}{Vector clocks}
%   \begin{block}{Observation}
%     Lamport's clocks do not guarantee that if \mathexpr{C(a) < C(b)} that \mathexpr{a} \blue{causally
%       preceded} \mathexpr{b}.
%   \end{block}
%   \begin{columns}[T]
%     \begin{column}{0.45\textwidth}
%       \begin{block}{Concurrent message transmission using logical clocks}
%         \begin{centerfig}
%           \includefigure{05-11}
%         \end{centerfig}
%       \end{block}
%     \end{column}
%     \begin{column}{0.5\textwidth}
%       \begin{block}{Observation}
%         Event \mathexpr{a}: \id{m_1} is received at \mathexpr{T = 16}; \newline
%         Event \mathexpr{b}: \id{m_2} is sent at \mathexpr{T = 20}.
%       \end{block}
%       
%       \begin{alertblock}{Note}
%         We \blue{cannot} conclude that \mathexpr{a} causally precedes \mathexpr{b}.
%       \end{alertblock}
%     \end{column}
%   \end{columns}
% \end{frame}
% \begin{frame}{Causal dependency}
%   \begin{block}{Definition}
%     We say that $b$ may causally depend on $a$ if $ts(a) < ts(b)$, with:
%     \begin{itemize}
%     \item for all $k$, $ts(a)[k] \leq ts(b)[k]$ and
%     \item there exists at least one index $k^{\prime}$ for which $ts(a)[k^{\prime}] < ts(b)[k^{\prime}]$ 
%     \end{itemize}
%   \end{block}
%   \begin{block}{Precedence vs.\ dependency}
%     \begin{itemize}
%       \item We say that $a$ causally precedes $b$.
%       \item $b$ \red{may} causally depend on $a$, as there may be information from $a$ that is propagated into
%         $b$.
%     \end{itemize}
%   \end{block}
% \end{frame}
% \begin{frame}{Capturing potential causality}
%   \begin{block}{Solution: each \id{P_i} maintains a vector \id{VC_i}}
%     \begin{itemize}
%     \item \mathexpr{\id{VC_i}[i]} is the local logical clock at process \id{P_i}.
%     \item If \mathexpr{\id{VC_i}[j] = k} then \id{P_i} knows that \mathexpr{k} events have occurred at
%       \id{P_j}.
%     \end{itemize}
%   \end{block}
%   \begin{block}{Maintaining vector clocks}
%     \begin{enumerate}
%     \item Before executing an event, \id{P_i} executes \mathexpr{\id{VC_i}[i] \leftarrow \id{VC_i}[i] + 1}.
%     \item When process \id{P_i} sends a message \id{m} to \id{P_j}, it sets \id{m}'s (vector) timestamp
%       \mathexpr{ts(\id{m})} equal to \id{VC_i} after having executed step 1.
%     \item Upon the receipt of a message \id{m}, process \id{P_j} sets \mathexpr{\id{VC_j}[k] \leftarrow
%       \max\{\id{VC_j}[k], ts(\id{m})[k]\}} for each \mathexpr{k}, after which it executes step 1 and then
%       delivers the message to the application.
%     \end{enumerate}
%   \end{block}
% \end{frame}
% \begin{frame}{Vector clocks: Example}
%   \begin{block}{Capturing potential causality when exchanging messages}
%     \begin{tabular}{@{}cc}
%       \includefigure[0.65]{05-12a} &
%       \includefigure[0.65]{05-12b} \\
%       {\footnotesize (a)} & {\footnotesize (b)}
%     \end{tabular}
%   \end{block}
%   \begin{block}{Analysis}
%     \begin{center}
%       \sffamily\footnotesize
%       \begin{tabular}{|c|c|c|c|c|l|}\hline
%         \textbf{Situation} 
%         & \mathexpr{ts(\id{m_2})} & \mathexpr{ts(\id{m_4})} & \mathexpr{ts(\id{m_2})} & \mathexpr{ts(\id{m_2})} 
%         & \multicolumn{1}{c|}{\textbf{Conclusion}} \\ [-0.75ex]
%         &                         &                        & \mathexpr{<}            & \mathexpr{>} & \\ [-0.75ex] 
%         &                         &                        & \mathexpr{ts(\id{m_4})} & \mathexpr{ts(\id{m_4})} & \\ \whline
%         (a) 
%         & \mathexpr{(2,1,0)}      & \mathexpr{(4,3,0)}     & Yes & No & \id{m_2} may causally precede \id{m_4} \\ \hline
%         (b) 
%         & \mathexpr{(4,1,0)}      & \mathexpr{(2,3,0)}     & No  & No & \id{m_2} and \id{m_4} may conflict \\ \hline
%       \end{tabular}
%     \end{center}
%   \end{block}
% \end{frame}
%   \begin{frame}{Causally ordered multicasting}
%     \begin{block}{Observation}
%       We can now ensure that a message is delivered only if all causally preceding messages have already been
%       delivered.
%     \end{block}
%     \begin{block}{Adjustment} 
%       \id{P_i} increments \mathexpr{\id{VC_i}[i]} only when sending a message, and \id{P_j} ``adjusts''
%       \id{VC_j} when receiving a message (i.e., effectively does not change \mathexpr{\id{VC_j}[j]}).
%     \end{block}
%     
%     \begin{alertblock}{\id{P_j} postpones delivery of \id{m} until:}
%       \begin{enumerate}\tightlist
%       \item \mathexpr{ts(\id{m})[i] = \id{VC_j}[i] + 1}
%       \item \mathexpr{ts(\id{m})[k] \leq \id{VC_j}[k]} for all \mathexpr{k \neq i}
%       \end{enumerate}
%     \end{alertblock}
%   \end{frame}
%   \begin{frame}{Causally ordered multicasting}
%     \begin{block}{Enforcing causal communication}
%       \begin{centerfig}
%         \includefigure{05-13}
%       \end{centerfig}
%     \end{block}
%     
%     \begin{exampleblock}{Example}
%       Take \mathexpr{\id{VC_3} = [0,2,2], ts(\id{m}) = [1,3,0]} from \id{P_1}. What information does \id{P_3}
%       have, and what will it do when receiving \id{m} (from \id{P_1})?
%     \end{exampleblock}
%   \end{frame}
\section{Mutual exclusion}
\subsection{Overview}
\begin{frame}[fragile]{Process Critical Sections}
  \begin{alertblock}{Problem}
    Several processes in a distributed system want exclusive access to 
    some resource - and we want to avoid concurrent access to this
    resource: The processes all have a region of code
    where the concurrency takes place. This is called the 
    \textbf{Critical Section}
  \end{alertblock}  
  \begin{block}{Critical Section}
    A \textbf{critical section} is a code segment within a process (or thread) 
    that accesses or modifies shared resources (e.g., variables, data structures, 
    files, database or devices) and must be executed atomically — as an indivisible 
    unit—by at most one \textbf{one concurrent process or thread} at a time.    
  \end{block}
 \end{frame}
  
 \begin{frame}[fragile]{Mutual exclusion: Example} 
  \begin{verbatim}
    do {
        // Non-critical section (local work, safe for concurrency)
        
        // Entry section (acquire synchronization primitive)
        while (!can_enter_critical_section());  // Busy-wait or block
        
        // *** CRITICAL SECTION ***
        // Shared resource access/modification (e.g., balance += amount;)
        // Must be atomic w.r.t. other threads
        
        // Exit section (release synchronization primitive)
        signal_exit_critical_section();
        
        // Non-critical section
    } while (true);
  \end{verbatim}
\end{frame}

\begin{frame}{Mutual exclusion}
  \begin{block}{Basic solutions}
    \begin{description}
      \item[Permission-based:] A process wanting to enter its critical region, or access a resource, needs
        permission from other processes.
      \item[Token-based:] A token is passed between processes. The one who has the token may proceed in its
        critical region, or pass it on when not interested.
    \end{description}
  \end{block}
\end{frame}
\subsection{A centralized algorithm}
\begin{frame}{Permission-based, centralized}
  \begin{block}{Simply use a coordinator}
    \begin{centerfig}
      \begin{tabular}{ccc}
        \includefigure{05-14a} &
        \includefigure{05-14b} &
        \includefigure{05-14c} \\
        (a) & (b) & (c)
      \end{tabular}
    \end{centerfig}
    \begin{itemize}
    \item[(a)] Process \id{P_1} asks the coordinator for permission to access a shared resource. Permission is
      granted.
    \item[(b)] Process \id{P_2} then asks permission to access the same resource. The coordinator does not reply.
    \item[(c)] When \id{P_1} releases the resource, it tells the coordinator, which then replies to \id{P_2}.
    \end{itemize}
  \end{block}
\end{frame}
\subsection{A distributed algorithm}
\begin{frame}{Mutual exclusion: Ricart \& Agrawala}
  \begin{block}{Acknowledgments are not sent (the caller blocks)}
    Return a response to a request only when:
    \begin{itemize}\tightlist
    \item The receiving process has no interest in the shared resource; or
    \item The receiving process is waiting for the resource, but has lower priority (known through comparison
      of time\-stamps).
    \end{itemize}
    In all other cases, reply is \blue{deferred}, implying some more local administration.
  \end{block}
\end{frame}
\begin{frame}{Mutual exclusion: Ricart \& Agrawala}
  \begin{block}{Example with three processes}
    \begin{center}
      \begin{tabular}{@{}c@{\hspace*{36pt}}c@{\hspace*{36pt}}c@{}}
        \includefigure{05-15a} &
        \includefigure{05-15b} &
        \includefigure{05-15c} \\
        (a) & (b) & (c)
      \end{tabular}
    \end{center}
    \begin{itemize}\tightlist
     \item[(a)] Two processes want to access a shared resource at the same moment.
     \item[(b)] \id{P_0} has the lowest timestamp, so it wins.
     \item[(c)] When process \id{P_0} is done, it sends an \id{OK} also, so \id{P_2} can now go ahead.
    \end{itemize}
  \end{block}
\end{frame}
\subsection{A token-ring algorithm}
\begin{frame}{Mutual exclusion: Token ring algorithm}
  \begin{block}{Essence} 
    Organize processes in a \blue{logical} ring, and let a token be passed between them. The one that holds
    the token is allowed to enter the critical region (if it wants to).
  \end{block}
  \begin{block}{An overlay network constructed as a logical ring with a circulating token}
    \begin{centerfig}
      \includefigure{05-16}
    \end{centerfig}
  \end{block}
\end{frame}
\subsection{A decentralized algorithm}
\begin{frame}{Decentralized mutual exclusion}
  \begin{block}{Principle}
    Assume every resource is replicated \mathexpr{N} times, with each replica having its own coordinator
    \mathexpr{\Rightarrow} access requires a \blue{majority vote} from \mathexpr{m > N/2} coordinators. A
    coordinator always responds immediately to a request.
  \end{block}
  \begin{block}{Assumption} 
    When a coordinator crashes, it will recover quickly, but will have forgotten about permissions it had
    granted.
  \end{block}
\end{frame}
\begin{frame}{Decentralized mutual exclusion}
  \begin{block}{How robust is this system?}
    \begin{itemize}
    \item Let \mathexpr{p = \Delta t / T} be the probability that a coordinator resets during a time interval
      \mathexpr{\Delta t}, while having a lifetime of \mathexpr{T}.
    \item The probability \mathexpr{\mathbb{P}[k]} that
    \mathexpr{k} out of \mathexpr{m} coordinators reset during the same interval is
    \[
    \mathbb{P}[k] = \binom{m}{k} p^k (1 - p)^{m-k}
    \]
    \item for \mathexpr{m > N/2}, if \mathexpr{f} coordinators reset \mathexpr{\Rightarrow} \blue{correctness is violated when there is
      only a minority of nonfaulty coordinators}: when \red{\mathexpr{N-(m-f) \geq m}}, or, \red{\mathexpr{f
        \geq 2m-N}}.
    \item The probability of a violation is \mathexpr{\sum_{k=2m-N}^m \mathbb{P}[k]}.
    \end{itemize}
  \end{block}
\end{frame}
\begin{frame}{Decentralized mutual exclusion}
  \begin{block}{Violation probabilities for various parameter values}
    \begin{center}
      \small\footnotesize
      \renewcommand{\arraystretch}{1.1}
      \begin{tabular}{cc}
        \begin{minipage}{0.4\textwidth}
          \[
          \begin{array}{|c|c|c|c|}\hline
            \mathbf{N}  & \mathbf{m} & \mathbf{p}        & \mbox{\textbf{Violation}} \\ \whline
            8           & 5          & \mbox{3 sec/hour} & < 10^{-5} \\ \hline
            8           & 6          & \mbox{3 sec/hour} & < 10^{-11} \\ \hline
            16          & 9          & \mbox{3 sec/hour} & < 10^{-4} \\ \hline
            16          & 12         & \mbox{3 sec/hour} & < 10^{-21} \\ \hline
            32          & 17         & \mbox{3 sec/hour} & < 10^{-4} \\ \hline
            32          & 24         & \mbox{3 sec/hour} & < 10^{-43} \\ \hline
          \end{array}
          \]
        \end{minipage} &
        \begin{minipage}{0.4\textwidth}
          \[
          \begin{array}{|c|c|c|c|}\hline
            \mathbf{N}  & \mathbf{m} & \mathbf{p}        & \mbox{\textbf{Violation}} \\ \whline
            8           & 5          & \mbox{30 sec/hour} & < 10^{-3} \\ \hline
            8           & 6          & \mbox{30 sec/hour} & < 10^{-7} \\ \hline
            16          & 9          & \mbox{30 sec/hour} & < 10^{-2} \\ \hline
            16          & 12         & \mbox{30 sec/hour} & < 10^{-13} \\ \hline
            32          & 17         & \mbox{30 sec/hour} & < 10^{-2} \\ \hline
            32          & 24         & \mbox{30 sec/hour} & < 10^{-27} \\ \hline
          \end{array}
          \]
        \end{minipage} 
      \end{tabular}
    \end{center}
  \end{block}
  \begin{alertblock}{So}
    What can we conclude?
  \end{alertblock}
\end{frame}
  \begin{frame}{Mutual exclusion: comparison}
    \begin{block}{}
      \begin{center}
        \footnotesize
        \renewcommand{\arraystretch}{1.2}
        \begin{tabular}{|l|l|l|} \hline
                             & \textbf{Messages per}      & \textbf{Delay before entry} \\ 
          \textbf{Algorithm} & \textbf{entry/exit}        & \textbf{(in message times)} \\ \whline
          Centralized   & 3                               & 2                       \\ \hline
          Distributed   & \mathexpr{2(N-1)}         & \mathexpr{2(N-1)} \\ \hline
          Token ring    & \mathexpr{1,\ldots,\infty}      & \mathexpr{0,\ldots,N-1} \\ \hline
          Decentralized & \mathexpr{2kN + (k-1)N/2 + N, k = 1,2,\ldots}
                        & \mathexpr{2kN + (k-1)N/2}        \\ \hline
        \end{tabular}
      \end{center}
    \end{block}
    Decentralized Case messages per entry/exit for \mathexpr{k \ge 1} attempts:
    \begin{itemize}\firmlist
      \item send \mathexpr{N} messages to coordinators receive N responses. 
      \item If it does not get a majority, release \mathexpr{N/2} votes. 
      \item If it did get enough votes, send \mathexpr{N} release messages later. 
      \item A process may need to go through \mathexpr{k \ge 1} attempts
    \end{itemize}
  \end{frame}
\subsection{Example: Simple locking with ZooKeeper}
\begin{frame}{Example: ZooKeeper}
  \begin{block}{Basics (and keeping it simple)}
    \begin{itemize}\firmlist
    \item Centralized server setup
    \item Distributed Nodes
    \item All client-server communication is \blue{nonblocking}: a client immediately gets a response
    \item ZooKeeper maintains a \blue{tree-based namespace}, akin to that of a filesystem
    \item Clients can \blue{create}, \blue{delete}, or \blue{update} nodes, as well as \blue{check existence}. 
    \end{itemize}
  \end{block}
\end{frame}
\begin{frame}{ZooKeeper versioning}
  \begin{centerfig}
    \includefigure{05-19}
  \end{centerfig}

  \begin{block}{Notations}
    \begin{itemize}\firmlist
    \item \red{\id{W(n,k)a}}: request to write \id{a} to node \id{n}, assuming current version is \id{k}.
    \item \red{\id{R(n,k)}}: current version of node \id{n} is \id{k}. 
    \item \red{\id{R(n)}}: client wants to know the current value of node \id{n}
    \item \red{\id{R(n,k)a}}: value \id{a} from node \id{n} is returned with its current version \id{k}.
    \end{itemize}
  \end{block}
\end{frame}
\begin{frame}{ZooKeeper locking protocol}
  \begin{block}{It is now very simple}
    \begin{enumerate}\firmlist
    \item \red{lock}: A client \id{C_1} creates a node \id{/lock}.
    \item \red{lock}: A client \id{C_2} wants to acquire the lock but is notified that the associated node
      already exists \mathexpr{\Rightarrow} \id{C_2} subscribes to notification on changes of \id{/lock}.
    \item \red{unlock}: Client \id{C_1} deletes node \id{/lock} \mathexpr{\Rightarrow} all subscribers to
      changes are notified.
    \end{enumerate}

    
  \end{block}
\end{frame}
\section{Election algorithms}
\begin{frame}{Election algorithms}
  \begin{block}{Principle} 
    An algorithm requires that some process acts as a coordinator. The question is how to select this special
    process \blue{dynamically}.
  \end{block}
  \begin{block}{Note} 
    In many systems, the coordinator is chosen manually (e.g.,\ file servers). This leads to centralized
    solutions \mathexpr{\Rightarrow} single point of failure.
  \end{block}
  \begin{block}{Teasers}
    \begin{enumerate}
    \item If a coordinator is chosen dynamically, to what extent can we speak about a centralized or
      distributed solution? 
      % Having a central coordinator does not necessarily make an algorithm nondistributed
    \item Is a fully distributed solution, i.e.\ one without a coordinator, always more robust than any
      centralized/coordinated solution?
      % Fully distributed solutions are not necessarily better (think of Ricart-Agrawala)
    \end{enumerate}
  \end{block}
\end{frame}
\begin{frame}{Basic assumptions}
  \begin{block}{}
    \begin{itemize}
    \item All processes have unique id's
    \item All processes know id's of all processes in the system (but not if they are up or down)
    \item Election means identifying the process with the highest id that is up
    \end{itemize}
  \end{block}
\end{frame}
\subsection{The bully algorithm}
\begin{frame}{Election by bullying}
  \begin{block}{Principle}
    Consider \mathexpr{N} processes \mathexpr{\{\id{P_0},\ldots,\id{P_{N-1}}\}} and let
    \mathexpr{id(\id{P_k}) = k}. When a process \id{P_k} notices that the coordinator is no longer responding to
    requests, it initiates an election:
    \begin{enumerate}
    \item \id{P_k} sends an \id{ELECTION} message to all processes with higher identifiers:
      \mathexpr{\id{P_{k+1}},\id{P_{k+2}},\ldots,\id{P_{N-1}}}. 
    \item If no one responds, \id{P_k} wins the election and becomes coordinator.
    \item If one of the higher-ups answers, it takes over and \mathexpr{P_k}'s job is done.
    \end{enumerate}
  \end{block}
\end{frame}
\begin{frame}{Election by bullying}
  \begin{block}{The bully election algorithm}
    \begin{center}
      \begin{tabular}{ccc}
        \includefigure[0.71]{05-20a} &
        \includefigure[0.71]{05-20b} &
        \includefigure[0.71]{05-20c} 
      \end{tabular}
      \begin{tabular}{c@{\hspace*{48pt}}c}
        \includefigure[0.71]{05-20d} &
        \includefigure[0.71]{05-20e} 
      \end{tabular}
    \end{center}
    %% \begin{itemize}\tightlist
    %%   \item[(a)] Process 4 holds an election
    %%   \item[(b)] Processes 5  and 6 respond, telling 4 to stop
    %%   \item[(c)] Now 5 and 6 each hold an election.
    %%   \item[(d)] Process 6 tells 5 to stop.
    %%   \item[(e)] Process 6 wins and tells everyone.  
    %% \end{itemize}
  \end{block}
\end{frame}
\subsection{A ring algorithm}
\begin{frame}{Election in a ring}
  \begin{block}{Principle}
    Process priority is obtained by organizing processes into a (logical) ring. The process with the highest
    priority should be elected as coordinator.
    \begin{itemize}
    \item Any process can start an election by sending an election message to its successor. If a successor is
      down, the message is passed on to the next successor.
    \item If a message is passed on, the sender adds itself to the list. When it gets back to the initiator,
      everyone had a chance to make its presence known.
    \item The initiator sends a coordinator message around the ring containing a list of all living
      processes. The one with the highest priority is elected as coordinator.
    \end{itemize}
  \end{block}
\end{frame}
\begin{frame}{Election in a ring}
  \begin{block}{Election algorithm using a ring}
    \begin{center}
      \includefigure{05-21}
    \end{center}
    \begin{itemize}
    \item The solid line shows the election messages initiated by \id{P_6}
    \item The dashed one, the messages by \id{P_3}
    \end{itemize}
  \end{block}
\end{frame}
\subsection{Example: Leader election in ZooKeeper}
\begin{frame}{Example: Leader election \red{in} ZooKeeper server group}
  \begin{block}{Basics}
    \begin{itemize}\firmlist
    \item Each server \id{s} in the server group has an identifier \blue{\func{id}(\id{s})}
    \item Each server has a monotonically increasing counter \blue{\func{tx}(\id{s})} of the latest transaction it
      handled (i.e., series of operations on the namespace).
    \item When follower \id{s} suspects leader crashed, it broadcasts an \id{ELECTION} message, along with the pair
      (\id{voteID},\id{voteTX}). Initially,
      \begin{itemize}\firmlist
      \item \mathexpr{\id{voteID} \leftarrow \func{id}(\id{s})}
      \item \mathexpr{\id{voteTX} \leftarrow \func{tx}(\id{s})}
      \end{itemize}
    \item Each server \id{s} maintains two variables:
      \begin{itemize}
      \item \blue{\func{leader}(\id{s})}: records the server that \id{s} believes may be final
        leader. \newline
        Initially, \mathexpr{\func{leader}(\id{s}) \leftarrow \func{id}(\id{s})}.
      \item \blue{\func{lastTX}(\id{s})}: what \id{s} knows to be the most recent transaction. \newline
        Initially, \mathexpr{\func{lastTX}(\id{s}) \leftarrow \func{tx}(\id{s})}.
      \end{itemize}
    \end{itemize}
  \end{block}
\end{frame}
\begin{frame}{Example: Leader election \red{in} ZooKeeper server group}
  \begin{block}{When \id{s^*} receives (\id{voteID},\id{voteTX})}
    \begin{itemize}%\firmlist

    \item If \mathexpr{\func{lastTX}(\id{s^*}) < \id{voteTX}}, then \id{s^*} just received more up-to-date
      information on the most recent transaction, and sets
      \begin{itemize}\firmlist
      \item \mathexpr{\func{leader}(\id{s^*}) \leftarrow \id{voteID}}
      \item \mathexpr{\func{lastTX}(\id{s^*}) \leftarrow \id{voteTX}}
      \end{itemize}

    \item If \mathexpr{\func{lastTX}(\id{s^*}) = \id{voteTX}} \emph{and} \mathexpr{\func{leader}(\id{s^*}) <
      \id{voteID}}, then \id{s^*} knows as much about the most recent transaction as what it was just sent, but
      its perspective on which server will be the next leader needs to be updated:
      \begin{itemize}\firmlist
      \item \mathexpr{\func{leader}(\id{s^*}) \leftarrow \id{voteID}}
      \end{itemize}
    \end{itemize}
  \end{block}
  \begin{alertblock}{Note}
    When \id{s^*} believes it should be the leader, it broadcasts
    \mathexpr{\langle\func{id}(\id{s^*}),\func{tx}(\id{s^*})\rangle}. \blue{Essentially, we're bullying}.
  \end{alertblock}
\end{frame}
\subsection{Example: Leader election in Raft}
\begin{frame}{Example: Leader election in Raft}
  \begin{block}{Basics}
    \begin{itemize}\firmlist
    \item We have a (relatively small) group of servers
    \item A server is in one of three states: \red{\id{follower}}, \red{\id{candidate}}, or \red{\id{leader}}
    \item The protocol works in \red{terms}, starting with term 0
    \item Each server starts in the \id{follower} state.
    \item A leader is to regularly broadcast messages (perhaps just a simple \blue{heartbeat})
    \end{itemize}
  \end{block}
\end{frame}
\begin{frame}{Example: Leader election in Raft}
  \begin{block}{Selecting a new leader}
    When follower \id{s^*} hasn't received anything from the alleged leader \id{s} for some time, \id{s^*}
    broadcasts that it volunteers to be the next leader, increasing the term by 1. \id{s^*} enters the
    \red{candidate} state. Then:
    \begin{itemize}\firmlist
    \item If leader \id{s} receives the message, it responds by acknowledging that it is still the
      leader. \id{s^*} returns to the \red{follower} state.
    \item If another follower \id{s^{**}} gets the election message from \id{s^*}, and it is the first
      election message during the current term, \id{s^{**}} votes for \id{s^*}. Otherwise, it simply ignores
      the election message from \id{s^*}. When \id{s^*} has collected a majority of votes, a new term starts
      with a new leader.
    \end{itemize}
  \end{block}

  \begin{alertblock}{Observation}
    By slightly differing the timeout values per follower for deciding when to start an election, we can avoid
    concurrent elections, and the election will rapidly converge.
  \end{alertblock}

\end{frame}
\subsection{Elections in large-scale systems}
\begin{frame}{Elections by proof of work}
  \begin{block}{Basics}
    \begin{itemize}\firmlist
    \item Consider a potentially large group of processes
    \item Each process is required to solve a computational puzzle
    \item When a process solves the puzzle, it broadcasts its victory to the group
    \item We assume there is a conflict resolution procedure when more than one process claims victory
    \end{itemize}
  \end{block}
  \begin{block}{Solving a computational puzzle}
    \begin{itemize}
    \item Make use of a \red{secure hashing function} \mathexpr{H(m)}:
      \begin{itemize}
      \item \mathexpr{m} is some data; \mathexpr{H(m)} returns a \blue{fixed-length bit string}
      \item computing \mathexpr{h = H(m)} is computationally efficient
      \item finding a function \mathexpr{H^{-1}} such that \mathexpr{m = H^{-1}(H(m))} is computationally
        extremely difficult
      \end{itemize}
    \item \blue{Practice}: finding \mathexpr{H^{-1}} boils down to an extensive \blue{trial-and-error}
      procedure
    \end{itemize}
  \end{block}
\end{frame}
\begin{frame}{Elections by proof of work}
  \begin{block}{Controlled race}
    \begin{itemize}
    \item Assume a globally known secure hash function \mathexpr{H^*}. Let \mathexpr{H_i} be the hash function
      used by process \mathexpr{P_i}.
    \item Task: given a bit string \mathexpr{h = H_i(m)}, find a bit string \mathexpr{\tilde{h}} such that
      \mathexpr{h^* = H^*(H_i(\tilde{h} \odot h))} where:
      \begin{itemize}
      \item \mathexpr{h^*} is a bit string with \mathexpr{K} leading zeroes
      \item \mathexpr{\tilde{h} \odot h} denotes some predetermined bitwise operation on \mathexpr{\tilde{h}}
        and \mathexpr{h} 
      \end{itemize}
    \end{itemize}
  \end{block}

  \begin{alertblock}{Observation}
    By controlling \mathexpr{K}, we control the difficulty of finding \mathexpr{\tilde{h}}. If \mathexpr{p}
    is the probability that a random guess for \mathexpr{\tilde{h}} will suffice: \mathexpr{p=(1/2)^{K}}.
  \end{alertblock}
  
  \begin{block}{Current practice}
    In many PoW-based blockchain systems, \mathexpr{K=64}
    \begin{itemize}%\firmlist
    \item With \mathexpr{K=64}, it takes about 10 minutes on a supercomputer to find \mathexpr{\tilde{h}}
    \item With \mathexpr{K=64}, it takes about 100 years on a laptop to find \mathexpr{\tilde{h}}
    \end{itemize}
  \end{block}
\end{frame}
\begin{frame}{Elections by proof of stake}
  \begin{block}{Basics}
    We assume a blockchain system in which \mathexpr{N} \red{secure tokens} are used:
    \begin{itemize}
    \item Each token has a unique \blue{owner}
    \item Each token has a uniquely associated \blue{index} \mathexpr{1 \leq k \leq N}
    \item A token cannot be modified or copied without this going unnoticed
    \end{itemize}
  \end{block}
  \begin{block}{Principle}
    \begin{itemize}
    \item Draw a random number \mathexpr{k \in \{1, \ldots, N\}}
    \item Look up the process \mathexpr{P} that owns the token with index \mathexpr{k}. \mathexpr{P} is the
      next leader.
    \end{itemize}
  \end{block}
  \begin{alertblock}{Observation}
    The more tokens a process owns, the higher the probability it will be selected as leader.
  \end{alertblock}
\end{frame}
\subsection{Elections in wireless environments}
\begin{frame}{A solution for wireless networks}
  \begin{block}{A sample network}
    \begin{center}
      \begin{tabular}{cc}
        \includefigure{05-24a} &
        \includefigure{05-24b} \\
      \end{tabular}
    \end{center}
  \end{block}
  \begin{block}{Essence}
    Find the node with the highest capacity to select as the next leader.
  \end{block}
\end{frame}
\begin{frame}{A solution for wireless networks}
  \begin{block}{A sample network}
    \begin{center}
      \begin{tabular}{cc}
        \includefigure{05-24c} &
        \includefigure{05-24d} \\
      \end{tabular}
    \end{center}
  \end{block}
\end{frame}
\begin{frame}{A solution for wireless networks}
  \begin{block}{A sample network}
    \begin{center}
      \begin{tabular}{cc}
        \includefigure{05-24e} &
        \includefigure{05-24f} \\
      \end{tabular}
    \end{center}
  \end{block}
  \begin{block}{Essence}
    A node reports back only the node that it found to have the highest capacity.
  \end{block}
\end{frame}
\section{Gossip-based coordination}
\subsection{Aggregation}
\begin{slide}{Gossip-based coordination}
  \begin{itemize}[tightlist]
    \item Nodes randomly select a few other nodes (peers) periodically and 
    exchange state information (e.g., membership, failure detection, key-value updates, 
    or metadata). 
    \item Information spreads exponentially fast, similar to how gossip or a 
    virus spreads in a population, achieving eventual consistency with very high probability 
    in logarithmic rounds.
    \item Advantages: Extremely robust to network partitions, node failures, 
    and churn; no single point of failure; low coordination overhead; scales to thousands or tens of thousands of nodes with minimal latency impact; self-healing membership and failure detection (e.g., SWIM, HyParView, or Lifeguard protocols).
    \item Trade-offs \& Common Uses: Provides only probabilistic guarantees 
    (not strict consistency); latency of propagation is O(log N); 
    widely used for failure detection (accrual detectors), 
    \item Lightweight broadcast instead of heavy consensus protocols 
    like Paxos or Raft when strong consistency isnt required.
  \end{itemize}
\end{slide}

\begin{frame}{Gossip-based coordination: aggregation}
  \begin{block}{Typical apps}
    \begin{itemize}
    \item \red{Data dissemination}: Perhaps the most important one. Note that there are many variants of
      dissemination.
    \item \red{Aggregation Function (Average)}: Let every node \id{P_i} maintain a variable \mathexpr{v_i}. When two nodes gossip, they
      each reset their variable to\[{v_i},{v_j} \leftarrow ({v_i} + {v_j}) /2\] Result: in the end
      each node will have computed the average \mathexpr{\bar{v} = \sum_i {v_i} / N}.
    \item What happens in the case that initially \mathexpr{{v_i} = 1} and \mathexpr{{v_j} = 0, j \neq i}?
    \end{itemize}
  \end{block}
\end{frame}
\subsection{A peer-sampling service}
\begin{frame}{Gossip-based coordination: peer sampling}
  \begin{block}{Problem}
    For many gossip-based applications, you need to \blue{select a peer uniformly at random} from the entire
    network. In principle, this means you need to know all other peers. \red{Impossible}?
  \end{block}
  \begin{block}{Basics}
    \begin{itemize}
    \item Each node maintains a list of \mathexpr{c} references to other nodes
    \item \red{Regularly}, pick another node at random (from the list), and \blue{exchange} roughly
      \mathexpr{c/2} references
    \item When the \red{application} needs to select a node at random, it also picks a random one from from
      its local list.
    \end{itemize}
  \end{block}
  \begin{alertblock}{Observation}
    Statistically, it turns out that the selection of a peer from the local list is indistinguishable from
    selecting uniformly at random peer from the entire network
  \end{alertblock}
\end{frame}
\subsection{Gossip-based overlay construction}
\begin{frame}{Gossip-based overlay construction}
  \begin{block}{Essence}
    Maintain two local lists of neighbors. The lowest is used for providing a \blue{peer-sampling service};
    the highest list is used to carefully select \blue{application-dependent neighbors}.
  \end{block}
  \begin{centerfig}
    \includefigure{05-26}
  \end{centerfig}
\end{frame}
\begin{frame}{Gossip-based overlay construction: a 2D torus}
  Consider a logical \mathexpr{N \times N} grid, with a node on each point of the grid.
  \begin{itemize}
  \item Every node must maintain a list of \mathexpr{c} nearest neighbors
  \item Distance between node at \mathexpr{(a_1, a_2)} and \mathexpr{(b_1, b_2)} is \mathexpr{d_1 + d_2},
    with \mathexpr{d_i = \min(N - |a_i - b_i|, |a_i - b_i|)}
  \item Every node picks a random other node from its lowest-level list, and keeps only the closest one in
    its top-level list.
  \item Once every node has picked and selected a random node, we move to the next \blue{round}
  \end{itemize}
  \begin{centerfig}
    \begin{tabular}{ccc}
      \includefigure{05-27a} &
      \includefigure{05-27b} &
      \includefigure{05-27c} \\
      start (\mathexpr{N=50})& after 5 rounds & after 20 rounds
    \end{tabular}
  \end{centerfig}
\end{frame}
  % \begin{frame}{A gossip-based 2D torus in Python (outline)}
  %   \begin{centerfig}
  %     \includelisting{05-28/outline}
  %   \end{centerfig}
  % \end{frame}
\subsection{Secure gossiping}
\begin{frame}{Secure gossiping}
  \begin{alertblock}{Dramatic attack}
    Consider when exchanging references, a set of \blue{colluding nodes} systematically returns links only to
    each other \mathexpr{\Rightarrow} we are dealing with \red{hub attack}.
  \end{alertblock}
  \begin{centerfig}
    \includefigure{05-29}
  \end{centerfig}
  \begin{block}{Situation}
    A network with 100,000 nodes, a local list size \mathexpr{c=30}, and only 30 attackers. The y-axis shows
    the number of nodes with links \blue{only} to the attackers. After less than 300 rounds, the attackers
    have full control.
  \end{block}
\end{frame}
\begin{frame}{A solution: gathering statistics}
  This is what measuring indegree distributions tells us: which fraction of nodes (y-axis) have how many other
  nodes pointing to them (x-axis)?
  \begin{centerfig}
    \newcommand{\idscale}{0.6}
    \begin{tabular}{ccc}
      \includefigure[\idscale]{05-30a} &
%      \includefigure[\idscale]{05-30b} &
      \includefigure[\idscale]{05-30c} &
%      \includefigure[\idscale]{05-30d} &
      \includefigure[\idscale]{05-30e} 
%      \includefigure[\idscale]{05-30f} 
    \end{tabular
     }
  \end{centerfig}
  \begin{block}{Basic approach}
    When a benign node initiates an exchange, it may either use the result for gathering statistics, or for
    updating its local list. An attacker is in limbo: will its response be used for statistical purposes or
    for functional purposes?
  \end{block}
  
  \begin{alertblock}{Observation}
    When gathering statistics may reveal colluders, a colluding node will be \red{forced} to behave according
    to the protocol.
  \end{alertblock}
\end{frame}
\section{Distributed event matching}
\begin{frame}{Distributed event matching}
  \begin{centerfig}
    \includefigure{02-12}
  \end{centerfig}
  \begin{block}{Principle}
    \begin{itemize}%\firmlist
    \item A process specifies in which events it is interested (\red{subscription} \id{S})
    \item When a process \red{publishes a notification} \id{N} we need to see whether \id{S} \blue{matches}
      \id{N}.
    \end{itemize}
  \end{block}
  
  \begin{alertblock}{Hard part}
    Implementing the \blue{match} function in a scalable manner.
  \end{alertblock}
\end{frame}
\subsection{Centralized implementations}
\begin{frame}{General approach}
  \begin{block}{What is needed}
    \begin{itemize}\firmlist
    \item \red{\mathexpr{\func{sub2node}(\id{S})}}: map a subscription \id{S} to a nonempty subset \set{S} of servers
    \item \red{\mathexpr{\func{not2node}(\id{N})}}: map a notification \id{N} to a nonempty subset \set{N} of servers
    \end{itemize}
    Make sure that \mathexpr{\set{S} \cap \set{N} \neq \emptyset}.
  \end{block}
  \begin{alertblock}{Observations}
    \begin{itemize}
    \item Centralized solution is simple: \mathexpr{\set{S} = \set{N} = \{s\}}, i.e. a single server.
    \item \blue{Topic-based publish-subscribe} is also simple: each \id{S} and \id{N} is tagged with a
      \blue{single topic}; each topic is handled by a single server (a \blue{rendezevous node}). Several
      topics may be handled by same server).
    \item \blue{Content-based publish-subscribe} is \red{tough}: a subscription takes the form
      (\emph{attribute},~\emph{value}) pair, with example values:
      \begin{itemize}\tightlist
      \item \blue{range}: ``\mathexpr{1 \leq x < 10}''
      \item \blue{containment}: ``\mathexpr{x \in \{\id{red}, \id{blue}\}}''
      \item \blue{prefix and suffix expressions}: ``\code{url.startswith(\char34 https\char34)}''
      \end{itemize}
    \end{itemize}
  \end{alertblock}
\end{frame}
\begin{frame}{Selective routing}
  \begin{centerfig}
    \begin{tabular}{cc}
      \includefigure{05-32a} &
      \includefigure{05-32b} \\
      (a) & (b)
    \end{tabular}
  \end{centerfig}
  \begin{itemize}
  \item[(a)]~first broadcast subscriptions
  \item[(b)]~forward notifications only to relevant rendezvous nodes
  \end{itemize}
  
  \begin{block}{Example of a (partially filled) routing table}
    \begin{centerfig}
      \sffamily\footnotesize
      \renewcommand{\arraystretch}{1.1}
      \begin{tabular}{|l|l|} \hline
        \textbf{Interface} & \textbf{Filter} \\ \whline 
        To node 3                & \mathexpr{\idsn{a} \in [0,3]} \\ \hline 
        To node 4                & \mathexpr{\idsn{a} \in [2,5]} \\ \hline 
        Toward router \idsn{R_1} & (unspecified) \\ \hline
      \end{tabular}
    \end{centerfig}
  \end{block}
\end{frame}
\begin{frame}{Gossiping: Sub-2-Sub}
  \begin{block}{Basics}
    \begin{itemize}\tightlist
    \item \red{Goal}: To realize scalability, make sure that subscribers with the same interests form just a
      single group
    \item \red{Model}: There are \mathexpr{N} attributes \mathexpr{\id{a_1},\ldots,\id{a_N}}. An attribute
      value is always (mappable to) a floating-point number.
    \item \red{Subscription}: Takes forms such as \mathexpr{\id{S} = \langle \id{a_1} \rightarrow 3.0,
      \id{a_4} \rightarrow [0.0, ~0.5) \rangle}: \id{a_1} should be 3.0; \id{a_4} should lie between 0.0 and
      0.5; other attribute values don't matter.
    \end{itemize}
  \end{block}
  \begin{block}{Observations}
    \begin{itemize}\tightlist
    \item A subscription \id{S_i} specifies a subset \set{S_i} in a \mathexpr{N}-dimensional space.
    \item We are interested only in notifications that fall into \mathexpr{\set{\overline{S}} = \cup \set{S_i}}.
    \end{itemize}
  \end{block}
  
  \begin{alertblock}{Goal}
    Partition \set{\overline{S}} into \mathexpr{M} disjoint subspaces
    \mathexpr{\set{\overline{S}_1},\ldots,\set{\overline{S}_M}} such that
    \begin{itemize}\tightlist
    \item \blue{Partitioning}: \( \forall k\neq m: \set{\overline{S}_k} \cap \set{\overline{S}_m} = \emptyset \mbox{\ and\ }
        \cup_m\set{\overline{S}_m} = \set{\overline{S}} \)
    \item \blue{Subscription coverage}: \( (\set{\overline{S}_m} \cap \set{S_i} \neq \emptyset ) \Rightarrow
      (\set{\overline{S}_m} \subseteq \set{S_i}) \)
    \end{itemize}
  \end{alertblock}
\end{frame}
\begin{frame}{Gossiping: Sub-2-Sub}
  \begin{centerfig}
    \includefigure{05-34}
  \end{centerfig}
  \begin{block}{Consider a single attribute}
    \begin{itemize}
    \item Nodes regularly exchange their subscriptions through gossiping
    \item An intersection between two nodes leads to a mutual reference
    \item If \mathexpr{\set{S_{ijk}} = \set{S_i} \cap \set{S_j} \cap \set{S_k} \neq \emptyset} \blue{and}
      \mathexpr{\set{S_{ij}}-\set{S_{ijk}} \neq \emptyset}, then:
      \begin{itemize}
      \item nodes \id{i}, \id{j}, \id{k} are grouped into a \red{single overlay network} (for \red{\set{S_{ijk}}})
      \item nodes \id{i}, \id{j} are grouped into a \red{single overlay network} (for
        \red{\mathexpr{\set{S_{ij}}-\set{S_{ijk}}}})
      \end{itemize}
    \end{itemize}
  \end{block}
  
\end{frame}
\subsection{Secure publish-subscribe solutions}
\begin{frame}{Secure publish-subscribe}
  \begin{alertblock}{We are facing nasty dilemma's}
    \begin{itemize}
    \item \red{Referential decoupling}: messages should be able to flow from a publisher to subscribers while
      guaranteeing mutual anonymity \mathexpr{\Rightarrow} we cannot set up a secure channel.
    \item Not knowing where messages come from imposes \red{integrity problems}.
    \item Assuming a \blue{trusted broker} may easily be practically impossible, certainly when dealing with
      sensitive information \mathexpr{\Rightarrow} we now have a \red{routing problem}.
    \end{itemize}
  \end{alertblock}
  
  \begin{block}{Solution}
    \begin{itemize}
    \item Allow for searching (and matching) on encrypted data, without the need for decryption.
    \item \blue{PEKS}: accompany encryptyed messages with a collection of (again encrypted) keywords and
      search for matches on keywords.
    \end{itemize}
  \end{block}
\end{frame}
% \begin{frame}{Public-Key Encryption with Keyword Search (PEKS)}
%   \begin{block}{Basics}
%     \begin{itemize}
%     \item Use a public key \id{PK}, message \id{m} and its \mathexpr{n} keywords
%       \mathexpr{\id{KW_1},\ldots,\id{KW_n}} are stored at a server as the message \id{m^*}:
%       \[
%       \id{m^*} = [ PK(\id{m}) | \func{PEKS}(\id{PK}, \id{KW_1}) | \func{PEKS}(\id{PK}, \id{KW_2}) | \cdots |
%         \func{PEKS}(\id{PK}, \id{KW_n}) ]
%       \]
%     \item A subscriber gets the accompanying secret key.
%     \item For each keyword \id{KW_i}, a \red{trapdoor} \id{T_{KW_i}} is generated: \id{T_W}(\id{m^*}) will
%       return \id{true} iff \mathexpr{\id{W} \in \{\id{KW_1},\ldots,\id{KW_n}\}}.
%     \end{itemize}
%   \end{block}
%   \begin{centerfig}
%     \includefigure{05-35} \\
%     {\footnotesize \mathexpr{\id{KW_i^*} = \func{PEKS}(\id{PK}, \id{KW_i})}}
%   \end{centerfig}
% \end{frame}
% \section{Location systems}
% \begin{frame}{Positioning nodes}
%   \begin{block}{Issue}
%     In large-scale distributed systems in which nodes are dispersed across a wide-area network, we often need
%     to take some notion of \blue{proximity} or \blue{distance} into account \mathexpr{\Rightarrow} it starts
%     with determining a (relative) \red{location} of a node.
%   \end{block}
% \end{frame}
% \subsection{GPS: Global Positioning System}
% \begin{frame}{Computing position}
%   \begin{block}{Observation} 
%     A node \id{P} needs \mathexpr{d+1} \blue{landmarks} to compute its own position in a
%     \mathexpr{d}-dimensional space. Consider two-dimensional case.
%   \end{block}
%   \begin{columns}[T]
%     \begin{column}{0.5\textwidth}
%       \begin{block}{Computing a position in 2D}
%         \begin{centerfig}
%           \includefigure{05-36}
%         \end{centerfig}
%       \end{block}
%     \end{column}
%     \begin{column}{0.45\textwidth}
%       \begin{block}{Solution} 
%         \id{P} needs to solve three equations in two unknowns (\mathexpr{x_P},\mathexpr{y_P}):
%         \[d_i = \sqrt{(x_i - x_P)^2 + (y_i - y_P)^2}\]
%       \end{block}
%     \end{column}
%   \end{columns}
% \end{frame}
% \begin{frame}{Global Positioning System}
%   \begin{block}{Assuming that the clocks of the satellites are accurate and synchronized}
%     \begin{itemize}\tightlist
%     \item It takes a while before a signal reaches the receiver
%     \item The receiver's clock is definitely out of sync with the satellite
%     \end{itemize}
%   \end{block}
%   \begin{block}{Basics}
%     \begin{itemize}\tightlist
%     \item \red{\mathexpr{\Delta_r}}: \red{unknown deviation} of the receiver's clock.
%     \item \red{\mathexpr{x_r}}, \red{\mathexpr{y_r}}, \red{\mathexpr{z_r}}: \red{unknown coordinates} of the receiver.
%     \item \mathexpr{T_i}: timestamp on a message from satellite \mathexpr{i}
%     \item \mathexpr{\blue{\Delta_i} = (T_{now} - T_i) + \red{\Delta_r}}: \blue{measured delay} of the message sent by satellite \mathexpr{i}.
%     \item \blue{Measured distance} to satellite \mathexpr{i}: \mathexpr{c \times \blue{\Delta_i}} (\mathexpr{c} is speed of light)
%     \item Real distance: \mathexpr{\red{d_i} = c \blue{\Delta_i} - c \red{\Delta_r} = \sqrt{(\blue{x_i} -
%         \red{x_r})^2 + (\blue{y_i} - \red{y_r})^2 + (\blue{z_i} - \red{z_r})^2}}
%     \end{itemize}
%   \end{block}
%   \begin{block}{Observation}
%     4 satellites \mathexpr{\Rightarrow} 4 equations in 4 unknowns (with \mathexpr{\red{\Delta_r}} as one of them)
%   \end{block}
% \end{frame}
% \subsection{When GPS is not an option}
% \begin{frame}{WiFi-based location services}
%   \begin{block}{Basic idea}
%     \begin{itemize}\tightlist
%     \item Assume we have a database of known access points (APs) with coordinates
%     \item Assume we can estimate distance to an AP
%     \item Then: with 3 detected access points, we can compute a position.
%     \end{itemize}
%   \end{block}
%   \begin{block}{War driving: locating access points}
%     \begin{itemize}\tightlist
%     \item Use a WiFi-enabled device along with a GPS receiver, and move through an area while recording
%       observed access points. 
%     \item Compute the centroid: assume an access point \id{AP} has been detected at \mathexpr{N} different
%       locations \mathexpr{\{\vec{x_1}, \vec{x_2}, \ldots, \vec{x_N}\}}, with known GPS location.
%     \item Compute location of \id{AP} as \mathexpr{\vec{x}_{AP} = \frac{\sum_{i=1}^N \vec{x_i}}{N}}.
%     \end{itemize}
%   \end{block}
%   \begin{alertblock}{Problems}
%     \begin{itemize}\tightlist
%     \item Limited accuracy of each GPS detection point \mathexpr{\vec{x_i}}
%     \item An access point has a nonuniform transmission range
%     \item Number of sampled detection points \mathexpr{N} may be too low.
%     \end{itemize}
%   \end{alertblock}
% \end{frame}
% \subsection{Logical positioning of nodes}
% \begin{frame}{Computing position}
%   \begin{columns}[T]
%     \begin{column}{0.45\textwidth}
%       \begin{block}{Problems}
%         \begin{itemize}
%         \item Measured latencies to landmarks fluctuate
%         \item Computed distances will not even be consistent
%         \end{itemize}
%       \end{block}
%     \end{column}
%     \begin{column}{0.5\textwidth}
%       \begin{block}{Inconsistent distances in 1D space}
%         \begin{centerfig}
%           \includefigure{05-37}
%         \end{centerfig}
%       \end{block}
%     \end{column}
%   \end{columns}
%   \begin{block}{Solution: minimize errors}
%     \begin{itemize}\tightlist
%     \item Use \mathexpr{N} special \red{landmark nodes} \mathexpr{\id{L_1}, \ldots, \id{L_N}}. 
%     \item Landmarks measure their pairwise latencies \mathexpr{\tilde{d}(\id{L_i}, \id{L_j})}
%     \item A central node computes the coordinates for each landmark, minimizing:
%       \[
%       \sum_{i=1}^N \sum_{j=i+1}^N \bigg(\frac{\tilde{d}(\id{L_i}, \id{L_j})
%         - \hat{d}(\id{L_i},\id{L_j})}{\tilde{d}(\id{L_i},\id{L_j})}\bigg)^{2}
%       \]
%       where \mathexpr{\hat{d}(\id{L_i}, \id{L_j})} is distance after nodes \id{L_i} and \id{L_j} have been
%       positioned.
%     \end{itemize}
%   \end{block}
% \end{frame}
% \begin{frame}{Computing position}
%   \begin{block}{Choosing the dimension \mathexpr{m}}
%     The hidden parameter is the dimension \mathexpr{m} with \mathexpr{N > m}. A node \id{P} measures its
%     distance to each of the \mathexpr{N} landmarks and computes its coordinates by minimizing
%     \[
%     \sum_{i=1}^N \bigg(\frac{\tilde{d}(\id{L_i}, \id{P})
%       - \hat{d}(\id{L_i},\id{P})}{\tilde{d}(\id{L_i},\id{P})}\bigg)^{2}
%     \]
%   \end{block}
%   \begin{block}{Observation}
%     Practice shows that \mathexpr{m} can be as small as 6 or 7 to achieve latency estimations within a factor
%     2 of the actual value.
%   \end{block}
% \end{frame}
% \begin{frame}{Vivaldi}
%   \begin{block}{Principle: network of springs exerting forces}
%     Consider a collection of \mathexpr{N} nodes \mathexpr{\id{P_1}, \ldots, \id{P_N}}, each \id{P_i} having
%     coordinates \mathexpr{\vec{x_i}}. Two nodes exert a \red{mutual force}:
%     \[
%     \vec{F}_{ij} = \big(\tilde{d}(\id{P_i},\id{P_j}) - \hat{d}(\id{P_i},\id{P_j})\big) \times
%     u(\vec{x_i}-\vec{x_j})
%     \]
%     with \mathexpr{u(\vec{x_i}-\vec{x_j})} is the unit vector in the direction of \mathexpr{\vec{x_i} -
%       \vec{x_j}}
%   \end{block}
%   \begin{block}{Node \id{P_i} repeatedly executes steps}
%     \begin{enumerate}\tightlist
%     \item Measure the latency \mathexpr{\tilde{d}_{ij}} to node \id{P_j}, and also receive \id{P_j}'s coordinates
%       \mathexpr{\vec{x_j}}. 
%     \item Compute the error \mathexpr{e = \tilde{d}(\id{P_i},\id{P_j}) - \hat{d}(\id{P_i},\id{P_j})}
%     \item Compute the direction \mathexpr{\vec{u} = u(\vec{x_i} - \vec{x_j})}.
%     \item Compute the force vector \mathexpr{F_{ij} = e \cdot \vec{u}}
%     \item Adjust own position by moving along the force vector: \mathexpr{\vec{x_i} \leftarrow \vec{x_i} + \delta
%       \cdot \vec{u}}.
%     \end{enumerate}
%   \end{block}
% \end{frame}
\section{Summary}
\begin{frame}{Summary}
The topics discussed in the \emph{coordination} section 
of the lecture notes include
\begin{enumerate}
  \item Mutual Exclusion
  \item Election Algorithms
  \item Gossip-based Coordination
  \item Distributed Event Matching
\end{enumerate}
\end{frame}

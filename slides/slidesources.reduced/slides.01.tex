\part{Introduction}
\section{Distributed versus Decentralized systems}
\subsection{Distributed versus Decentralized systems}
\begin{frame}{Distributed versus Decentralized}
  \begin{block}{What many people state}
    \begin{centerfig}
      \begin{tabular}{c@{\hspace*{1cm}}c@{\hspace*{1cm}}c}
        \includefigure{01-01a} &
        \includefigure{01-01b} &
        \includefigure{01-01c}                               \\
        Centralized            & Decentralized & Distributed
      \end{tabular}
    \end{centerfig}
  \end{block}
  \onslide
  \begin{alertblock}{When does a decentralized system become distributed?}
    \begin{itemize}\tightlist
      \item Adding 1 link between two nodes in a decentralized system?
      \item Adding 2 links between two other nodes?
      \item In general: adding \mathexpr{k>0} links....?
    \end{itemize}
  \end{alertblock}
\end{frame}

\begin{frame}{Alternative approach}
  \begin{block}{Distributed system}
    \begin{itemize}
      \item A distributed system consists of multiple computers
            (nodes) that work together to appear as a single system to
            the user.
      \item \textbf{Focus}: performance, scalability, fault tolerance
      \item \textbf{Control} typically/commonly centralized
    \end{itemize}
  \end{block}
  \begin{block}{Decentralized system}
    \begin{itemize}
      \item A decentralized system distributes control and
            decision-making authority across multiple independent
            nodes rather than relying on a central authority.
      \item \textbf{Focus}: autonomy, resilience to control, trust minimization
      \item \textbf{Control}: No single node has ultimate authority
    \end{itemize}
  \end{block}
\end{frame}

%----------------------------
\begin{frame}{The Key Difference: Control \& Authority}
  \begin{block}{Distributed}
    Multiple nodes \emph{compute together}, but control can still be centralized:
    \begin{itemize}
      \item Leader / coordinator often exists
      \item Decisions may flow from one organization or service
    \end{itemize}
  \end{block}

  \begin{block}{Decentralized}
    Multiple nodes \emph{share control}:
    \begin{itemize}
      \item No single node (or org) has ultimate authority
      \item Governance/decision-making spread across participants
    \end{itemize}
  \end{block}

  \begin{alertblock}{Key takeaway}
    A system can be \textbf{distributed yet centralized}; a \textbf{decentralized} system must distribute \emph{control}.
  \end{alertblock}
\end{frame}

%----------------------------
\begin{frame}{Architecture \& Coordination}
  \begin{block}{Typical distributed coordination}
    \begin{itemize}
      \item Client--server, master--worker, leader-based replication
      \item Specialized roles (leader, replicas, workers)
    \end{itemize}
  \end{block}

  \begin{block}{Typical decentralized coordination}
    \begin{itemize}
      \item Peer-to-peer style participation
      \item Collective coordination (e.g., voting/consensus-like mechanisms)
    \end{itemize}
  \end{block}

  \begin{exampleblock}{Intuition}
    Distributed $\rightarrow$ ``many machines, one system'' \\
    Decentralized $\rightarrow$ ``many owners, shared authority''
  \end{exampleblock}
\end{frame}

%----------------------------
\begin{frame}{Fault Tolerance \& Failure Modes}
  \begin{columns}[T,onlytextwidth]
    \column{0.48\textwidth}
    \begin{block}{Distributed systems}
      \begin{itemize}
        \item Handle \textbf{node failures} (crashes, partitions)
        \item But may have \textbf{single point of control}
      \end{itemize}
    \end{block}

    \column{0.48\textwidth}
    \begin{block}{Decentralized systems}
      \begin{itemize}
        \item Handle node failures \emph{and} control failures
        \item Aim to avoid \textbf{single authority failure}
      \end{itemize}
    \end{block}
  \end{columns}

  \begin{alertblock}{Practical distinction}
    Distributed: resilience to \textbf{hardware/service failure} \\
    Decentralized: resilience to \textbf{control/censorship/authority failure}
  \end{alertblock}
\end{frame}

%----------------------------
\begin{frame}{Trust \& Security Model}
  \begin{block}{Distributed (often)}
    \begin{itemize}
      \item Assumes trusted administrators / central policy
      \item Security enforced via access control and ops processes
    \end{itemize}
  \end{block}

  \begin{block}{Decentralized (often)}
    \begin{itemize}
      \item Assumes some participants may be malicious
      \item Uses mechanisms to reduce reliance on trust in any one node
    \end{itemize}
  \end{block}

  \begin{exampleblock}{Rule of thumb}
    More decentralization usually means a \textbf{stronger adversarial model} (and more design complexity).
  \end{exampleblock}
\end{frame}

%----------------------------
\begin{frame}{Performance \& Efficiency Trade-offs}
  \begin{block}{Distributed systems tend to optimize}
    \begin{itemize}
      \item Latency, throughput, operational efficiency
      \item Coordination cost kept low via leaders / centralized control
    \end{itemize}
  \end{block}

  \begin{block}{Decentralized systems tend to trade performance for}
    \begin{itemize}
      \item Independence, robustness, shared governance
      \item Higher coordination overhead (more parties must agree)
    \end{itemize}
  \end{block}

  \begin{alertblock}{Trade-off}
    Decentralization often increases cost of coordination $\Rightarrow$ lower peak performance.
  \end{alertblock}
\end{frame}

%----------------------------
\begin{frame}{Summary Comparison}
  \begin{block}{Quick comparison}
    \begin{itemize}
      \item \textbf{Goal:} Distributed $\rightarrow$ scalability/performance \quad vs \quad Decentralized $\rightarrow$ autonomy/resilience
      \item \textbf{Control:} Distributed $\rightarrow$ may be centralized \quad vs \quad Decentralized $\rightarrow$ shared control
      \item \textbf{Trust:} Distributed $\rightarrow$ trusted operators \quad vs \quad Decentralized $\rightarrow$ trust-minimized
      \item \textbf{Complexity:} Distributed $\rightarrow$ moderate \quad vs \quad Decentralized $\rightarrow$ higher
    \end{itemize}
  \end{block}
\end{frame}

\section{Design goals}
\begin{frame}{What do we want to achieve?}
  \begin{block}{Overall design goals}
    \begin{itemize}
      \item Support sharing of resources
      \item Distribution transparency
      \item Openness
      \item Scalability
    \end{itemize}
  \end{block}
\end{frame}
\subsection{Resource sharing}
\begin{frame}{Sharing resources}
  \begin{exampleblock}{Canonical examples}
    \begin{itemize}\firmlist
      \item Cloud-based shared storage and files
      \item Peer-to-peer assisted multimedia streaming
      \item Shared mail services (think of outsourced mail systems)
      \item Shared Web hosting (think of content distribution networks)
    \end{itemize}
  \end{exampleblock}
  \begin{block}{Observation}
    \begin{quote}\itshape
      ``The network is the computer''
    \end{quote}
    (John Gage, Sun Microsystems)
  \end{block}
\end{frame}
\subsection{Distribution transparency}
\begin{frame}{Distribution transparency}
  \begin{centerfig}
    \includefigure{01-02}
  \end{centerfig}

  \begin{block}{What is transparency?}
    \itshape The phenomenon by which a distributed system attempts to \blue{hide} the fact that its processes
    and resources are \blue{physically distributed across multiple computers}, possibly \blue{separated by
      large distances}.
  \end{block}
  \onslide
  \begin{block}{Observation}
    Distribution transparancy is handled through many different techniques in a layer between applications and
    operating systems: a \textbf{middleware layer}
  \end{block}

\end{frame}
\begin{frame}{Distribution transparency}
  \begin{block}{Types}
    \begin{center}
      \sffamily\small \renewcommand{\arraystretch}{1.1}
      \begin{tabular}{|l|>{\RRCOL}p{0.7\textwidth}|} \hline
        \textbf{Transparency} & \blue{Description}                                                    \\ \whline
        \textbf{Access}       & Hide differences in data representation and how an object is accessed \\ \hline
        \textbf{Location}     & Hide where an object is located                                       \\ \hline
        \textbf{Migration}    & Hide that an object may move to another location                      \\ \hline
        \textbf{Replication}  & Hide that an object is replicated                                     \\ \hline
        \textbf{Concurrency}  & Hide that an object may be shared by several independent users        \\ \hline
        \textbf{Failure}      & Hide the failure and recovery of an object                            \\ \hline
      \end{tabular}
    \end{center}
  \end{block}
\end{frame}

\subsection{Openness}
\begin{frame}{Openness of distributed systems}
  \begin{block}{Open distributed system}
    \itshape A system that \blue{offers components} that can easily be used by, or \blue{integrated into
      other systems}. An open distributed system itself will often consist of components that originate from
    elsewhere.
  \end{block}

  \begin{block}{What are we talking about?}
    Be able to interact with services from other open systems, irrespective of the underlying environment:
    \begin{itemize}\tightlist
      \item Systems should conform to well-defined \blue{interfaces}
      \item Systems should easily \blue{interoperate}
      \item Theis means publicly documented protocols and APIs
      \item Vendor-neutral standards
      \item Interoperability and extensibility
    \end{itemize}
  \end{block}
\end{frame}
% \begin{frame}{Policies versus mechanisms}
%   \begin{block}{Implementing openness: policies}
%     \begin{itemize}\firmlist
%     \item What level of consistency do we require for client-cached data?
%     \item Which operations do we allow downloaded code to perform?
%     \item Which QoS requirements do we adjust in the face of varying bandwidth?
%     \item What level of secrecy do we require for communication?
%     \end{itemize}
%   \end{block}
%   \begin{block}{Implementing openness: mechanisms}
%     \begin{itemize}\firmlist
%     \item Allow (dynamic) setting of caching policies
%     \item Support different levels of trust for mobile code
%     \item Provide adjustable QoS parameters per data stream
%     \item Offer different encryption algorithms
%     \end{itemize}
%   \end{block}
% \end{frame}
% \begin{frame}{On strict separation}
%   \begin{block}{Observation}
%     The stricter the separation between policy and mechanism, the more we need to ensure proper
%     mechanisms, potentially leading to many configuration parameters and complex management.
%   \end{block}

%   \begin{alertblock}{Finding a balance}
%     Hard-coding policies often simplifies management, \red{and} reduces complexity at the price of less
%     flexibility. There is no obvious solution.
%   \end{alertblock}
% \end{frame}
\subsection{Dependability}
\begin{frame}{Dependability}
  \begin{block}{Basics}
    A \blue{component} provides \blue{services} to \blue{clients}.  To provide services, the component may
    require the services from other components \mathexpr{\Rightarrow} a component may \red{depend} on some
    other component.
  \end{block}
  \begin{block}{Specifically}
    A component \id{C} depends on \id{C^*} if the \blue{correctness} of \id{C}'s behavior depends on the
    correctness of \id{C^*}'s behavior. (Components are processes or channels.)
  \end{block}
\end{frame}
\begin{frame}{Dependability}
  \begin{block}{Requirements related to dependability}
    \begin{center}
      \begin{tabular}{|l|l|}\hline
        \textbf{Requirement}     & \textbf{Description}                     \\ \whline
        \textbf{Availability}    & Readiness for usage                      \\ \hline
        \textbf{Reliability}     & Continuity of service delivery           \\ \hline
        \textbf{Safety}          & Very low probability of catastrophes     \\ \hline
        \textbf{Maintainability} & How easy can a failed system be repaired \\ \hline
      \end{tabular}
    \end{center}
  \end{block}
\end{frame}

\begin{frame}{Traditional reliability - MTTF/MTTR}
  The following \emph{traditional} metrics were derived from
  shop-floor machine reliability modelling over many years.
  \begin{block}{Traditional metrics}
    \begin{itemize}\firmlist
      \item \textbf{Mean Time To Failure} (\blue{\MTTF}): The average time until a component fails.
      \item \textbf{Mean Time To Repair} (\blue{\MTTR}): The average time needed to repair a component.
      \item \textbf{Mean Time Between Failures} (\blue{\MTBF}): Simply \MTTF\ + \MTTR.
    \end{itemize}
  \end{block}
  You will often see $MTTF$, $MTTR$, $MTBF$ used for modelling
  system reliability over time.
\end{frame}

\begin{frame}{Reliability v Availability}
  \begin{itemize}\firmlist
    \item \emph{Availability} is about how much of the time the system is usable,
          allowing multiple failures and repairs.
    \item \emph{Availability} is measured in \emph{Uptime percentage}
          or \emph{SLA "nines"} (eg, 5 9s)
          \[
            A = \lim_{T \to \infty} \frac{\text{time system is up in } [0, T]}{T}
          \]
    \item \emph{Reliability}: time to first failure
    \item \emph{Reliability} is about whether failure occurs at all
          during an interval.
          \[
            R(t) = \Pr\{\text{system survives without failure for time } t\}
          \]
    \item \emph{Reliability} is measured Failure rate
          $\lambda$ or MTTF
  \end{itemize}
\end{frame}

\begin{frame}{Availability v Reliability: Numerical Example}
  \begin{block}{System 1}
    \begin{itemize}
      \item Fails every 10 minutes
      \item Repair time = 1 second
      \item \emph{Availability} $\approx$ 99.83\%
      \item \emph{Reliability over 1 hour} $\approx$ almost zero
    \end{itemize}
  \end{block}

  \begin{block}{System 2}
    \begin{itemize}
      \item Fails every 6 months
      \item Repair time = 6 hours
      \item \emph{Availability} $\approx$ 99.83\%
      \item \emph{Reliability over 1 hour} $\approx$ almost 1
    \end{itemize}
  \end{block}
  \textbf{Conclusion}: Two systems, with the same
  \emph{availability}, but completely different
  \emph{reliability}.
\end{frame}

\subsection{Security}
\begin{frame}{A Note on Security}
  \begin{alertblock}{Observation}
    A distributed system that is not secure, is not dependable
  \end{alertblock}
  \onslide
  \begin{block}{What we need}
    \begin{itemize}\firmlist
      \item \red{Confidentiality}: information is disclosed only to authorized parties
      \item \red{Integrity}: Ensure that alterations to assets of a system can be made only in an authorized way
    \end{itemize}
  \end{block}
  \onslide
  \begin{block}{Authorization, Authentication, Trust}
    \begin{itemize}\firmlist
      \item \blue{Authentication}: verifying the correctness of a claimed identity
      \item \blue{Authorization}: does an identified entity has proper access rights?
      \item \blue{Trust}: one entity can be assured that another will perform particular actions
            according to a specific expectation
    \end{itemize}
  \end{block}
\end{frame}

\begin{frame}{Security mechanisms}
  \begin{block}{Keeping it simple}
    It's all about \blue{encrypting} and \blue{decrypting} data using \blue{security keys}.
  \end{block}
  \begin{block}{Notation}
    \mathexpr{K(\id{data})} denotes that we \blue{use key \mathexpr{K}} to \blue{encrypt/decrypt \id{data}}.
  \end{block}
\end{frame}

\begin{frame}{Security mechanisms}
  \begin{block}{Symmetric cryptosystem}
    With \blue{encryption key \mathexpr{E_K(\id{data})}} and \blue{decryption key \mathexpr{D_K(\id{data})}}:
    \(
    \mbox{\itshape if\ } \id{data} = D_K(E_K(\id{data})) \mbox{\itshape \ then\ } \id{D_K} = \id{E_K}.
    \)
    Note: encryption and descryption key are the same and should be kept \red{secret}.
  \end{block}
  \begin{block}{Asymmetric cryptosystem}
    Distinguish a \red{public key} \blue{\mathexpr{PK(\id{data})}} and a \red{private} (\blue{secret})
    \red{key} \blue{\mathexpr{SK(\id{data})}}.
    \begin{itemize}\tightlist
      \item Encrypt message from \id{Alice} to \id{Bob}:
            \(
            \id{data} =
            \underbrace{%
              \red{SK_{bob}(}\overbrace{%
                \blue{PK_{bob}(\id{data})}
              }^{\mbox{\tiny Sent by Alice}}\red{)}
            }_{\mbox{\tiny Action by Bob}}
            \)
      \item Sign message for \id{Bob} by \id{Alice}:
            \(
            [\id{data}, \underbrace{%
            \red{\id{data}\stackrel{?}{=}PK_{alice}(}\blue{SK_{alice}(\id{data})}\red{)}
            }_{\mbox{\tiny Check by Bob}}
            ] =
            \underbrace{%
              [\id{data}, \blue{SK_{alice}(\id{data})}]
            }_{\mbox{\tiny Sent by Alice}}
            \)
    \end{itemize}
  \end{block}
\end{frame}
\begin{frame}{Security mechanisms}
  \begin{block}{Secure hashing}
    In practice, we use \blue{secure hash functions}: \mathexpr{H(\id{data})} returns a \red{fixed-length
      string}. \vspace*{-6pt}
    \begin{itemize}\tightlist
      \item \blue{Any change} from \id{data} to \id{data^*} will lead to a \blue{completely different string}
            \mathexpr{H(\id{data^*})}.
      \item Given a hash value, it is computationally impossible to find a \id{data} with \mathexpr{h = H(\id{data})}
    \end{itemize}
  \end{block}
  \onslide
  \begin{block}{Practical digital signatures}
    Sign message for \id{Bob} by \id{Alice}:
    \[
      [\id{data}, \underbrace{%
      \red{H(data)\stackrel{?}{=}PK_{alice}(}\blue{sgn}\red{)}
      }_{\mbox{\tiny Check by Bob}}
      ] =
      \underbrace{%
        [\id{data}, H, \blue{\id{sgn} = SK_{alice}(H(\id{data}))}]
      }_{\mbox{\tiny Sent by Alice}}
    \]
  \end{block}
\end{frame}

\section{Performance Models}
\subsection{Performance Models}
\begin{frame}{Performance Models}
  \begin{block}{A centralized service can be modeled as a simple queuing system}
    \centering\includefigure{01-05}
  \end{block}
  \begin{block}{Assumptions and notations}
    \begin{itemize}\tightlist
      \item The queue has infinite capacity \mathexpr{\Rightarrow} arrival rate of requests is not influenced
            by current queue length or what is being processed.
      \item Arrival rate requests: \mathexpr{\lambda}
      \item Processing capacity service: \mathexpr{\mu} requests per second
    \end{itemize}
  \end{block}
  % \begin{alertblock}{Fraction of time having \mathexpr{k} requests in the system}
  %   \[ p_k = \bigl(1 - \frac{\lambda}{\mu}\bigr)\bigl(\frac{\lambda}{\mu}\bigr)^k \]
  % \end{alertblock}
\end{frame}
\begin{frame}{Performance models}
  \begin{block}{Utilization \mathexpr{U} of a service is the fraction of time that it is busy}
    %%\[ U = \frac{\lambda}{\mu} \Rightarrow p_k = (1-U) U^k \]
    \[ U = \frac{\lambda}{\mu} \]
  \end{block}
  \begin{block}{Average number of requests in the system}
    % \[ \average{N} = \sum_{k\geq 0} k \cdot p_k = \sum_{k \geq 0} k \cdot (1-U)U^k = (1-U)\sum_{k\geq 0} k\cdot U^k \]
    \[ \average{N} = \frac{U}{1-U} \]
  \end{block}
  \begin{block}{Average throughput}
    \[ X = \frac{\lambda}{\mu} \cdot \mu = \lambda \]
    via the Principle of Equilibrium (or conservation)
  \end{block}
\end{frame}
\begin{frame}{Performance models}
  \begin{block}{Response time: total time take to process a request after submission}
    From Little's Law:
    \[ \average{N} = X \cdot R \Rightarrow R = \frac{\average{N}}{X}\]
    \[ \Rightarrow R = \frac{1}{\mu \cdot (1-U)} \]
  \end{block}
  \begin{block}{Observations}
    \begin{itemize}
      \item If \mathexpr{U} is small, response-to-service time is close to 1: a request is immediately
            processed
      \item If \mathexpr{U} goes up to 1, the system comes to a grinding halt. \newline Solution: increase $\mu$.
    \end{itemize}
  \end{block}
\end{frame}


\section{A simple classification of distributed systems}
\subsection{High-performance distributed computing}
\begin{frame}{Parallel computing}
  \begin{block}{Observation}
    High-performance distributed computing started with parallel computing
  \end{block}
  \begin{block}{Multiprocessor and multicore versus multicomputer}
    \begin{tabular}{cc}
      \includefigure{01-08a} &
      \includefigure{01-08b}
    \end{tabular}
  \end{block}
\end{frame}

\begin{frame}{Distributed shared memory systems}
  \begin{block}{Observation}
    Multiprocessors are relatively easy to program in comparison to multicomputers, yet have problems when
    increasing the number of processors (or cores). \blue{Solution}: Try to implement a \red{shared-memory
      model} on top of a multicomputer.
  \end{block}
  \begin{exampleblock}{Example through virtual-memory techniques}
    Map all main-memory pages (from different processors) into one \blue{single virtual address space}. If
    a process at processor \id{A} addresses a page \id{P} located at processor \id{B}, the OS at \id{A}
    \blue{traps and fetches \id{P}} from \id{B}, just as it would if \id{P} had been located on local disk.
  \end{exampleblock}
  \begin{block}{Problem}
    Performance of distributed shared memory could never compete with that of multiprocessors, and failed to
    meet the expectations of programmers. It has been widely abandoned by now.
  \end{block}
\end{frame}

\section{Pitfalls}
\begin{frame}{Developing distributed systems: Pitfalls}
  \begin{block}{Observation}
    Many distributed systems are needlessly complex, caused by mistakes that required patching later on.
    Many \blue{false assumptions} are often made.
  \end{block}
  \onslide
  \begin{block}{False (and often hidden) assumptions}
    \begin{itemize}
      \item The network is reliable
      \item The network is secure
      \item The network is homogeneous
      \item The topology does not change
      \item Latency is zero
      \item Bandwidth is infinite
      \item Transport cost is zero
      \item There is one administrator
    \end{itemize}
  \end{block}
\end{frame}

\section{Summary}
\begin{frame}{Summary and Conclusions}
  We have discussed some important principles
  in Distributed Systems, namely:
  \begin{itemize}
    \item Distributed and Decentralized Systems
    \item Resource Sharing
    \item Distribution Transparency
    \item Openness and Security
    \item Performance Models
    \item Classification of Distributed Systems
    \item Pitfalls of Distributed Systems Development
  \end{itemize}
\end{frame}
